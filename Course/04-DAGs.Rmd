# DAGs {#dags-1}

## Modelling

This session kicks off the block on linear regression as a statistic
modelling technique, but before we jump into the deep end and learn what
linear regression is and how we can apply it, we first have to understand
what modelling is and why we might do it. We also need a way to find out what we
actually have to include in the model and what we might not want or even can not
include to achieve robust results. This is what this session is all about.

### What is modelling?

Before we approach this question, we should briefly think about what steps a 
typical data analysis project comprises. We usually start with an interesting
problem and derive a research question from it. Based on this question we would
go into the literature and read up on theories and already published research
papers that are relevant to our question. We construct a theoretical framework
for our particular problem and formulate some hypotheses, collect or identify
appropriate data and conduct an exploratory data analysis. At this point we
should already have a firm understanding about what we actually want to find out
and how our data is structured. The next step would be modelling.

So what is modelling? In general we have one *dependent variable*, typically
denoted as $y$. This variable has some varying values. Our goal in modelling is
to estimate how these values are generated. Generating refers to the 
*data generating process* that we asumme responsible for $y$ having the values
it has. One or multiple *independent variables*, $x_1 \ x_2 \ ... \ x_k$, 
influence how the values of $y$ are generated; thus $y$ *depends* on the values
of our independent variable(s).

When we model, we do not know the data generating process, but based on 
theoretical considerations, careful thinking and exploratory data analysis, we
can make assumptions on how we think the process operates. DAGs are a tool that
can help us in clarifying our assumptions on the data generating process and
to formulate a model based on this. 

Before we dive into DAGs, we should briefly discuss the possible reasons for
modelling and what they imply for constructing our DAG and model.


### Estimating effects vs. prediction

There are two main reasons for modelling in the social sciences.

Our goal can be *prediction*, as in predicting our dependent variable $y$ to the
highest accuracy. This may be is the less classical reason for modelling, but 
one that has come to the forefront in recent years in the context of 
*machine learning*. 

Take ChatGPT for instance. The underlying GPT model, a large language model
(LLM), is used to predict what the next word in a sequence of words should be. 
Based on the context of the question and the prior words in the answer, which we
can understand as independent variables for our example, it calculates what word
has the highest probability of being the correct next one. It is all about 
prediction.

An example closer to home are annotations for text data. Imagine you have a lot 
of text, hundred thousands of social media posts, and you want to explore the
sentiment expressed in those. Do they lean to the positive or to the negative?
You can now go and take a "small" sample, let us say a few thousands and 
annotate them by hand. A lot of work, but based on those manually annotated
posts you can train a machine learning model that learns from those posts and
then, if everything goes well, is able to automatically annotate the remaining
hundred thousands of posts for you. Again, this is all about prediction; here 
predicting the sentiment of a post, the dependent variable, based on the words
it contains, the independent variables.

When prediction is our goal, we most often are not primarily interested in
understanding what independent variables influence the dependent variables in
which direction and with which magnitude. We are interested in the most accurate
prediction possible. These approaches are also called *y-centered*.

When we our interest can be centered on y, we can also be *x-centered*. This is
the more classical approach in statistics, at least for the social sciences.
Here our goal is estimate an effect of interest as possible. $y$ is still our
dependent variable but our focus lies on understanding which $x$ variables
influence $y$, in which direction this influence goes and what the magnitude is.

Let us say we are interested in why people cast their vote for a certain party.
We may have some hypotheses that proposes that voters who find certain issues
important have a higher probability of casting their ballot for this party. Our
interest would not be predicting the vote accurately but explaining why someone
votes the way they do. We can build a model from our assumptions, maybe there
are other important factors that correlate with the issues and the vote, and
test our hypotheses based on the results. Does holding certain issues important
really increase the chances of voting for this party or is there no effect?

Over the last sessions we build an interest in the relationship between points
scored and the salary received for NBA players. We could approach this as a
prediction problem, i.e. trying to predict the salary as accurately as possible 
based on a model that incorporates the scored points as well as other factors
that we assume of having an effect on the salary. We will return to this in 
session 11. We could also approach this as estimation problem, i.e. trying to
estimate the effect of scored points on the salary. We will most probably have
to include other variables that affect the relationship of score on salary as
well, but the model used will not necessarily be the same. This approach is what
we will tackle in this and the next 5 sessions.

Having settled on estimating the effect of score on salary, how can we find out
which variables we have to include in the model? The first step, and we can
never replace this with ever so fancy a statistical technique, is thinking about
the problem. We should also have a theoretical understanding of our problem,
know the current research on the topic and do some exploratory data analysis.
Based on this we will already have developed some assumptions concerning our
proposed underlying data generating process. Should we now throw everything into
our model that we deem interesting or relevant for the relationship between
score and salary? No, we should not. What we should do is use a tool that helps
us organize our assumptions and figure out which variables are actually relevant
for the effect we want to measure. This is where DAGs come in.


## DAGs

*DAG* is short for *directed acyclical graph*. 



* Indirect causal effect/Overcontrol Bias/Pipe
* Confounders/Fork
* Colliders

* Best model if our DAG is correct

## Total/Direct effect

* Identification


## NBA DAG

## dagitty.net

