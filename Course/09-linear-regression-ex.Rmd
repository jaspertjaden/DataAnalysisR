# Linear Regression - Exercises {#lin-e}

## Exercises of Linear Regression
In this exercise, you will use the Boston Housing Dataset to explore the relationship between housing prices and various features of the houses and their surroundings. The dataset contains 506 observations and 15 columns. The last column, MEDV, is the median value of owner-occupied homes in $1000â€™s. This is the target variable that you will try to predict using linear regression models. The other 14 columns represent different features of the houses and their surroundings, such as crime rate, nitric oxides concentration, pupil-teacher ratio, etc.

**DRAFT**

1. **Simple linear regression**: Use simple linear regression to predict the median value of owner-occupied homes (`MEDV`) based on a single predictor variable which is the average number of rooms per dwelling (`RM`). Fit the model.
```{r slm, warning=FALSE, message=FALSE}
# loading dataset
library(readxl)
BostonHousing <- read_excel("../datasets/boston.xlsx")
# applying linear regression
model_l <- lm(medv ~ rm, data = BostonHousing)
```

2. **Multiple linear regression**: Use multiple linear regression to predict `MEDV` based on multiple predictor variables, such as `RM`, `CRIM` (per capita crime rate by town), and `LSTAT` (% lower status of the population). Fit the model, generate predictions, and calculate the R-squared value to assess the model's performance.
```{r mlm, warning=FALSE, message=FALSE}
# applying linear regression
model_m <- lm(medv ~ rm + crim + lstat, data = BostonHousing)
```
3. **Model summary**: Generate summary of a both regression model, including information about the coefficients, standard errors, t-values, and p-values. Interpret the results. Calculate the R-squared value to assess both model's performance. Which model has better goodness of fit (R-Squared) ?

```{r model_summary, warning=FALSE, message=FALSE}
summary(model_l)
summary(model_m)
```
XXX--INTERPRETATION HERE--XXX

4. **Model diagnostics**: Create diagnostic plots to assess the assumptions of the models. Check whether your regression models from Tasks 1 and 2 satisfy the assumptions of linearity, multicollinearity, normality and homoscedasticity.Use numerical method variance inflation factor (VIF) to detect any multicollinearity issues among your predictor variables.

```{r model_diag, message=FALSE, warning=FALSE}
library(ggfortify)
library(car)
autoplot(model_l)
autoplot(model_m)
vif(model_m)
```

XXX---INTERPRETATION HERE---XXX



