<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 13 Logistic regression | Data Analysis with R for Social Scientists</title>
  <meta name="description" content="In this course, you will learn how to analyse data using regression in R." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content=" 13 Logistic regression | Data Analysis with R for Social Scientists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="In this course, you will learn how to analyse data using regression in R." />
  <meta name="github-repo" content="jaspertjaden/DataAnalysisR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 13 Logistic regression | Data Analysis with R for Social Scientists" />
  
  <meta name="twitter:description" content="In this course, you will learn how to analyse data using regression in R." />
  

<meta name="author" content="Jakob Tures &amp; Jasper Tjaden" />


<meta name="date" content="2023-09-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pm-a.html"/>
<link rel="next" href="out-look.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#acknowlegdements"><i class="fa fa-check"></i><b>0.1</b> Acknowlegdements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro-sem.html"><a href="intro-sem.html"><i class="fa fa-check"></i><b>1</b> Introduction to Seminar</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro-sem.html"><a href="intro-sem.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="intro-sem.html"><a href="intro-sem.html#why-should-i-take-this-course"><i class="fa fa-check"></i><b>1.2</b> Why should I take this course?</a></li>
<li class="chapter" data-level="1.3" data-path="intro-sem.html"><a href="intro-sem.html#objectives"><i class="fa fa-check"></i><b>1.3</b> Objectives</a></li>
<li class="chapter" data-level="1.4" data-path="intro-sem.html"><a href="intro-sem.html#what-is-not-covered"><i class="fa fa-check"></i><b>1.4</b> What is not covered</a></li>
<li class="chapter" data-level="1.5" data-path="intro-sem.html"><a href="intro-sem.html#prerequisites"><i class="fa fa-check"></i><b>1.5</b> Prerequisites</a></li>
<li class="chapter" data-level="1.6" data-path="intro-sem.html"><a href="intro-sem.html#structure"><i class="fa fa-check"></i><b>1.6</b> Structure</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="eda-1.html"><a href="eda-1.html"><i class="fa fa-check"></i><b>2</b> Exploratory Data Analysis - I</a>
<ul>
<li class="chapter" data-level="2.1" data-path="eda-1.html"><a href="eda-1.html#objectives-1"><i class="fa fa-check"></i><b>2.1</b> Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="eda-1.html"><a href="eda-1.html#r-functions-covered-this-week"><i class="fa fa-check"></i><b>2.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="2.3" data-path="eda-1.html"><a href="eda-1.html#why-is-eda-so-important"><i class="fa fa-check"></i><b>2.3</b> Why is EDA so important?</a></li>
<li class="chapter" data-level="2.4" data-path="eda-1.html"><a href="eda-1.html#importing-data-into-r"><i class="fa fa-check"></i><b>2.4</b> Importing data into R</a></li>
<li class="chapter" data-level="2.5" data-path="eda-1.html"><a href="eda-1.html#import-data-into-r"><i class="fa fa-check"></i><b>2.5</b> Import data into R</a></li>
<li class="chapter" data-level="2.6" data-path="eda-1.html"><a href="eda-1.html#merge-datasets"><i class="fa fa-check"></i><b>2.6</b> Merge datasets</a></li>
<li class="chapter" data-level="2.7" data-path="eda-1.html"><a href="eda-1.html#clean-dataset"><i class="fa fa-check"></i><b>2.7</b> Clean dataset</a></li>
<li class="chapter" data-level="2.8" data-path="eda-1.html"><a href="eda-1.html#change-variables"><i class="fa fa-check"></i><b>2.8</b> change variables</a></li>
<li class="chapter" data-level="2.9" data-path="eda-1.html"><a href="eda-1.html#explore-the-whole-dataset"><i class="fa fa-check"></i><b>2.9</b> Explore the whole dataset</a></li>
<li class="chapter" data-level="2.10" data-path="eda-1.html"><a href="eda-1.html#explore-individual-variables"><i class="fa fa-check"></i><b>2.10</b> explore individual variables</a></li>
<li class="chapter" data-level="2.11" data-path="eda-1.html"><a href="eda-1.html#further-resources"><i class="fa fa-check"></i><b>2.11</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda-2.html"><a href="eda-2.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis - II</a>
<ul>
<li class="chapter" data-level="3.1" data-path="eda-2.html"><a href="eda-2.html#markdown-introduction"><i class="fa fa-check"></i><b>3.1</b> Markdown Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="eda-2.html"><a href="eda-2.html#applying-edawvsown-data"><i class="fa fa-check"></i><b>3.2</b> Applying EDA(WVS/own data)</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="eda-2.html"><a href="eda-2.html#exercise---1"><i class="fa fa-check"></i><b>3.2.1</b> Exercise - 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dags-1.html"><a href="dags-1.html"><i class="fa fa-check"></i><b>4</b> DAGs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dags-1.html"><a href="dags-1.html#objectives-2"><i class="fa fa-check"></i><b>4.1</b> Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="dags-1.html"><a href="dags-1.html#functions-covered"><i class="fa fa-check"></i><b>4.2</b> Functions Covered</a></li>
<li class="chapter" data-level="4.3" data-path="dags-1.html"><a href="dags-1.html#modelling"><i class="fa fa-check"></i><b>4.3</b> Modelling</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dags-1.html"><a href="dags-1.html#what-is-modelling"><i class="fa fa-check"></i><b>4.3.1</b> What is modelling?</a></li>
<li class="chapter" data-level="4.3.2" data-path="dags-1.html"><a href="dags-1.html#estimating-effects-vs.-prediction"><i class="fa fa-check"></i><b>4.3.2</b> Estimating effects vs. prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dags-1.html"><a href="dags-1.html#dags"><i class="fa fa-check"></i><b>4.4</b> DAGs</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dags-1.html"><a href="dags-1.html#directed-acyclical-graphs"><i class="fa fa-check"></i><b>4.4.1</b> Directed acyclical graphs</a></li>
<li class="chapter" data-level="4.4.2" data-path="dags-1.html"><a href="dags-1.html#patterns-of-relationships"><i class="fa fa-check"></i><b>4.4.2</b> Patterns of relationships</a></li>
<li class="chapter" data-level="4.4.3" data-path="dags-1.html"><a href="dags-1.html#adjustment-set"><i class="fa fa-check"></i><b>4.4.3</b> Adjustment set</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dags-1.html"><a href="dags-1.html#nba-dag"><i class="fa fa-check"></i><b>4.5</b> NBA DAG</a></li>
<li class="chapter" data-level="4.6" data-path="dags-1.html"><a href="dags-1.html#resources"><i class="fa fa-check"></i><b>4.6</b> Resources</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="dags-1.html"><a href="dags-1.html#dagitty.net"><i class="fa fa-check"></i><b>4.6.1</b> dagitty.net</a></li>
<li class="chapter" data-level="4.6.2" data-path="dags-1.html"><a href="dags-1.html#how-to-use-dagitty"><i class="fa fa-check"></i><b>4.6.2</b> How to use dagitty()</a></li>
<li class="chapter" data-level="4.6.3" data-path="dags-1.html"><a href="dags-1.html#more-on-dags"><i class="fa fa-check"></i><b>4.6.3</b> More on DAGs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lin-t-1.html"><a href="lin-t-1.html"><i class="fa fa-check"></i><b>5</b> Linear Regression Theory I: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lin-t-1.html"><a href="lin-t-1.html#objectives-3"><i class="fa fa-check"></i><b>5.1</b> Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="lin-t-1.html"><a href="lin-t-1.html#what-is-linear-regression"><i class="fa fa-check"></i><b>5.2</b> What is Linear Regression</a></li>
<li class="chapter" data-level="5.3" data-path="lin-t-1.html"><a href="lin-t-1.html#examplary-research-question-data"><i class="fa fa-check"></i><b>5.3</b> Examplary research question &amp; data</a></li>
<li class="chapter" data-level="5.4" data-path="lin-t-1.html"><a href="lin-t-1.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.4</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="lin-t-1.html"><a href="lin-t-1.html#regression-formula"><i class="fa fa-check"></i><b>5.4.1</b> Regression Formula</a></li>
<li class="chapter" data-level="5.4.2" data-path="lin-t-1.html"><a href="lin-t-1.html#regressing-grade-on-hours"><i class="fa fa-check"></i><b>5.4.2</b> Regressing <code>grade</code> on <code>hours</code></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="lin-t-1.html"><a href="lin-t-1.html#moving-on"><i class="fa fa-check"></i><b>5.5</b> Moving on</a></li>
<li class="chapter" data-level="5.6" data-path="lin-t-1.html"><a href="lin-t-1.html#further-resources-1"><i class="fa fa-check"></i><b>5.6</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lin-t-2.html"><a href="lin-t-2.html"><i class="fa fa-check"></i><b>6</b> Linear Regression Theory II: Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lin-t-2.html"><a href="lin-t-2.html#objectives-4"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="lin-t-2.html"><a href="lin-t-2.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-additional-metric-variables"><i class="fa fa-check"></i><b>6.2.1</b> Adding additional metric variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-dummy-variables"><i class="fa fa-check"></i><b>6.2.2</b> Adding dummy variables</a></li>
<li class="chapter" data-level="6.2.3" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-categorical-variables"><i class="fa fa-check"></i><b>6.2.3</b> Adding categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="lin-t-2.html"><a href="lin-t-2.html#returning-to-our-research-question"><i class="fa fa-check"></i><b>6.3</b> Returning to our research question</a></li>
<li class="chapter" data-level="6.4" data-path="lin-t-2.html"><a href="lin-t-2.html#adressing-the-uncertainty"><i class="fa fa-check"></i><b>6.4</b> Adressing the uncertainty</a></li>
<li class="chapter" data-level="6.5" data-path="lin-t-2.html"><a href="lin-t-2.html#moving-on-1"><i class="fa fa-check"></i><b>6.5</b> Moving on</a></li>
<li class="chapter" data-level="6.6" data-path="lin-t-2.html"><a href="lin-t-2.html#further-resources-2"><i class="fa fa-check"></i><b>6.6</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="log-t-3.html"><a href="log-t-3.html"><i class="fa fa-check"></i><b>7</b> Linear Regression Theory III: Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="log-t-3.html"><a href="log-t-3.html#objectives-5"><i class="fa fa-check"></i><b>7.1</b> Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="log-t-3.html"><a href="log-t-3.html#model-fit"><i class="fa fa-check"></i><b>7.2</b> Model fit</a></li>
<li class="chapter" data-level="7.3" data-path="log-t-3.html"><a href="log-t-3.html#regression-diagnostics"><i class="fa fa-check"></i><b>7.3</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="log-t-3.html"><a href="log-t-3.html#linearity"><i class="fa fa-check"></i><b>7.3.1</b> Linearity</a></li>
<li class="chapter" data-level="7.3.2" data-path="log-t-3.html"><a href="log-t-3.html#normally-distributed-residuals"><i class="fa fa-check"></i><b>7.3.2</b> Normally distributed residuals</a></li>
<li class="chapter" data-level="7.3.3" data-path="log-t-3.html"><a href="log-t-3.html#homoscedasticity"><i class="fa fa-check"></i><b>7.3.3</b> Homoscedasticity</a></li>
<li class="chapter" data-level="7.3.4" data-path="log-t-3.html"><a href="log-t-3.html#no-overly-influential-data-points"><i class="fa fa-check"></i><b>7.3.4</b> No overly influential data points</a></li>
<li class="chapter" data-level="7.3.5" data-path="log-t-3.html"><a href="log-t-3.html#no-multicollinearity"><i class="fa fa-check"></i><b>7.3.5</b> No (multi)collinearity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="log-t-3.html"><a href="log-t-3.html#returning-to-our-research-question-1"><i class="fa fa-check"></i><b>7.4</b> Returning to our research question</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="log-t-3.html"><a href="log-t-3.html#interactions"><i class="fa fa-check"></i><b>7.4.1</b> Interactions</a></li>
<li class="chapter" data-level="7.4.2" data-path="log-t-3.html"><a href="log-t-3.html#regression-diagnostics-revisited"><i class="fa fa-check"></i><b>7.4.2</b> Regression diagnostics (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="log-t-3.html"><a href="log-t-3.html#conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
<li class="chapter" data-level="7.6" data-path="log-t-3.html"><a href="log-t-3.html#further-resources-3"><i class="fa fa-check"></i><b>7.6</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lin-a.html"><a href="lin-a.html"><i class="fa fa-check"></i><b>8</b> Linear Regression - Application</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lin-a.html"><a href="lin-a.html#objectives-6"><i class="fa fa-check"></i><b>8.1</b> Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="lin-a.html"><a href="lin-a.html#r-functions-covered-this-week-1"><i class="fa fa-check"></i><b>8.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="8.3" data-path="lin-a.html"><a href="lin-a.html#research-question"><i class="fa fa-check"></i><b>8.3</b> Research question</a></li>
<li class="chapter" data-level="8.4" data-path="lin-a.html"><a href="lin-a.html#simple-linear-regression-in-r"><i class="fa fa-check"></i><b>8.4</b> Simple linear regression in R</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="lin-a.html"><a href="lin-a.html#interpretation"><i class="fa fa-check"></i><b>8.4.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lin-a.html"><a href="lin-a.html#multiple-linear-regression-in-r"><i class="fa fa-check"></i><b>8.5</b> Multiple linear regression in R</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="lin-a.html"><a href="lin-a.html#interpretation-1"><i class="fa fa-check"></i><b>8.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="8.5.2" data-path="lin-a.html"><a href="lin-a.html#sidenote-adding-interactions"><i class="fa fa-check"></i><b>8.5.2</b> Sidenote: Adding interactions</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lin-a.html"><a href="lin-a.html#regression-diagnostics-1"><i class="fa fa-check"></i><b>8.6</b> Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="lin-a.html"><a href="lin-a.html#skewed-outcome-variable"><i class="fa fa-check"></i><b>8.6.1</b> Skewed outcome variable</a></li>
<li class="chapter" data-level="8.6.2" data-path="lin-a.html"><a href="lin-a.html#non-linearity"><i class="fa fa-check"></i><b>8.6.2</b> Non-linearity</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="lin-a.html"><a href="lin-a.html#returning-to-our-research-question-2"><i class="fa fa-check"></i><b>8.7</b> Returning to our research question</a></li>
<li class="chapter" data-level="8.8" data-path="lin-a.html"><a href="lin-a.html#moving-on-2"><i class="fa fa-check"></i><b>8.8</b> Moving on</a></li>
<li class="chapter" data-level="8.9" data-path="lin-a.html"><a href="lin-a.html#further-resources-4"><i class="fa fa-check"></i><b>8.9</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lin-e.html"><a href="lin-e.html"><i class="fa fa-check"></i><b>9</b> Linear Regression - Exercises</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lin-e.html"><a href="lin-e.html#exercises"><i class="fa fa-check"></i><b>9.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="med.html"><a href="med.html"><i class="fa fa-check"></i><b>10</b> Mediation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="med.html"><a href="med.html#objectives-7"><i class="fa fa-check"></i><b>10.1</b> Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="med.html"><a href="med.html#r-functions-covered-this-week-2"><i class="fa fa-check"></i><b>10.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="10.3" data-path="med.html"><a href="med.html#further-resources-5"><i class="fa fa-check"></i><b>10.3</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pm-t.html"><a href="pm-t.html"><i class="fa fa-check"></i><b>11</b> Prediction - Theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pm-t.html"><a href="pm-t.html#objectives-8"><i class="fa fa-check"></i><b>11.1</b> Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="pm-t.html"><a href="pm-t.html#r-functions-covered-this-week-3"><i class="fa fa-check"></i><b>11.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="11.3" data-path="pm-t.html"><a href="pm-t.html#how-prediction-works"><i class="fa fa-check"></i><b>11.3</b> How prediction works</a></li>
<li class="chapter" data-level="11.4" data-path="pm-t.html"><a href="pm-t.html#intro-to-machine-learning"><i class="fa fa-check"></i><b>11.4</b> Intro to Machine learning</a></li>
<li class="chapter" data-level="11.5" data-path="pm-t.html"><a href="pm-t.html#further-resources-6"><i class="fa fa-check"></i><b>11.5</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pm-a.html"><a href="pm-a.html"><i class="fa fa-check"></i><b>12</b> Prediction - Application</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pm-a.html"><a href="pm-a.html#exercises-1"><i class="fa fa-check"></i><b>12.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="log-est.html"><a href="log-est.html"><i class="fa fa-check"></i><b>13</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="13.1" data-path="log-est.html"><a href="log-est.html#objectives-9"><i class="fa fa-check"></i><b>13.1</b> Objectives</a></li>
<li class="chapter" data-level="13.2" data-path="log-est.html"><a href="log-est.html#functions-covered-in-this-week"><i class="fa fa-check"></i><b>13.2</b> Functions covered in this week</a></li>
<li class="chapter" data-level="13.3" data-path="log-est.html"><a href="log-est.html#basic-concepts"><i class="fa fa-check"></i><b>13.3</b> Basic concepts</a></li>
<li class="chapter" data-level="13.4" data-path="log-est.html"><a href="log-est.html#application"><i class="fa fa-check"></i><b>13.4</b> Application</a></li>
<li class="chapter" data-level="13.5" data-path="log-est.html"><a href="log-est.html#interpretation-2"><i class="fa fa-check"></i><b>13.5</b> Interpretation</a></li>
<li class="chapter" data-level="13.6" data-path="log-est.html"><a href="log-est.html#model-fit-1"><i class="fa fa-check"></i><b>13.6</b> model fit</a></li>
<li class="chapter" data-level="13.7" data-path="log-est.html"><a href="log-est.html#diagnostics"><i class="fa fa-check"></i><b>13.7</b> diagnostics</a></li>
<li class="chapter" data-level="13.8" data-path="log-est.html"><a href="log-est.html#prediction"><i class="fa fa-check"></i><b>13.8</b> prediction</a></li>
<li class="chapter" data-level="13.9" data-path="log-est.html"><a href="log-est.html#mediation-1"><i class="fa fa-check"></i><b>13.9</b> Mediation</a></li>
<li class="chapter" data-level="13.10" data-path="log-est.html"><a href="log-est.html#comparing-linear-and-logistic-regression"><i class="fa fa-check"></i><b>13.10</b> comparing linear and logistic regression</a></li>
<li class="chapter" data-level="13.11" data-path="log-est.html"><a href="log-est.html#logistic-regression-in-machine-learning-context"><i class="fa fa-check"></i><b>13.11</b> logistic regression in Machine Learning context</a></li>
<li class="chapter" data-level="13.12" data-path="log-est.html"><a href="log-est.html#further-resources-7"><i class="fa fa-check"></i><b>13.12</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="out-look.html"><a href="out-look.html"><i class="fa fa-check"></i><b>14</b> Outlook</a>
<ul>
<li class="chapter" data-level="14.1" data-path="out-look.html"><a href="out-look.html#summary-of-what-was-covered-in-course"><i class="fa fa-check"></i><b>14.1</b> Summary of what was covered in course</a></li>
<li class="chapter" data-level="14.2" data-path="out-look.html"><a href="out-look.html#other-outcome-variables"><i class="fa fa-check"></i><b>14.2</b> Other outcome variables</a></li>
<li class="chapter" data-level="14.3" data-path="out-look.html"><a href="out-look.html#data-structures"><i class="fa fa-check"></i><b>14.3</b> Data structures</a></li>
<li class="chapter" data-level="14.4" data-path="out-look.html"><a href="out-look.html#where-to-go-next"><i class="fa fa-check"></i><b>14.4</b> Where to go next</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis with R for Social Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="log-est" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number"> 13</span> Logistic regression<a href="log-est.html#log-est" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objectives-9" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Objectives<a href="log-est.html#objectives-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="objectives">
<ul>
<li>here to be filled</li>
</ul>
</div>
</div>
<div id="functions-covered-in-this-week" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Functions covered in this week<a href="log-est.html#functions-covered-in-this-week" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="functions">
<ul>
<li><code>glm()</code> : This function is used to fit a generalized linear model to the data. It takes a formula that specifies the dependent and independent variables, a data frame that contains the variables, and a family argument that specifies the type of model, such as binomial for logistic regression. It returns a model object that can be used for further analysis.</li>
<li><code>summary()</code> : This function is used to get a summary of a model object, such as the coefficients, standard errors, z-values, p-values, deviance, and AIC. It also provides information on the residuals, such as the minimum, maximum, median, and quartiles.</li>
<li><code>exp()</code> : This function is used to compute the exponential function of a numeric vector. It can be used to convert the log odds coefficients from a logistic regression into odds ratios.</li>
<li><code>tidy()</code> : This function is from the <strong>broom</strong> package. It is used to convert a model object into a tidy tibble that contains one row per parameter estimate and columns for the term, estimate, standard error, statistic, and p-value. It also has an argument to exponentiate the coefficients for logistic regression models.</li>
<li><code>glance()</code> : This function is from the <strong>broom</strong> package. It is used to get a summary of a model object, such as the deviance, AIC, BIC, pseudo R-squared, etc. It takes a model object and returns a tibble with one row per model and one column per statistic.</li>
<li><code>augment()</code> : This function is from the <strong>broom</strong> package. It is used to add columns with predictions, residuals, and other information to the original data frame. It takes a model object and an optional new data frame for prediction. It returns a tibble with one row per observation and one column per variable or statistic.</li>
<li><code>ggplot()</code> : This function is from the <strong>ggplot2</strong> package. It is used to create a wide variety of static, dynamic, and interactive graphics in R. The function allows you to specify a mapping from data to aesthetics (color, shape, size) and geometric objects (points, lines, bars). It also allows you to add statistical transformations, coordinate systems, faceting, and themes.</li>
<li><code>geom_count()</code> : This function is from the <strong>ggplot2</strong> package. It is used to create plots that show the number of observations at each combination of x and y values. It takes a mapping from data to aesthetics and other arguments that control the appearance of the points, such as color, size, alpha, etc. It returns a layer that can be added to a ggplot object.</li>
<li><code>stat_smooth()</code> : This function is from the <strong>ggplot2</strong> package. It is used to add a smoothed conditional mean or regression line to a plot. It takes a mapping from data to aesthetics and other arguments that control the appearance of the line or curve, such as method, formula, color, linetype, etc. It returns a layer that can be added to a ggplot object.</li>
<li><code>theme_minimal()</code> : This function is from the <strong>ggplot2</strong> package. It is used to apply a minimal theme to a plot. It takes no arguments and returns a theme object that can be added to a ggplot object.</li>
<li><code>margins()</code> : This function is from the <strong>margins</strong> package. It is used to compute marginal effects for various types of models in R. It takes a model object and other arguments that specify the variables of interest, the type of marginal effects (response or link), etc. It returns an object that contains the average marginal effects and their standard errors for each variable.</li>
<li><code>summary.margins()</code> : This function is from the <strong>margins</strong> package. It is used to get a summary of an object returned by <code>margins()</code>. It takes an object of class margins and other arguments that control the confidence intervals and p-values for marginal effects. It prints out a summary table of marginal effects.</li>
<li><code>model_performance()</code> : This function is from the <strong>performance</strong> package. It is used to get various indices of model performance for different types of models in R. It takes a model object and other arguments that specify which indices to include or exclude. It returns an object that contains indices such as AIC, BIC, pseudo R-squared, RMSE, log loss etc.</li>
<li><code>r2_mcfadden()</code> : This function is from the <strong>performance</strong> package. It is used to compute McFadden’s pseudo R-squared for generalized linear models in R. It takes a model object and returns an object that contains McFadden’s R-squared and adjusted R-squared values.</li>
<li><code>compare_performance()</code> : This function is from the <strong>performance</strong> package. It is used to compare multiple models based on their performance indices in R. It takes one or more model objects and other arguments that specify which indices to include or exclude. It returns an object that contains a table that shows the performance indices and their relative weights for each model.</li>
<li><code>check_model()</code> : This function is from the <strong>performance</strong> package. It is used to check the model assumptions and perform diagnostics for different types of models in R. It takes a model object and other arguments that specify which checks to perform or exclude. It returns an object that contains a list of diagnostic plots and tests for the model.</li>
<li><code>createDataPartition()</code> : This function is from the <strong>caret</strong> package. It is used to create a random split of the data into training and testing sets. It takes a vector of outcomes, a proportion of data to be assigned to the training set, and an option to return a list or not. It returns a vector or list of indices for the training set.</li>
<li><code>train()</code> : This function is from the <strong>caret</strong> package. It is used to train a predictive model using different methods and tuning parameters. It takes a formula that specifies the dependent and independent variables, a data frame that contains the training data, a method that specifies the type of model, and a train control object that specifies how to train the model. It returns a model object that can be used for prediction and evaluation.</li>
<li><code>trainControl()</code> : This function is from the <strong>caret</strong> package. It is used to create a train control object that controls how the model is trained. It takes various arguments that specify the resampling method, the number of resamples, the selection metric, etc. It returns a train control object that can be passed to <code>train()</code>.</li>
<li><code>predict()</code> : This function is used to make predictions from a fitted model object. It takes a model object and a new data frame that contains the values of the independent variables for which predictions are desired. It returns a vector of predicted values for the dependent variable.</li>
<li><code>ggpredict()</code> : This function is from the <strong>ggeffects</strong> package. It is used to create predicted values and confidence intervals for different types of models in R. It takes a model object and one or more terms that specify which variables to predict for. It returns an object that contains predicted values and confidence intervals for each level of the terms.</li>
<li><code>library()</code> : This function is used to load an installed package into R session so that its functions can be used. It takes one or more package names as arguments and loads them into memory.</li>
</ul>
</div>
</div>
<div id="basic-concepts" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Basic concepts<a href="log-est.html#basic-concepts" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Logistic regression is similar to linear regression. The main difference is that
it can perform better for binary variables (i.e. 0 vs. 1). Binary outcomes have
only two levels. Linear regression is used to model continuous variables such as the number of points scored in an NBA game. A binary outcome would be the sex of the player (male vs. female) or the maybe the health status (injured vs. not injured).</p>
<p>Logistic regression and linear regression are both part of the family of
generalized linear regression models (including also Poisson regression, ridge, lasso etc.).
Logistic regression and linear regression share some of the same assumptions, such
as linearity, outliers and multicollienarity.However, under the hood, logistic
regression uses a different estimation method.</p>
<p>Rather than fitting a straight line through data points as in linear regression,
logistic regression fits a “s-shaped” line through data points. Coefficients in
the logistic model are interepreted as the probability of being category 1 or 0.</p>
<div class="float">
<img src="linear-vs-logistic.png" alt="Scatterplot with striaght line and s-shaped line." />
<div class="figcaption"><strong>Scatterplot with striaght line and s-shaped line.</strong></div>
</div>
<p>Linear regression uses ordinary least squares as estimation method (i.e. using the distance from each observation to the regression line). Logistic regression uses the “maximum likelihood function” to approximate the s-shape curve which best fits the data. It moves the s-curve left and right and
calculates for each observation the likelihood of being either 0 or 1 given the assumed distribution. Then we take the average of all likelihoods of observations. The best fitting
curve is the one with the largest likelihood (that’s why it is called “maximum likelihood function”).</p>
<p>See this <a href="https://www.youtube.com/watch?v=yIYKR4sgzI8&amp;list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe&amp;ab_channel=StatQuestwithJoshStarmer">youtube</a> playlist on logistic regression for more details.</p>
</div>
<div id="application" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Application<a href="log-est.html#application" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s apply logistic regression to our NBA data.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="log-est.html#cb170-1" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb170-2"><a href="log-est.html#cb170-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</span>
<span id="cb170-3"><a href="log-est.html#cb170-3" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;readxl&quot;</span>)</span>
<span id="cb170-4"><a href="log-est.html#cb170-4" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;lubridate&quot;</span>)</span>
<span id="cb170-5"><a href="log-est.html#cb170-5" tabindex="-1"></a></span>
<span id="cb170-6"><a href="log-est.html#cb170-6" tabindex="-1"></a><span class="co"># import data </span></span>
<span id="cb170-7"><a href="log-est.html#cb170-7" tabindex="-1"></a>nba_salaries <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;../datasets/nba/salaries_1985to2018.csv&quot;</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb170-8"><a href="log-est.html#cb170-8" tabindex="-1"></a>nba_players <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;../datasets/nba/players.csv&quot;</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb170-9"><a href="log-est.html#cb170-9" tabindex="-1"></a></span>
<span id="cb170-10"><a href="log-est.html#cb170-10" tabindex="-1"></a><span class="co"># merge</span></span>
<span id="cb170-11"><a href="log-est.html#cb170-11" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> <span class="fu">merge</span>(nba_players, nba_salaries, <span class="at">by.x =</span> <span class="fu">c</span>(<span class="st">&quot;_id&quot;</span>), <span class="at">by.y=</span><span class="fu">c</span>(<span class="st">&quot;player_id&quot;</span>))</span>
<span id="cb170-12"><a href="log-est.html#cb170-12" tabindex="-1"></a></span>
<span id="cb170-13"><a href="log-est.html#cb170-13" tabindex="-1"></a><span class="co"># clean</span></span>
<span id="cb170-14"><a href="log-est.html#cb170-14" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span></span>
<span id="cb170-15"><a href="log-est.html#cb170-15" tabindex="-1"></a>        dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">everything</span>(), <span class="sc">-</span>league, <span class="sc">-</span>highSchool) <span class="sc">%&gt;%</span></span>
<span id="cb170-16"><a href="log-est.html#cb170-16" tabindex="-1"></a>        <span class="fu">filter</span>(season_start<span class="sc">&gt;=</span><span class="dv">1998</span>) <span class="sc">%&gt;%</span></span>
<span id="cb170-17"><a href="log-est.html#cb170-17" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">year_of_birth =</span> <span class="fu">year</span>(<span class="fu">mdy</span>(birthDate)),</span>
<span id="cb170-18"><a href="log-est.html#cb170-18" tabindex="-1"></a>         <span class="at">age =</span> season_start <span class="sc">-</span> year_of_birth,</span>
<span id="cb170-19"><a href="log-est.html#cb170-19" tabindex="-1"></a>         <span class="at">position_center =</span> </span>
<span id="cb170-20"><a href="log-est.html#cb170-20" tabindex="-1"></a>      <span class="fu">case_when</span>(<span class="at">position =</span> <span class="fu">str_detect</span>(position,<span class="st">&quot;Center&quot;</span>) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb170-21"><a href="log-est.html#cb170-21" tabindex="-1"></a>                <span class="cn">TRUE</span> <span class="sc">~</span> <span class="dv">0</span>),</span>
<span id="cb170-22"><a href="log-est.html#cb170-22" tabindex="-1"></a>    <span class="at">position_sf =</span> </span>
<span id="cb170-23"><a href="log-est.html#cb170-23" tabindex="-1"></a>      <span class="fu">case_when</span>(<span class="at">position =</span> <span class="fu">str_detect</span>(position,<span class="st">&quot;Small Forward&quot;</span>) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb170-24"><a href="log-est.html#cb170-24" tabindex="-1"></a>                <span class="cn">TRUE</span> <span class="sc">~</span> <span class="dv">0</span>),</span>
<span id="cb170-25"><a href="log-est.html#cb170-25" tabindex="-1"></a>    <span class="at">position_pf =</span> </span>
<span id="cb170-26"><a href="log-est.html#cb170-26" tabindex="-1"></a>      <span class="fu">case_when</span>(<span class="at">position =</span> <span class="fu">str_detect</span>(position,<span class="st">&quot;Power Forward&quot;</span>) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb170-27"><a href="log-est.html#cb170-27" tabindex="-1"></a>                <span class="cn">TRUE</span> <span class="sc">~</span> <span class="dv">0</span>),</span>
<span id="cb170-28"><a href="log-est.html#cb170-28" tabindex="-1"></a>    <span class="at">position_sg =</span> </span>
<span id="cb170-29"><a href="log-est.html#cb170-29" tabindex="-1"></a>      <span class="fu">case_when</span>(<span class="at">position =</span> <span class="fu">str_detect</span>(position,<span class="st">&quot;Shooting Guard&quot;</span>) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb170-30"><a href="log-est.html#cb170-30" tabindex="-1"></a>                <span class="cn">TRUE</span> <span class="sc">~</span> <span class="dv">0</span>),</span>
<span id="cb170-31"><a href="log-est.html#cb170-31" tabindex="-1"></a>    <span class="at">position_pg =</span> </span>
<span id="cb170-32"><a href="log-est.html#cb170-32" tabindex="-1"></a>      <span class="fu">case_when</span>(<span class="at">position =</span> <span class="fu">str_detect</span>(position,<span class="st">&quot;Point Guard&quot;</span>) <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb170-33"><a href="log-est.html#cb170-33" tabindex="-1"></a>                <span class="cn">TRUE</span> <span class="sc">~</span> <span class="dv">0</span>),</span>
<span id="cb170-34"><a href="log-est.html#cb170-34" tabindex="-1"></a>    <span class="at">weight =</span> <span class="fu">str_replace</span>(weight, <span class="st">&quot;lb&quot;</span>, <span class="st">&quot;&quot;</span>),</span>
<span id="cb170-35"><a href="log-est.html#cb170-35" tabindex="-1"></a>         <span class="at">weight =</span> <span class="fu">as.numeric</span>(weight),</span>
<span id="cb170-36"><a href="log-est.html#cb170-36" tabindex="-1"></a>         <span class="at">height =</span> <span class="fu">str_replace</span>(height, <span class="st">&quot;-&quot;</span>, <span class="st">&quot;.&quot;</span>),</span>
<span id="cb170-37"><a href="log-est.html#cb170-37" tabindex="-1"></a>         <span class="at">height =</span> <span class="fu">as.numeric</span>(height),</span>
<span id="cb170-38"><a href="log-est.html#cb170-38" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb170-39"><a href="log-est.html#cb170-39" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">id =</span> <span class="st">&quot;_id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb170-40"><a href="log-est.html#cb170-40" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(id, name, age, weight, height, birthPlace, <span class="fu">everything</span>(), <span class="sc">-</span>position, <span class="sc">-</span>birthDate, <span class="sc">-</span>year_of_birth)</span>
<span id="cb170-41"><a href="log-est.html#cb170-41" tabindex="-1"></a></span>
<span id="cb170-42"><a href="log-est.html#cb170-42" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span></span>
<span id="cb170-43"><a href="log-est.html#cb170-43" tabindex="-1"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb170-44"><a href="log-est.html#cb170-44" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">seasons_played =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb170-45"><a href="log-est.html#cb170-45" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb170-46"><a href="log-est.html#cb170-46" tabindex="-1"></a><span class="fu">str</span>(data_nba)</span></code></pre></div>
<pre><code>## tibble [9,728 × 35] (S3: tbl_df/tbl/data.frame)
##  $ id             : chr [1:9728] &quot;abdulma02&quot; &quot;abdulta01&quot; &quot;abdulta01&quot; &quot;abdulta01&quot; ...
##  $ name           : chr [1:9728] &quot;Mahmoud Abdul-Rauf&quot; &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; ...
##  $ age            : num [1:9728] 31 24 25 26 27 28 29 30 31 32 ...
##  $ weight         : num [1:9728] 162 223 223 223 223 223 223 223 223 223 ...
##  $ height         : num [1:9728] 6.1 6.6 6.6 6.6 6.6 6.6 6.6 6.6 6.6 6.6 ...
##  $ birthPlace     : chr [1:9728] &quot;Gulfport, Mississippi&quot; &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; ...
##  $ index.x        : num [1:9728] 3 4 4 4 4 4 4 4 4 4 ...
##  $ career_AST     : num [1:9728] 3.5 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 ...
##  $ career_FG%     : chr [1:9728] &quot;44.2&quot; &quot;41.7&quot; &quot;41.7&quot; &quot;41.7&quot; ...
##  $ career_FG3%    : chr [1:9728] &quot;35.4&quot; &quot;23.7&quot; &quot;23.7&quot; &quot;23.7&quot; ...
##  $ career_FT%     : chr [1:9728] &quot;90.5&quot; &quot;70.3&quot; &quot;70.3&quot; &quot;70.3&quot; ...
##  $ career_G       : num [1:9728] 586 236 236 236 236 236 236 236 236 236 ...
##  $ career_PER     : chr [1:9728] &quot;15.4&quot; &quot;11.4&quot; &quot;11.4&quot; &quot;11.4&quot; ...
##  $ career_PTS     : num [1:9728] 14.6 7.8 7.8 7.8 7.8 7.8 7.8 7.8 7.8 7.8 ...
##  $ career_TRB     : chr [1:9728] &quot;1.9&quot; &quot;3.3&quot; &quot;3.3&quot; &quot;3.3&quot; ...
##  $ career_WS      : num [1:9728] 25.2 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 ...
##  $ career_eFG%    : chr [1:9728] &quot;47.2&quot; &quot;42.2&quot; &quot;42.2&quot; &quot;42.2&quot; ...
##  $ college        : chr [1:9728] &quot;Louisiana State University&quot; &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; ...
##  $ draft_pick     : chr [1:9728] &quot;3rd overall&quot; &quot;11th overall&quot; &quot;11th overall&quot; &quot;11th overall&quot; ...
##  $ draft_round    : chr [1:9728] &quot;1st round&quot; &quot;1st round&quot; &quot;1st round&quot; &quot;1st round&quot; ...
##  $ draft_team     : chr [1:9728] &quot;Denver Nuggets&quot; &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; ...
##  $ draft_year     : chr [1:9728] &quot;1990&quot; &quot;1997&quot; &quot;1997&quot; &quot;1997&quot; ...
##  $ shoots         : chr [1:9728] &quot;Right&quot; &quot;Right&quot; &quot;Right&quot; &quot;Right&quot; ...
##  $ index.y        : num [1:9728] 17 19 20 21 22 23 24 25 26 27 ...
##  $ salary         : num [1:9728] 798500 1411000 1594920 4500000 5062500 ...
##  $ season         : chr [1:9728] &quot;2000-01&quot; &quot;1998-99&quot; &quot;1999-00&quot; &quot;2000-01&quot; ...
##  $ season_end     : num [1:9728] 2001 1999 2000 2001 2002 ...
##  $ season_start   : num [1:9728] 2000 1998 1999 2000 2001 ...
##  $ team           : chr [1:9728] &quot;Vancouver Grizzlies&quot; &quot;Sacramento Kings&quot; &quot;Denver Nuggets&quot; &quot;Denver Nuggets&quot; ...
##  $ position_center: num [1:9728] 0 0 0 0 0 0 0 0 0 0 ...
##  $ position_sf    : num [1:9728] 0 0 0 0 0 0 0 0 0 0 ...
##  $ position_pf    : num [1:9728] 0 0 0 0 0 0 0 0 0 0 ...
##  $ position_sg    : num [1:9728] 0 1 1 1 1 1 1 1 1 1 ...
##  $ position_pg    : num [1:9728] 1 0 0 0 0 0 0 0 0 0 ...
##  $ seasons_played : int [1:9728] 1 9 9 9 9 9 9 9 9 9 ...</code></pre>
<p>First, let’s check out dataset for binary outcomes. Binary variables in R are
labelled as <em>factor</em> variables. Any categorical variable is a factor variable.
A binary variable is simply a categorical variable with two categories.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="log-est.html#cb172-1" tabindex="-1"></a><span class="fu">str</span>(data_nba)</span></code></pre></div>
<pre><code>## tibble [9,728 × 35] (S3: tbl_df/tbl/data.frame)
##  $ id             : chr [1:9728] &quot;abdulma02&quot; &quot;abdulta01&quot; &quot;abdulta01&quot; &quot;abdulta01&quot; ...
##  $ name           : chr [1:9728] &quot;Mahmoud Abdul-Rauf&quot; &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; ...
##  $ age            : num [1:9728] 31 24 25 26 27 28 29 30 31 32 ...
##  $ weight         : num [1:9728] 162 223 223 223 223 223 223 223 223 223 ...
##  $ height         : num [1:9728] 6.1 6.6 6.6 6.6 6.6 6.6 6.6 6.6 6.6 6.6 ...
##  $ birthPlace     : chr [1:9728] &quot;Gulfport, Mississippi&quot; &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; ...
##  $ index.x        : num [1:9728] 3 4 4 4 4 4 4 4 4 4 ...
##  $ career_AST     : num [1:9728] 3.5 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 ...
##  $ career_FG%     : chr [1:9728] &quot;44.2&quot; &quot;41.7&quot; &quot;41.7&quot; &quot;41.7&quot; ...
##  $ career_FG3%    : chr [1:9728] &quot;35.4&quot; &quot;23.7&quot; &quot;23.7&quot; &quot;23.7&quot; ...
##  $ career_FT%     : chr [1:9728] &quot;90.5&quot; &quot;70.3&quot; &quot;70.3&quot; &quot;70.3&quot; ...
##  $ career_G       : num [1:9728] 586 236 236 236 236 236 236 236 236 236 ...
##  $ career_PER     : chr [1:9728] &quot;15.4&quot; &quot;11.4&quot; &quot;11.4&quot; &quot;11.4&quot; ...
##  $ career_PTS     : num [1:9728] 14.6 7.8 7.8 7.8 7.8 7.8 7.8 7.8 7.8 7.8 ...
##  $ career_TRB     : chr [1:9728] &quot;1.9&quot; &quot;3.3&quot; &quot;3.3&quot; &quot;3.3&quot; ...
##  $ career_WS      : num [1:9728] 25.2 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 ...
##  $ career_eFG%    : chr [1:9728] &quot;47.2&quot; &quot;42.2&quot; &quot;42.2&quot; &quot;42.2&quot; ...
##  $ college        : chr [1:9728] &quot;Louisiana State University&quot; &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; ...
##  $ draft_pick     : chr [1:9728] &quot;3rd overall&quot; &quot;11th overall&quot; &quot;11th overall&quot; &quot;11th overall&quot; ...
##  $ draft_round    : chr [1:9728] &quot;1st round&quot; &quot;1st round&quot; &quot;1st round&quot; &quot;1st round&quot; ...
##  $ draft_team     : chr [1:9728] &quot;Denver Nuggets&quot; &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; ...
##  $ draft_year     : chr [1:9728] &quot;1990&quot; &quot;1997&quot; &quot;1997&quot; &quot;1997&quot; ...
##  $ shoots         : chr [1:9728] &quot;Right&quot; &quot;Right&quot; &quot;Right&quot; &quot;Right&quot; ...
##  $ index.y        : num [1:9728] 17 19 20 21 22 23 24 25 26 27 ...
##  $ salary         : num [1:9728] 798500 1411000 1594920 4500000 5062500 ...
##  $ season         : chr [1:9728] &quot;2000-01&quot; &quot;1998-99&quot; &quot;1999-00&quot; &quot;2000-01&quot; ...
##  $ season_end     : num [1:9728] 2001 1999 2000 2001 2002 ...
##  $ season_start   : num [1:9728] 2000 1998 1999 2000 2001 ...
##  $ team           : chr [1:9728] &quot;Vancouver Grizzlies&quot; &quot;Sacramento Kings&quot; &quot;Denver Nuggets&quot; &quot;Denver Nuggets&quot; ...
##  $ position_center: num [1:9728] 0 0 0 0 0 0 0 0 0 0 ...
##  $ position_sf    : num [1:9728] 0 0 0 0 0 0 0 0 0 0 ...
##  $ position_pf    : num [1:9728] 0 0 0 0 0 0 0 0 0 0 ...
##  $ position_sg    : num [1:9728] 0 1 1 1 1 1 1 1 1 1 ...
##  $ position_pg    : num [1:9728] 1 0 0 0 0 0 0 0 0 0 ...
##  $ seasons_played : int [1:9728] 1 9 9 9 9 9 9 9 9 9 ...</code></pre>
<p>We see that there are no <em>factor</em> variables currently in the dataset. However,
there are a few variables that should be marked as factors which currently
aren’t, such as birth place, college, draft team, and the shooting hand (left/right hand).
If we want to use any of these variables in a regression, we need to convert them.
Currently they are marked as “character” variables.</p>
<p>Let’s assume we are interested in knowing how long a player plays in the NBA
measured by the number of seasons he played. It could be very useful for teams to predict
how long players will last.</p>
<p>Let’s first look at that variable, dichotomize it (turning it into 0 vs. 1), and
then explore it’s distribution.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="log-est.html#cb174-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ggeffects&quot;</span>)</span>
<span id="cb174-2"><a href="log-est.html#cb174-2" tabindex="-1"></a><span class="co"># check distribution of original variable</span></span>
<span id="cb174-3"><a href="log-est.html#cb174-3" tabindex="-1"></a><span class="fu">summary</span>(data_nba<span class="sc">$</span>seasons_played) </span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.000   5.000   9.000   8.758  12.000  21.000</code></pre>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="log-est.html#cb176-1" tabindex="-1"></a><span class="co"># dichotomize</span></span>
<span id="cb176-2"><a href="log-est.html#cb176-2" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span></span>
<span id="cb176-3"><a href="log-est.html#cb176-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">career_long =</span> </span>
<span id="cb176-4"><a href="log-est.html#cb176-4" tabindex="-1"></a>           <span class="fu">case_when</span>(seasons_played<span class="sc">&gt;</span><span class="dv">12</span> <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb176-5"><a href="log-est.html#cb176-5" tabindex="-1"></a>                     seasons_played<span class="sc">&lt;=</span><span class="dv">12</span> <span class="sc">~</span> <span class="dv">0</span>,</span>
<span id="cb176-6"><a href="log-est.html#cb176-6" tabindex="-1"></a>                     <span class="cn">TRUE</span> <span class="sc">~</span> <span class="cn">NA_real_</span>),</span>
<span id="cb176-7"><a href="log-est.html#cb176-7" tabindex="-1"></a>         <span class="at">career_long =</span> <span class="fu">as.factor</span>(career_long))</span>
<span id="cb176-8"><a href="log-est.html#cb176-8" tabindex="-1"></a></span>
<span id="cb176-9"><a href="log-est.html#cb176-9" tabindex="-1"></a><span class="fu">table</span>(data_nba<span class="sc">$</span>career_long)</span></code></pre></div>
<pre><code>## 
##    0    1 
## 7499 2229</code></pre>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="log-est.html#cb178-1" tabindex="-1"></a>data_nba <span class="sc">%&gt;%</span></span>
<span id="cb178-2"><a href="log-est.html#cb178-2" tabindex="-1"></a>  <span class="fu">filter</span>(team <span class="sc">==</span><span class="st">&quot;Dallas Mavericks&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb178-3"><a href="log-est.html#cb178-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span> seasons_played, <span class="at">y=</span>career_long)) <span class="sc">+</span></span>
<span id="cb178-4"><a href="log-est.html#cb178-4" tabindex="-1"></a>  <span class="fu">geom_count</span>() <span class="sc">+</span></span>
<span id="cb178-5"><a href="log-est.html#cb178-5" tabindex="-1"></a>  <span class="co"># stat_smooth(method=&quot;glm&quot;,</span></span>
<span id="cb178-6"><a href="log-est.html#cb178-6" tabindex="-1"></a>  <span class="co">#              se=FALSE, </span></span>
<span id="cb178-7"><a href="log-est.html#cb178-7" tabindex="-1"></a>  <span class="co">#              method.args = list(family=binomial),</span></span>
<span id="cb178-8"><a href="log-est.html#cb178-8" tabindex="-1"></a>  <span class="co">#              formula= aes(career_long ~ seasons_played)) +</span></span>
<span id="cb178-9"><a href="log-est.html#cb178-9" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/log_1-1.png" width="672" /></p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="log-est.html#cb179-1" tabindex="-1"></a><span class="co"># NIAZ - plot below should show the logistic regression curve, but doesnt work</span></span>
<span id="cb179-2"><a href="log-est.html#cb179-2" tabindex="-1"></a><span class="co"># Reason: Insufficient unique x values: the variable seasons_played has insufficient unique values to support the smoothing method or they fall in one line</span></span></code></pre></div>
<p>The plot above shows the number of players for the Dallas Mavericks by career length
and seasons played. The size of the bubble represents the number of players in that
category.</p>
<p>Now, let’s estimate a model explaining whether a player has a long career or not.
Let’s include weight and height as independent variables</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="log-est.html#cb180-1" tabindex="-1"></a>model_logit1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(career_long <span class="sc">~</span> height <span class="sc">+</span> weight,</span>
<span id="cb180-2"><a href="log-est.html#cb180-2" tabindex="-1"></a>                    <span class="at">data =</span> data_nba,</span>
<span id="cb180-3"><a href="log-est.html#cb180-3" tabindex="-1"></a>                    <span class="at">family =</span> binomial)</span>
<span id="cb180-4"><a href="log-est.html#cb180-4" tabindex="-1"></a></span>
<span id="cb180-5"><a href="log-est.html#cb180-5" tabindex="-1"></a><span class="fu">summary</span>(model_logit1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = career_long ~ height + weight, family = binomial, 
##     data = data_nba)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9313  -0.7363  -0.6959  -0.6540   1.8572  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.3636355  0.4126623  -3.304 0.000952 ***
## height      -0.1663504  0.0684373  -2.431 0.015070 *  
## weight       0.0055569  0.0009376   5.927 3.09e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 10472  on 9727  degrees of freedom
## Residual deviance: 10437  on 9725  degrees of freedom
## AIC: 10443
## 
## Number of Fisher Scoring iterations: 4</code></pre>
</div>
<div id="interpretation-2" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Interpretation<a href="log-est.html#interpretation-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The interpretation of coefficients in a logistic regression is different from
the linear model. In a linear model, coefficients are interpreted as the increase
on the y-scale for one unit increase in x. For logistic regression, coefficients
relate to the increase or decrease of the probability (measured in log odds) that
y= 1 for a one unit increase x.</p>
<p>In the output above, we see that the coefficient for height is -0.16. This means
that for every inch (~ ca. 2.5 cm) in height, the probability of having a long career
is 0.16 log odds lower. This suggests that taller people have shorter NBA careers.</p>
<p>In practice no one interprets the effect size in log odds. In the standard logistic
regression model, we only look at the p-value to see if the effect is statistically
significant and we look at the sign in front of the coefficient to check whether
the effect is positive or negative.</p>
<p>A more meaningful way to interpret effects are odds ratios. Log odds can be
converted using the following approach.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="log-est.html#cb182-1" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(model_logit1))</span></code></pre></div>
<pre><code>## (Intercept)      height      weight 
##   0.2557294   0.8467494   1.0055724</code></pre>
<p>Now, the effect of height is 0.84. This means that the probability of a long career
is 0.85 times higher for taller people than for smaller people. If the odds ratio
is 1, the probability would be the same. If it is 2, the probability would be twice
as high. If it is lower than 1, it means that the probability is lower and that
the effect is negative.</p>
<p>There is an alternative <code>tidyverse</code> way to get odds ratios using the <code>broom()</code> package.
It neatly converts the output into a table which makes it easier to graph later.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="log-est.html#cb184-1" tabindex="-1"></a>model_logit1 <span class="sc">%&gt;%</span> </span>
<span id="cb184-2"><a href="log-est.html#cb184-2" tabindex="-1"></a>      broom<span class="sc">::</span><span class="fu">tidy</span>(<span class="at">exp =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 5
##   term        estimate std.error statistic       p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 (Intercept)    0.256  0.413        -3.30 0.000952     
## 2 height         0.847  0.0684       -2.43 0.0151       
## 3 weight         1.01   0.000938      5.93 0.00000000309</code></pre>
<p>More recently, it has become more common to convert the coefficients into probabilities.
There are various packages and various options and no clear agreement on what is
the preferred output.</p>
<p>Documentation for the <code>ggeffects</code> <a href="https://strengejacke.github.io/ggeffects/index.html">package</a> and the <code>margins</code> <a href="https://thomasleeper.com/margins/">package</a> capture this discussion in detail. In the following, we will show you how to get Average Marginal Effects
and Average Predicted Probabilities.</p>
<p>The interpretation of Average Marginal Effects (AMEs) is more intuitive than log odds
or odd ratios. AMEs are the average change in probability of y occurring for each unit increase
in x.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="log-est.html#cb186-1" tabindex="-1"></a><span class="co"># get average predicted probabilities for each level of &quot;height&quot;</span></span>
<span id="cb186-2"><a href="log-est.html#cb186-2" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">augment</span>(model_logit1, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb186-3"><a href="log-est.html#cb186-3" tabindex="-1"></a>  <span class="fu">group_by</span>(height) <span class="sc">%&gt;%</span></span>
<span id="cb186-4"><a href="log-est.html#cb186-4" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean_fitted =</span> <span class="fu">mean</span>(.fitted, <span class="at">rm.na=</span>T))</span>
<span id="cb186-5"><a href="log-est.html#cb186-5" tabindex="-1"></a></span>
<span id="cb186-6"><a href="log-est.html#cb186-6" tabindex="-1"></a><span class="co"># same as above, just using &quot;ggpredict&quot;</span></span>
<span id="cb186-7"><a href="log-est.html#cb186-7" tabindex="-1"></a><span class="co">#install.packages(&quot;ggeffects&quot;)</span></span>
<span id="cb186-8"><a href="log-est.html#cb186-8" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ggeffects&quot;</span>)</span>
<span id="cb186-9"><a href="log-est.html#cb186-9" tabindex="-1"></a><span class="fu">ggpredict</span>(model_logit1, <span class="st">&quot;height&quot;</span>)</span></code></pre></div>
<pre><code>## # Predicted probabilities of career_long
## 
## height | Predicted |       95% CI
## ---------------------------------
##   5.00 |      0.28 | [0.24, 0.32]
##   5.40 |      0.26 | [0.23, 0.29]
##   5.60 |      0.26 | [0.23, 0.28]
##   6.00 |      0.24 | [0.23, 0.26]
##   6.40 |      0.23 | [0.22, 0.24]
##   6.80 |      0.22 | [0.21, 0.23]
##   7.20 |      0.21 | [0.19, 0.23]
##   7.80 |      0.19 | [0.17, 0.22]
## 
## Adjusted for:
## * weight = 220.90</code></pre>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="log-est.html#cb188-1" tabindex="-1"></a><span class="co"># ggpredict</span></span>
<span id="cb188-2"><a href="log-est.html#cb188-2" tabindex="-1"></a><span class="co">#install.packages(&quot;ggeffects&quot;)</span></span>
<span id="cb188-3"><a href="log-est.html#cb188-3" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ggeffects&quot;</span>)</span>
<span id="cb188-4"><a href="log-est.html#cb188-4" tabindex="-1"></a><span class="fu">ggpredict</span>(model_logit1, <span class="st">&quot;height&quot;</span>)</span></code></pre></div>
<pre><code>## # Predicted probabilities of career_long
## 
## height | Predicted |       95% CI
## ---------------------------------
##   5.00 |      0.28 | [0.24, 0.32]
##   5.40 |      0.26 | [0.23, 0.29]
##   5.60 |      0.26 | [0.23, 0.28]
##   6.00 |      0.24 | [0.23, 0.26]
##   6.40 |      0.23 | [0.22, 0.24]
##   6.80 |      0.22 | [0.21, 0.23]
##   7.20 |      0.21 | [0.19, 0.23]
##   7.80 |      0.19 | [0.17, 0.22]
## 
## Adjusted for:
## * weight = 220.90</code></pre>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="log-est.html#cb190-1" tabindex="-1"></a><span class="co"># get Average marginal effects</span></span>
<span id="cb190-2"><a href="log-est.html#cb190-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;margins&quot;</span>)</span>
<span id="cb190-3"><a href="log-est.html#cb190-3" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;broom&quot;</span>)</span>
<span id="cb190-4"><a href="log-est.html#cb190-4" tabindex="-1"></a></span>
<span id="cb190-5"><a href="log-est.html#cb190-5" tabindex="-1"></a><span class="co"># Average Marginal Effects - for all model variables</span></span>
<span id="cb190-6"><a href="log-est.html#cb190-6" tabindex="-1"></a><span class="fu">margins</span>(model_logit1, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##    height    weight
##  -0.02928 0.0009779</code></pre>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="log-est.html#cb192-1" tabindex="-1"></a><span class="co"># Only for some</span></span>
<span id="cb192-2"><a href="log-est.html#cb192-2" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">margins</span>(model_logit1, <span class="at">variables =</span> <span class="st">&quot;height&quot;</span>))</span></code></pre></div>
<pre><code>##  factor     AME     SE       z      p   lower   upper
##  height -0.0293 0.0120 -2.4326 0.0150 -0.0529 -0.0057</code></pre>
<p>The AME for height is -0.029. This means that for every additional inch in height,
the NBA players are ~ 3 percentage points less likely to have a long career.</p>
</div>
<div id="model-fit-1" class="section level2 hasAnchor" number="13.6">
<h2><span class="header-section-number">13.6</span> model fit<a href="log-est.html#model-fit-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As we have seen with linear regression, there are different ways to assess whether a model is actually “good”. For linear regression, a popular measure is the R-squared which reports the “percentage of variance in y which is explained by the model”.
For logistic regression, there is no consensus on what the best measure is. There are dozens of different ways to calculate different r-squares. It’s complicated. See <a href="https://www.youtube.com/watch?v=xxFYro8QuXA&amp;ab_channel=StatQuestwithJoshStarmer">here</a> for more in-depth technical discussion.</p>
<p>One way to get model performance measures is the <code>performance</code> package. One r2
that is often recommended is the McFadden pseudo r2. This measure should not
be interpreted as “percentage of variance” explained. It is useful as a relative
tool. Larger values are better than smaller values.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="log-est.html#cb194-1" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">model_performance</span>(model_logit1)</span></code></pre></div>
<pre><code>## # Indices of model performance
## 
## AIC       |      AICc |       BIC | Tjur&#39;s R2 |  RMSE | Sigma | Log_loss | Score_log |   PCP
## --------------------------------------------------------------------------------------------
## 10442.919 | 10442.921 | 10464.467 |     0.004 | 0.420 | 1.036 |    0.536 |      -Inf | 0.648</code></pre>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="log-est.html#cb196-1" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">r2_mcfadden</span>(model_logit1)</span></code></pre></div>
<pre><code>## # R2 for Generalized Linear Regression
##        R2: 0.003
##   adj. R2: 0.003</code></pre>
<p>Let’s add some variables to our model:</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="log-est.html#cb198-1" tabindex="-1"></a>model_logit2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(career_long <span class="sc">~</span> height <span class="sc">+</span> weight <span class="sc">+</span> position_center <span class="sc">+</span> position_pg <span class="sc">+</span></span>
<span id="cb198-2"><a href="log-est.html#cb198-2" tabindex="-1"></a>                      season_start,</span>
<span id="cb198-3"><a href="log-est.html#cb198-3" tabindex="-1"></a>                    <span class="at">data =</span> data_nba,</span>
<span id="cb198-4"><a href="log-est.html#cb198-4" tabindex="-1"></a>                    <span class="at">family =</span> binomial)</span></code></pre></div>
<p>Now, let’s compare models</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="log-est.html#cb199-1" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">r2_mcfadden</span>(model_logit1)</span></code></pre></div>
<pre><code>## # R2 for Generalized Linear Regression
##        R2: 0.003
##   adj. R2: 0.003</code></pre>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="log-est.html#cb201-1" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">r2_mcfadden</span>(model_logit2)</span></code></pre></div>
<pre><code>## # R2 for Generalized Linear Regression
##        R2: 0.007
##   adj. R2: 0.007</code></pre>
<p>As we can see, the second model has a larger pseudo r2 and this can be considered the better model.</p>
<p>Another way to compare models is the performance package:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="log-est.html#cb203-1" tabindex="-1"></a>performance<span class="sc">::</span><span class="fu">compare_performance</span>(model_logit1, model_logit2)</span></code></pre></div>
<pre><code>## # Comparison of Model Performance Indices
## 
## Name         | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) | Tjur&#39;s R2 |  RMSE | Sigma | Log_loss | Score_log |   PCP | Score_spherical
## -------------------------------------------------------------------------------------------------------------------------------------------------------
## model_logit1 |   glm | 10442.9 (&lt;.001) | 10442.9 (&lt;.001) | 10464.5 (&lt;.001) |     0.004 | 0.420 | 1.036 |    0.536 |      -Inf | 0.648 |                
## model_logit2 |   glm | 10405.8 (&gt;.999) | 10405.8 (&gt;.999) | 10448.9 (&gt;.999) |     0.008 | 0.419 | 1.034 |    0.534 |      -Inf | 0.649 |       1.322e-04</code></pre>
</div>
<div id="diagnostics" class="section level2 hasAnchor" number="13.7">
<h2><span class="header-section-number">13.7</span> diagnostics<a href="log-est.html#diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Testing model assumptions and performing diagnostics is trickier for logistic regression compared to linear regression. Many diagnostics revolve around analyzing residuals (difference between predictions and actual values). In the context of logistic regression, given that the predicted values are probabilities and the actual values are either 0 and 1, it is not very clear what residuals mean.</p>
<p>We won’t cover diagnostic tests for logistic regression here, mainly to save time. A deeper dive into diagnostics can be found <a href="http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/">here</a>. A more recent package used in machine learning, called “performance” can also be used for diagnostics using the <code>check_model</code> function.</p>
</div>
<div id="prediction" class="section level2 hasAnchor" number="13.8">
<h2><span class="header-section-number">13.8</span> prediction<a href="log-est.html#prediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Predicting outcomes based on logistic regression was already covered above because predicted probabilities are an easier way of interpreting coefficients.</p>
<p>Here, let’s predict whether certain “fake” players
will have a long career or a shorter career based on our model.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="log-est.html#cb205-1" tabindex="-1"></a><span class="co">#define new observation</span></span>
<span id="cb205-2"><a href="log-est.html#cb205-2" tabindex="-1"></a>newdata <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">height=</span><span class="fu">c</span>(<span class="fl">5.0</span>, <span class="fl">8.0</span>),</span>
<span id="cb205-3"><a href="log-est.html#cb205-3" tabindex="-1"></a>                     <span class="at">weight=</span><span class="fu">c</span>(<span class="fu">mean</span>(data_nba<span class="sc">$</span>weight),</span>
<span id="cb205-4"><a href="log-est.html#cb205-4" tabindex="-1"></a>                              <span class="fu">mean</span>(data_nba<span class="sc">$</span>weight)))</span>
<span id="cb205-5"><a href="log-est.html#cb205-5" tabindex="-1"></a></span>
<span id="cb205-6"><a href="log-est.html#cb205-6" tabindex="-1"></a></span>
<span id="cb205-7"><a href="log-est.html#cb205-7" tabindex="-1"></a><span class="co">#use model to predict value of am</span></span>
<span id="cb205-8"><a href="log-est.html#cb205-8" tabindex="-1"></a><span class="fu">predict</span>(model_logit1, newdata, <span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##         1         2 
## 0.2753049 0.1874108</code></pre>
<p>The results above show that a very short player (5 feet) has a 27% probability of having a long career, whereas a very tall (8 feet) player only has a 18% probability of having a long career. Maybe taller people get injured more.</p>
</div>
<div id="mediation-1" class="section level2 hasAnchor" number="13.9">
<h2><span class="header-section-number">13.9</span> Mediation<a href="log-est.html#mediation-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Remember week X when we discussed mediation analysis based on linear regression?
Mediation is also possible for logistic regression, however, it is more complicated.
There are dedicated packages that help users apply mediation analysis following
<code>glm(models)</code> such as the <code>khb</code> package.</p>
</div>
<div id="comparing-linear-and-logistic-regression" class="section level2 hasAnchor" number="13.10">
<h2><span class="header-section-number">13.10</span> comparing linear and logistic regression<a href="log-est.html#comparing-linear-and-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As we have seen above, logistic regression can cause many headaches because
assessing the model fit, testing diagnostics, prediction and diagnostics are
all very complicated to perform and interpret.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="log-est.html#cb207-1" tabindex="-1"></a><span class="co"># logistic regression</span></span>
<span id="cb207-2"><a href="log-est.html#cb207-2" tabindex="-1"></a>model_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(career_long <span class="sc">~</span> height <span class="sc">+</span> weight <span class="sc">+</span> position_center <span class="sc">+</span> position_pg <span class="sc">+</span></span>
<span id="cb207-3"><a href="log-est.html#cb207-3" tabindex="-1"></a>                      season_start,</span>
<span id="cb207-4"><a href="log-est.html#cb207-4" tabindex="-1"></a>                    <span class="at">data =</span> data_nba,</span>
<span id="cb207-5"><a href="log-est.html#cb207-5" tabindex="-1"></a>                    <span class="at">family =</span> binomial)</span>
<span id="cb207-6"><a href="log-est.html#cb207-6" tabindex="-1"></a><span class="fu">margins</span>(model_glm, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##    height   weight position_center position_pg season_start
##  -0.00724 0.001603        0.008915     0.08375     0.001355</code></pre>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="log-est.html#cb209-1" tabindex="-1"></a><span class="co"># same model as linear regression</span></span>
<span id="cb209-2"><a href="log-est.html#cb209-2" tabindex="-1"></a>model_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">as.numeric</span>(career_long) <span class="sc">~</span> height <span class="sc">+</span> weight <span class="sc">+</span> position_center <span class="sc">+</span> position_pg <span class="sc">+</span></span>
<span id="cb209-3"><a href="log-est.html#cb209-3" tabindex="-1"></a>                      season_start,</span>
<span id="cb209-4"><a href="log-est.html#cb209-4" tabindex="-1"></a>                    <span class="at">data =</span> data_nba)</span>
<span id="cb209-5"><a href="log-est.html#cb209-5" tabindex="-1"></a><span class="fu">summary</span>(model_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = as.numeric(career_long) ~ height + weight + position_center + 
##     position_pg + season_start, data = data_nba)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.4419 -0.2441 -0.2119 -0.1536  0.8658 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     -1.7880877  1.4735139  -1.213   0.2250    
## height          -0.0072116  0.0130242  -0.554   0.5798    
## weight           0.0016320  0.0002599   6.278 3.57e-10 ***
## position_center  0.0085814  0.0126006   0.681   0.4959    
## position_pg      0.0835295  0.0135119   6.182 6.59e-10 ***
## season_start     0.0013347  0.0007354   1.815   0.0696 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4187 on 9722 degrees of freedom
## Multiple R-squared:  0.00803,    Adjusted R-squared:  0.007519 
## F-statistic: 15.74 on 5 and 9722 DF,  p-value: 1.821e-15</code></pre>
<p>As we can see, the Average Marginal Effects calculated based on the logistic
regression model are almost identical compared to the linear regression coefficient.
This is why in applied research, many scholars simply use OLS regression for binary
outcomes. It is easier to apply, easier to interpret and the results are very similar
in logistic regression.</p>
<p>As a rule of thumb, many researchers consider using logistic regression when
the probabilities are extreme, so many 99% or 1% cases. In these cases, linear
regression could predict values higher than 100% or lower than 1%, which is, of course,
not possible. However, if most predicted probabilities are between 20-80%, linear
regression models have many advantages.</p>
<p>Example: If you’re modeling the probability of an NBA player to play more than 5 seasons, then nearly all the modeled probabilities will be between .20 and .80, and a linear probability model should fit nicely and offer a straightforward interpretation. Alternatively, consider you want to predict which player will score on average 30 points per game. This probability is likely
between .000001 and .20. In that situation, the linear model just isn’t viable, and you have to use a logistic model or other alternatives.</p>
<p>For a more in-depth discussion see <a href="https://statisticalhorizons.com/linear-vs-logistic/">here</a>.</p>
</div>
<div id="logistic-regression-in-machine-learning-context" class="section level2 hasAnchor" number="13.11">
<h2><span class="header-section-number">13.11</span> logistic regression in Machine Learning context<a href="log-est.html#logistic-regression-in-machine-learning-context" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Such like linear regression, logistic regression is one of the algorithms which
are used in the context of Machine Learning to predict outcomes.</p>
<p>There are many alternatives to logistic regression when predicting binary outcomes such as …,…,…. These appraoches go far beyond the scope of this course. Predicting binary outcomes is often called “classification” in machine learning.
Imagine you have 50 million pictures of animals and you want to predict whether
an image contains a cat. Being a cat or not is a binary outcome, so logistic regresison could be used in this context.</p>
<p>In the following, we provide a very short introduction on how to use logistic regression in a machine learning appraoach using the <code>caret</code> package.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="log-est.html#cb211-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb211-2"><a href="log-est.html#cb211-2" tabindex="-1"></a></span>
<span id="cb211-3"><a href="log-est.html#cb211-3" tabindex="-1"></a><span class="co"># Create a train and test split</span></span>
<span id="cb211-4"><a href="log-est.html#cb211-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb211-5"><a href="log-est.html#cb211-5" tabindex="-1"></a>train_indices <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(data_nba<span class="sc">$</span>career_long, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb211-6"><a href="log-est.html#cb211-6" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> data_nba[train_indices, ]</span>
<span id="cb211-7"><a href="log-est.html#cb211-7" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> data_nba[<span class="sc">-</span>train_indices, ]</span>
<span id="cb211-8"><a href="log-est.html#cb211-8" tabindex="-1"></a></span>
<span id="cb211-9"><a href="log-est.html#cb211-9" tabindex="-1"></a><span class="co"># Create a train control object</span></span>
<span id="cb211-10"><a href="log-est.html#cb211-10" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb211-11"><a href="log-est.html#cb211-11" tabindex="-1"></a></span>
<span id="cb211-12"><a href="log-est.html#cb211-12" tabindex="-1"></a><span class="co"># Train a linear regression model using caret</span></span>
<span id="cb211-13"><a href="log-est.html#cb211-13" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb211-14"><a href="log-est.html#cb211-14" tabindex="-1"></a>  career_long <span class="sc">~</span> height <span class="sc">+</span> weight <span class="sc">+</span> position_center <span class="sc">+</span> position_pg <span class="sc">+</span></span>
<span id="cb211-15"><a href="log-est.html#cb211-15" tabindex="-1"></a>                      season_start,</span>
<span id="cb211-16"><a href="log-est.html#cb211-16" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb211-17"><a href="log-est.html#cb211-17" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>,</span>
<span id="cb211-18"><a href="log-est.html#cb211-18" tabindex="-1"></a>  <span class="at">trControl =</span> ctrl</span>
<span id="cb211-19"><a href="log-est.html#cb211-19" tabindex="-1"></a>)</span>
<span id="cb211-20"><a href="log-est.html#cb211-20" tabindex="-1"></a></span>
<span id="cb211-21"><a href="log-est.html#cb211-21" tabindex="-1"></a></span>
<span id="cb211-22"><a href="log-est.html#cb211-22" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb211-23"><a href="log-est.html#cb211-23" tabindex="-1"></a>predicted_career_m1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, <span class="at">newdata =</span> test_data,</span>
<span id="cb211-24"><a href="log-est.html#cb211-24" tabindex="-1"></a>                               <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb211-25"><a href="log-est.html#cb211-25" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predicted_class_binary=</span><span class="st">`</span><span class="at">1</span><span class="st">`</span>)</span></code></pre></div>
<p>The above yields our predicted probabilities for <code>career_long</code> for every observation in the test dataset. Previously, we have used <code>RMSE</code> to evaluate how good the predictions were. Again, this is different for models with binary outcome models since there are no “residuals” in the classic sense.
Instead, a common metric for assessing model performance is “accuracy”. Accuracy measures which percentage of the actual values (whether someone had a long career or not) are corrected predicted by the model. Other metrics are kappa, sensitivity, specificity. The so-called “confusion matrix” compares the predicted “classes” with the actual “classes” in the training data and computes all these metrics:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="log-est.html#cb212-1" tabindex="-1"></a>test_data<span class="sc">$</span>pred_career <span class="ot">&lt;-</span> predicted_career_m1<span class="sc">$</span>predicted_class_binary</span>
<span id="cb212-2"><a href="log-est.html#cb212-2" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> test_data <span class="sc">%&gt;%</span></span>
<span id="cb212-3"><a href="log-est.html#cb212-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predicted_class_binary =</span> </span>
<span id="cb212-4"><a href="log-est.html#cb212-4" tabindex="-1"></a>           <span class="fu">case_when</span>(pred_career<span class="sc">&gt;</span><span class="fl">0.5</span> <span class="sc">~</span><span class="dv">1</span>,</span>
<span id="cb212-5"><a href="log-est.html#cb212-5" tabindex="-1"></a>                     pred_career<span class="sc">&lt;=</span><span class="fl">0.5</span> <span class="sc">~</span><span class="dv">0</span>,</span>
<span id="cb212-6"><a href="log-est.html#cb212-6" tabindex="-1"></a>                     <span class="cn">TRUE</span><span class="sc">~</span> <span class="cn">NA_real_</span>),</span>
<span id="cb212-7"><a href="log-est.html#cb212-7" tabindex="-1"></a>         <span class="at">predicted_class_binary =</span> <span class="fu">as.factor</span>(predicted_class_binary))</span>
<span id="cb212-8"><a href="log-est.html#cb212-8" tabindex="-1"></a></span>
<span id="cb212-9"><a href="log-est.html#cb212-9" tabindex="-1"></a><span class="fu">str</span>(test_data)</span></code></pre></div>
<pre><code>## tibble [2,917 × 38] (S3: tbl_df/tbl/data.frame)
##  $ id                    : chr [1:2917] &quot;abdulta01&quot; &quot;abdulta01&quot; &quot;abdulta01&quot; &quot;abdulta01&quot; ...
##  $ name                  : chr [1:2917] &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; &quot;Tariq Abdul-Wahad&quot; ...
##  $ age                   : num [1:2917] 25 26 29 30 32 23 24 26 27 31 ...
##  $ weight                : num [1:2917] 223 223 223 223 223 225 225 225 225 225 ...
##  $ height                : num [1:2917] 6.6 6.6 6.6 6.6 6.6 6.9 6.9 6.9 6.9 6.9 ...
##  $ birthPlace            : chr [1:2917] &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; &quot;Maisons Alfort, France&quot; ...
##  $ index.x               : num [1:2917] 4 4 4 4 4 5 5 5 5 5 ...
##  $ career_AST            : num [1:2917] 1.1 1.1 1.1 1.1 1.1 2.5 2.5 2.5 2.5 2.5 ...
##  $ career_FG%            : chr [1:2917] &quot;41.7&quot; &quot;41.7&quot; &quot;41.7&quot; &quot;41.7&quot; ...
##  $ career_FG3%           : chr [1:2917] &quot;23.7&quot; &quot;23.7&quot; &quot;23.7&quot; &quot;23.7&quot; ...
##  $ career_FT%            : chr [1:2917] &quot;70.3&quot; &quot;70.3&quot; &quot;70.3&quot; &quot;70.3&quot; ...
##  $ career_G              : num [1:2917] 236 236 236 236 236 830 830 830 830 830 ...
##  $ career_PER            : chr [1:2917] &quot;11.4&quot; &quot;11.4&quot; &quot;11.4&quot; &quot;11.4&quot; ...
##  $ career_PTS            : num [1:2917] 7.8 7.8 7.8 7.8 7.8 18.1 18.1 18.1 18.1 18.1 ...
##  $ career_TRB            : chr [1:2917] &quot;3.3&quot; &quot;3.3&quot; &quot;3.3&quot; &quot;3.3&quot; ...
##  $ career_WS             : num [1:2917] 3.5 3.5 3.5 3.5 3.5 71.2 71.2 71.2 71.2 71.2 ...
##  $ career_eFG%           : chr [1:2917] &quot;42.2&quot; &quot;42.2&quot; &quot;42.2&quot; &quot;42.2&quot; ...
##  $ college               : chr [1:2917] &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; &quot;University of Michigan, San Jose State University&quot; ...
##  $ draft_pick            : chr [1:2917] &quot;11th overall&quot; &quot;11th overall&quot; &quot;11th overall&quot; &quot;11th overall&quot; ...
##  $ draft_round           : chr [1:2917] &quot;1st round&quot; &quot;1st round&quot; &quot;1st round&quot; &quot;1st round&quot; ...
##  $ draft_team            : chr [1:2917] &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; &quot;Sacramento Kings&quot; ...
##  $ draft_year            : chr [1:2917] &quot;1997&quot; &quot;1997&quot; &quot;1997&quot; &quot;1997&quot; ...
##  $ shoots                : chr [1:2917] &quot;Right&quot; &quot;Right&quot; &quot;Right&quot; &quot;Right&quot; ...
##  $ index.y               : num [1:2917] 20 21 24 25 27 29 30 32 33 37 ...
##  $ salary                : num [1:2917] 1594920 4500000 6187500 6750000 1968750 ...
##  $ season                : chr [1:2917] &quot;1999-00&quot; &quot;2000-01&quot; &quot;2003-04&quot; &quot;2004-05&quot; ...
##  $ season_end            : num [1:2917] 2000 2001 2004 2005 2007 ...
##  $ season_start          : num [1:2917] 1999 2000 2003 2004 2006 ...
##  $ team                  : chr [1:2917] &quot;Denver Nuggets&quot; &quot;Denver Nuggets&quot; &quot;Dallas Mavericks&quot; &quot;Dallas Mavericks&quot; ...
##  $ position_center       : num [1:2917] 0 0 0 0 0 1 1 1 1 1 ...
##  $ position_sf           : num [1:2917] 0 0 0 0 0 1 1 1 1 1 ...
##  $ position_pf           : num [1:2917] 0 0 0 0 0 1 1 1 1 1 ...
##  $ position_sg           : num [1:2917] 1 1 1 1 1 0 0 0 0 0 ...
##  $ position_pg           : num [1:2917] 0 0 0 0 0 0 0 0 0 0 ...
##  $ seasons_played        : int [1:2917] 9 9 9 9 9 10 10 10 10 10 ...
##  $ career_long           : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ pred_career           : num [1:2917] 0.202 0.203 0.205 0.206 0.208 ...
##  $ predicted_class_binary: Factor w/ 1 level &quot;0&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="log-est.html#cb214-1" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>test_data<span class="sc">$</span>predicted_class_binary, <span class="at">reference=</span> test_data<span class="sc">$</span>career_long)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 2249  668
##          1    0    0
##                                           
##                Accuracy : 0.771           
##                  95% CI : (0.7553, 0.7861)
##     No Information Rate : 0.771           
##     P-Value [Acc &gt; NIR] : 0.5104          
##                                           
##                   Kappa : 0               
##                                           
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 1.000           
##             Specificity : 0.000           
##          Pos Pred Value : 0.771           
##          Neg Pred Value :   NaN           
##              Prevalence : 0.771           
##          Detection Rate : 0.771           
##    Detection Prevalence : 1.000           
##       Balanced Accuracy : 0.500           
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<p>The confusion matrix shows that the model predicted short careers (0) for 668 players who actually had long careers (1). It correctely predicted the career for 2249 players. Overall, the career that players had was predicted accurately in 77% of cases.</p>
</div>
<div id="further-resources-7" class="section level2 hasAnchor" number="13.12">
<h2><span class="header-section-number">13.12</span> Further resources<a href="log-est.html#further-resources-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="resources">
<ul>
<li><a href="https://www.r-bloggers.com/2021/01/machine-learning-with-r-a-complete-guide-to-logistic-regression/">Machine Learning with R: A Complete Guide to Logistic Regression</a>: This is a blog post that explains how to use logistic regression for predictive modeling in R, using the trees data set as an example. It covers how to fit, visualize, and evaluate linear regression models, as well as how to calculate confidence and prediction intervals.</li>
<li><a href="https://www.datacamp.com/tutorial/logistic-regression-R">Logistic Regression in R Tutorial</a>: This is a web page that provides a step-by-step tutorial on how to perform logistic regression in R using both base-R and tidymodels workflows. It also shows how to interpret the model output, assess model performance, and make predictions.</li>
<li><a href="http://sthda.com/english/articles/36-classification-methods-essentials/151-logistic-regression-essentials-in-r/">Logistic Regression Essentials in R</a>: This is a web page that introduces the basic concepts and techniques of logistic regression in R. It covers topics such as model assumptions, diagnostics, odds ratios, marginal effects, and model comparison. It also provides examples of applying logistic regression methods to real-world data sets.</li>
<li><a href="https://www.statology.org/r-logistic-regression-predict/">How to Use predict() with Logistic Regression Model in R</a>: This is a web page that shows how to use the predict() function in R to make predictions from a fitted logistic regression model. It also explains the difference between type = “response” and type = “link” arguments, and how to use new data for prediction.</li>
</ul>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pm-a.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="out-look.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/13-logistic-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
