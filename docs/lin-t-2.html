<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 7 Linear Regression - Theory II: Multiple Linear Regression | Data Analysis with R for Social Scientists</title>
  <meta name="description" content="In this course, you will learn how to analyse data using regression in R." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content=" 7 Linear Regression - Theory II: Multiple Linear Regression | Data Analysis with R for Social Scientists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="In this course, you will learn how to analyse data using regression in R." />
  <meta name="github-repo" content="jaspertjaden/DataAnalysisR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 7 Linear Regression - Theory II: Multiple Linear Regression | Data Analysis with R for Social Scientists" />
  
  <meta name="twitter:description" content="In this course, you will learn how to analyse data using regression in R." />
  

<meta name="author" content="Jakob Tures &amp; Jasper Tjaden" />


<meta name="date" content="2023-10-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lin-t-1.html"/>
<link rel="next" href="lin-t-3.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="github-repo.html"><a href="github-repo.html"><i class="fa fa-check"></i><b>1</b> GitHub Repo</a></li>
<li class="chapter" data-level="2" data-path="intro-sem.html"><a href="intro-sem.html"><i class="fa fa-check"></i><b>2</b> Introduction to Seminar</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro-sem.html"><a href="intro-sem.html#prerequisites"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda-1.html"><a href="eda-1.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="eda-1.html"><a href="eda-1.html#objectives"><i class="fa fa-check"></i><b>3.1</b> Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="eda-1.html"><a href="eda-1.html#r-functions-covered-this-week"><i class="fa fa-check"></i><b>3.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="3.3" data-path="eda-1.html"><a href="eda-1.html#what-is-eda-and-why-is-it-so-important"><i class="fa fa-check"></i><b>3.3</b> What is <em>EDA</em> and why is it so important?</a></li>
<li class="chapter" data-level="3.4" data-path="eda-1.html"><a href="eda-1.html#importing-data-into-r"><i class="fa fa-check"></i><b>3.4</b> Importing data into R</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="eda-1.html"><a href="eda-1.html#merge-datasets"><i class="fa fa-check"></i><b>3.4.1</b> Merge datasets</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="eda-1.html"><a href="eda-1.html#clean-dataset"><i class="fa fa-check"></i><b>3.5</b> Clean dataset</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="eda-1.html"><a href="eda-1.html#mutating-variables"><i class="fa fa-check"></i><b>3.5.1</b> Mutating variables</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="eda-1.html"><a href="eda-1.html#explore-the-complete-dataset"><i class="fa fa-check"></i><b>3.6</b> Explore the complete dataset</a></li>
<li class="chapter" data-level="3.7" data-path="eda-1.html"><a href="eda-1.html#explore-individual-variables"><i class="fa fa-check"></i><b>3.7</b> Explore individual variables</a></li>
<li class="chapter" data-level="3.8" data-path="eda-1.html"><a href="eda-1.html#moving-on"><i class="fa fa-check"></i><b>3.8</b> Moving on</a></li>
<li class="chapter" data-level="3.9" data-path="eda-1.html"><a href="eda-1.html#further-resources"><i class="fa fa-check"></i><b>3.9</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="eda-2.html"><a href="eda-2.html"><i class="fa fa-check"></i><b>4</b> Exploratory Data Analysis - Exercise</a>
<ul>
<li class="chapter" data-level="4.1" data-path="eda-2.html"><a href="eda-2.html#what-is-r-markdown"><i class="fa fa-check"></i><b>4.1</b> What is R Markdown?</a></li>
<li class="chapter" data-level="4.2" data-path="eda-2.html"><a href="eda-2.html#creating-a-r-markdown-file"><i class="fa fa-check"></i><b>4.2</b> Creating a R Markdown file</a></li>
<li class="chapter" data-level="4.3" data-path="eda-2.html"><a href="eda-2.html#writing-in-r-markdown"><i class="fa fa-check"></i><b>4.3</b> Writing in R Markdown</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="eda-2.html"><a href="eda-2.html#document-components"><i class="fa fa-check"></i><b>4.3.1</b> Document components</a></li>
<li class="chapter" data-level="4.3.2" data-path="eda-2.html"><a href="eda-2.html#formatting"><i class="fa fa-check"></i><b>4.3.2</b> Formatting</a></li>
<li class="chapter" data-level="4.3.3" data-path="eda-2.html"><a href="eda-2.html#code-chunks"><i class="fa fa-check"></i><b>4.3.3</b> Code chunks</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="eda-2.html"><a href="eda-2.html#further-resources-1"><i class="fa fa-check"></i><b>4.4</b> Further resources</a></li>
<li class="chapter" data-level="4.5" data-path="eda-2.html"><a href="eda-2.html#eda---exercise"><i class="fa fa-check"></i><b>4.5</b> EDA - Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dags-1.html"><a href="dags-1.html"><i class="fa fa-check"></i><b>5</b> DAGs</a>
<ul>
<li class="chapter" data-level="5.1" data-path="dags-1.html"><a href="dags-1.html#objectives-1"><i class="fa fa-check"></i><b>5.1</b> Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="dags-1.html"><a href="dags-1.html#functions-covered"><i class="fa fa-check"></i><b>5.2</b> Functions Covered</a></li>
<li class="chapter" data-level="5.3" data-path="dags-1.html"><a href="dags-1.html#modelling"><i class="fa fa-check"></i><b>5.3</b> Modelling</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="dags-1.html"><a href="dags-1.html#what-is-modelling"><i class="fa fa-check"></i><b>5.3.1</b> What is modelling?</a></li>
<li class="chapter" data-level="5.3.2" data-path="dags-1.html"><a href="dags-1.html#estimating-effects-vs.-prediction"><i class="fa fa-check"></i><b>5.3.2</b> Estimating effects vs. prediction</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="dags-1.html"><a href="dags-1.html#dags"><i class="fa fa-check"></i><b>5.4</b> DAGs</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="dags-1.html"><a href="dags-1.html#directed-acyclical-graphs"><i class="fa fa-check"></i><b>5.4.1</b> Directed acyclical graphs</a></li>
<li class="chapter" data-level="5.4.2" data-path="dags-1.html"><a href="dags-1.html#patterns-of-relationships"><i class="fa fa-check"></i><b>5.4.2</b> Patterns of relationships</a></li>
<li class="chapter" data-level="5.4.3" data-path="dags-1.html"><a href="dags-1.html#adjustment-set"><i class="fa fa-check"></i><b>5.4.3</b> Adjustment set</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="dags-1.html"><a href="dags-1.html#nba-dag"><i class="fa fa-check"></i><b>5.5</b> NBA DAG</a></li>
<li class="chapter" data-level="5.6" data-path="dags-1.html"><a href="dags-1.html#resources"><i class="fa fa-check"></i><b>5.6</b> Resources</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="dags-1.html"><a href="dags-1.html#dagitty.net"><i class="fa fa-check"></i><b>5.6.1</b> dagitty.net</a></li>
<li class="chapter" data-level="5.6.2" data-path="dags-1.html"><a href="dags-1.html#how-to-use-dagitty"><i class="fa fa-check"></i><b>5.6.2</b> How to use dagitty()</a></li>
<li class="chapter" data-level="5.6.3" data-path="dags-1.html"><a href="dags-1.html#more-on-dags"><i class="fa fa-check"></i><b>5.6.3</b> More on DAGs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lin-t-1.html"><a href="lin-t-1.html"><i class="fa fa-check"></i><b>6</b> Linear Regression - Theory I: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lin-t-1.html"><a href="lin-t-1.html#objectives-2"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="lin-t-1.html"><a href="lin-t-1.html#what-is-linear-regression"><i class="fa fa-check"></i><b>6.2</b> What is Linear Regression</a></li>
<li class="chapter" data-level="6.3" data-path="lin-t-1.html"><a href="lin-t-1.html#examplary-research-question-data"><i class="fa fa-check"></i><b>6.3</b> Examplary research question &amp; data</a></li>
<li class="chapter" data-level="6.4" data-path="lin-t-1.html"><a href="lin-t-1.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.4</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="lin-t-1.html"><a href="lin-t-1.html#regression-formula"><i class="fa fa-check"></i><b>6.4.1</b> Regression Formula</a></li>
<li class="chapter" data-level="6.4.2" data-path="lin-t-1.html"><a href="lin-t-1.html#regressing-grade-on-hours"><i class="fa fa-check"></i><b>6.4.2</b> Regressing <code>grade</code> on <code>hours</code></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="lin-t-1.html"><a href="lin-t-1.html#moving-on-1"><i class="fa fa-check"></i><b>6.5</b> Moving on</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lin-t-2.html"><a href="lin-t-2.html"><i class="fa fa-check"></i><b>7</b> Linear Regression - Theory II: Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lin-t-2.html"><a href="lin-t-2.html#objectives-3"><i class="fa fa-check"></i><b>7.1</b> Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="lin-t-2.html"><a href="lin-t-2.html#multiple-linear-regression"><i class="fa fa-check"></i><b>7.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-additional-metric-variables"><i class="fa fa-check"></i><b>7.2.1</b> Adding additional metric variables</a></li>
<li class="chapter" data-level="7.2.2" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-dummy-variables"><i class="fa fa-check"></i><b>7.2.2</b> Adding dummy variables</a></li>
<li class="chapter" data-level="7.2.3" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-categorical-variables"><i class="fa fa-check"></i><b>7.2.3</b> Adding categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="lin-t-2.html"><a href="lin-t-2.html#returning-to-our-research-question"><i class="fa fa-check"></i><b>7.3</b> Returning to our research question</a></li>
<li class="chapter" data-level="7.4" data-path="lin-t-2.html"><a href="lin-t-2.html#adressing-the-uncertainty"><i class="fa fa-check"></i><b>7.4</b> Adressing the uncertainty</a></li>
<li class="chapter" data-level="7.5" data-path="lin-t-2.html"><a href="lin-t-2.html#moving-on-2"><i class="fa fa-check"></i><b>7.5</b> Moving on</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lin-t-3.html"><a href="lin-t-3.html"><i class="fa fa-check"></i><b>8</b> Linear Regression - Theory III: Diagnostics</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lin-t-3.html"><a href="lin-t-3.html#objectives-4"><i class="fa fa-check"></i><b>8.1</b> Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="lin-t-3.html"><a href="lin-t-3.html#model-fit"><i class="fa fa-check"></i><b>8.2</b> Model fit</a></li>
<li class="chapter" data-level="8.3" data-path="lin-t-3.html"><a href="lin-t-3.html#regression-diagnostics"><i class="fa fa-check"></i><b>8.3</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="lin-t-3.html"><a href="lin-t-3.html#linearity"><i class="fa fa-check"></i><b>8.3.1</b> Linearity</a></li>
<li class="chapter" data-level="8.3.2" data-path="lin-t-3.html"><a href="lin-t-3.html#normally-distributed-residuals"><i class="fa fa-check"></i><b>8.3.2</b> Normally distributed residuals</a></li>
<li class="chapter" data-level="8.3.3" data-path="lin-t-3.html"><a href="lin-t-3.html#homoscedasticity"><i class="fa fa-check"></i><b>8.3.3</b> Homoscedasticity</a></li>
<li class="chapter" data-level="8.3.4" data-path="lin-t-3.html"><a href="lin-t-3.html#no-overly-influential-data-points"><i class="fa fa-check"></i><b>8.3.4</b> No overly influential data points</a></li>
<li class="chapter" data-level="8.3.5" data-path="lin-t-3.html"><a href="lin-t-3.html#no-multicollinearity"><i class="fa fa-check"></i><b>8.3.5</b> No (multi)collinearity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="lin-t-3.html"><a href="lin-t-3.html#returning-to-our-research-question-1"><i class="fa fa-check"></i><b>8.4</b> Returning to our research question</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="lin-t-3.html"><a href="lin-t-3.html#interactions"><i class="fa fa-check"></i><b>8.4.1</b> Interactions</a></li>
<li class="chapter" data-level="8.4.2" data-path="lin-t-3.html"><a href="lin-t-3.html#regression-diagnostics-revisited"><i class="fa fa-check"></i><b>8.4.2</b> Regression diagnostics (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lin-t-3.html"><a href="lin-t-3.html#conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a></li>
<li class="chapter" data-level="8.6" data-path="lin-t-3.html"><a href="lin-t-3.html#resources-1"><i class="fa fa-check"></i><b>8.6</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lin-a.html"><a href="lin-a.html"><i class="fa fa-check"></i><b>9</b> Linear Regression - Application</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lin-a.html"><a href="lin-a.html#objectives-5"><i class="fa fa-check"></i><b>9.1</b> Objectives</a></li>
<li class="chapter" data-level="9.2" data-path="lin-a.html"><a href="lin-a.html#r-functions-covered-this-week-1"><i class="fa fa-check"></i><b>9.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="9.3" data-path="lin-a.html"><a href="lin-a.html#research-question"><i class="fa fa-check"></i><b>9.3</b> Research question</a></li>
<li class="chapter" data-level="9.4" data-path="lin-a.html"><a href="lin-a.html#simple-linear-regression-in-r"><i class="fa fa-check"></i><b>9.4</b> Simple linear regression in R</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="lin-a.html"><a href="lin-a.html#interpretation"><i class="fa fa-check"></i><b>9.4.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="lin-a.html"><a href="lin-a.html#multiple-linear-regression-in-r"><i class="fa fa-check"></i><b>9.5</b> Multiple linear regression in R</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="lin-a.html"><a href="lin-a.html#interpretation-1"><i class="fa fa-check"></i><b>9.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="9.5.2" data-path="lin-a.html"><a href="lin-a.html#sidenote-adding-interactions"><i class="fa fa-check"></i><b>9.5.2</b> Sidenote: Adding interactions</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="lin-a.html"><a href="lin-a.html#regression-diagnostics-1"><i class="fa fa-check"></i><b>9.6</b> Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="lin-a.html"><a href="lin-a.html#skewed-outcome-variable"><i class="fa fa-check"></i><b>9.6.1</b> Skewed outcome variable</a></li>
<li class="chapter" data-level="9.6.2" data-path="lin-a.html"><a href="lin-a.html#non-linearity"><i class="fa fa-check"></i><b>9.6.2</b> Non-linearity</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="lin-a.html"><a href="lin-a.html#returning-to-our-research-question-2"><i class="fa fa-check"></i><b>9.7</b> Returning to our research question</a></li>
<li class="chapter" data-level="9.8" data-path="lin-a.html"><a href="lin-a.html#moving-on-3"><i class="fa fa-check"></i><b>9.8</b> Moving on</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="lin-e.html"><a href="lin-e.html"><i class="fa fa-check"></i><b>10</b> Linear Regression - Exercise</a>
<ul>
<li class="chapter" data-level="10.1" data-path="lin-e.html"><a href="lin-e.html#exercises"><i class="fa fa-check"></i><b>10.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="med.html"><a href="med.html"><i class="fa fa-check"></i><b>11</b> Mediation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="med.html"><a href="med.html#objectives-6"><i class="fa fa-check"></i><b>11.1</b> Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="med.html"><a href="med.html#r-functions-covered-this-week-2"><i class="fa fa-check"></i><b>11.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="11.3" data-path="med.html"><a href="med.html#further-resources-2"><i class="fa fa-check"></i><b>11.3</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pm-t.html"><a href="pm-t.html"><i class="fa fa-check"></i><b>12</b> Prediction</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pm-t.html"><a href="pm-t.html#objectives-7"><i class="fa fa-check"></i><b>12.1</b> Objectives</a></li>
<li class="chapter" data-level="12.2" data-path="pm-t.html"><a href="pm-t.html#r-functions-covered-this-week-3"><i class="fa fa-check"></i><b>12.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="12.3" data-path="pm-t.html"><a href="pm-t.html#how-prediction-works"><i class="fa fa-check"></i><b>12.3</b> How prediction works</a></li>
<li class="chapter" data-level="12.4" data-path="pm-t.html"><a href="pm-t.html#intro-to-machine-learning"><i class="fa fa-check"></i><b>12.4</b> Intro to Machine learning</a></li>
<li class="chapter" data-level="12.5" data-path="pm-t.html"><a href="pm-t.html#further-resources-3"><i class="fa fa-check"></i><b>12.5</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pm-a.html"><a href="pm-a.html"><i class="fa fa-check"></i><b>13</b> Prediction - Exercise</a>
<ul>
<li class="chapter" data-level="13.1" data-path="pm-a.html"><a href="pm-a.html#exercises-1"><i class="fa fa-check"></i><b>13.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="log-est.html"><a href="log-est.html"><i class="fa fa-check"></i><b>14</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="14.1" data-path="log-est.html"><a href="log-est.html#objectives-8"><i class="fa fa-check"></i><b>14.1</b> Objectives</a></li>
<li class="chapter" data-level="14.2" data-path="log-est.html"><a href="log-est.html#functions-covered-in-this-week"><i class="fa fa-check"></i><b>14.2</b> Functions covered in this week</a></li>
<li class="chapter" data-level="14.3" data-path="log-est.html"><a href="log-est.html#basic-concepts"><i class="fa fa-check"></i><b>14.3</b> Basic concepts</a></li>
<li class="chapter" data-level="14.4" data-path="log-est.html"><a href="log-est.html#application"><i class="fa fa-check"></i><b>14.4</b> Application</a></li>
<li class="chapter" data-level="14.5" data-path="log-est.html"><a href="log-est.html#interpretation-2"><i class="fa fa-check"></i><b>14.5</b> Interpretation</a></li>
<li class="chapter" data-level="14.6" data-path="log-est.html"><a href="log-est.html#model-fit-1"><i class="fa fa-check"></i><b>14.6</b> model fit</a></li>
<li class="chapter" data-level="14.7" data-path="log-est.html"><a href="log-est.html#diagnostics"><i class="fa fa-check"></i><b>14.7</b> diagnostics</a></li>
<li class="chapter" data-level="14.8" data-path="log-est.html"><a href="log-est.html#prediction"><i class="fa fa-check"></i><b>14.8</b> prediction</a></li>
<li class="chapter" data-level="14.9" data-path="log-est.html"><a href="log-est.html#mediation-1"><i class="fa fa-check"></i><b>14.9</b> Mediation</a></li>
<li class="chapter" data-level="14.10" data-path="log-est.html"><a href="log-est.html#comparing-linear-and-logistic-regression"><i class="fa fa-check"></i><b>14.10</b> comparing linear and logistic regression</a></li>
<li class="chapter" data-level="14.11" data-path="log-est.html"><a href="log-est.html#logistic-regression-in-machine-learning-context"><i class="fa fa-check"></i><b>14.11</b> logistic regression in Machine Learning context</a></li>
<li class="chapter" data-level="14.12" data-path="log-est.html"><a href="log-est.html#further-resources-4"><i class="fa fa-check"></i><b>14.12</b> Further resources</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis with R for Social Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lin-t-2" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number"> 7</span> Linear Regression - Theory II: Multiple Linear Regression<a href="lin-t-2.html#lin-t-2" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Maybe explaining the grade a student receives solely based on the hours of
invested time does not paint the whole picture. As we have alluded to, there
may be other variables that could affect the relationship between <code>hours</code> and
<code>grade</code>.
If we fail to include these in our model, we may not get an unbiased estimate
for our effect of interest. Maybe the actual effect for <code>hours</code> is even stronger,
maybe it is weaker, or maybe there is no effect at all.
To assess this, we have to move from simple to multiple linear regression.</p>
<div id="objectives-3" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Objectives<a href="lin-t-2.html#objectives-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="objectives">
<ul>
<li>Expand the idea to multiple linear regression</li>
<li>Interpreting different types of independent variables</li>
<li>Understand measures of uncertainty</li>
</ul>
</div>
</div>
<div id="multiple-linear-regression" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Multiple Linear Regression<a href="lin-t-2.html#multiple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <em>simple linear regression</em> only allows for one independent variable. This is
why we need <em>multiple linear regression</em> if we want to start introducing
additional variables into the model. Luckily this is easy to understand as we
already know the formula for a simple linear regression:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1*x_1 + \epsilon\]</span></p>
<p>To change a simple into a multiple linear regression, we just start adding the
additional variables and their coefficients additively to the formula.</p>
<p><span class="math display">\[y = \beta_0 + \beta_1*x_1 + \beta_2*x_2 + ... + \beta_k*x_k + \epsilon\]</span></p>
<p>So to add a second variable and its coefficient we add the term <span class="math inline">\(+ \beta_2*x_2\)</span>
and so on until we added all independent variables of interest <span class="math inline">\(k\)</span> to the model.
Everything else works exactly as for the simple model.</p>
<div id="adding-additional-metric-variables" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Adding additional metric variables<a href="lin-t-2.html#adding-additional-metric-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We already expected that the mean of the previous grades could be a strong
predictor for future grades. We could understand these as a <em>proxy</em> variable for
the general skill level of a student. The higher the skill level, the higher
previous grades will have been.</p>
<p>How we can add additional variables in R code will again be a topic for the next
session, but let us look at the results of a regression of <code>grade</code> on
<code>hours_centered</code> and <code>previous_grades_centered</code>, the latter being centered on the
mean previous grade of <span class="math inline">\(2.935\)</span>.</p>
<pre><code>## 
## Call:
## lm(formula = grade ~ hours_centered + previous_grades_centered, 
##     data = grades)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.44462 -0.30556  0.00622  0.32878  1.31002 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               2.967500   0.038316  77.449   &lt;2e-16 ***
## hours_centered           -0.056543   0.006114  -9.248   &lt;2e-16 ***
## previous_grades_centered  0.904079   0.039830  22.699   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5419 on 197 degrees of freedom
## Multiple R-squared:  0.7492, Adjusted R-squared:  0.7467 
## F-statistic: 294.3 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>As we added a new variable, we now see three coefficients.
The intercept has not changed. It now indicates the estimated grade for a
student who invests the mean amount of hours, <span class="math inline">\(40.33\)</span>, and whose previous grades
are exactly <span class="math inline">\(2.935\)</span>, the mean of the variable.</p>
<p>The coefficient for <code>hours_centered</code> got mildly more negative, still telling us
that the value of <code>grade</code> gets lower, the more hours are invested in writing the
paper. This coefficient now gives us the effect while <em>controlling</em> for the
effect of <code>previous_grades_centered</code>. This is what multiple linear regression
does, giving us the coefficients for our variables of interest while keeping all
other independent variables at specific values. As we have centered the variable
for previous grades, the coefficient for <code>hours centered</code> gives us the effect
when the previous grades were exactly at the mean of <span class="math inline">\(2.935\)</span>.</p>
<p>In the same way, the coefficient for <code>previous_grades_centered</code> gives us the
effect of previous grades when the invested hours are controlled for, in this
case when the invested hours were exactly <span class="math inline">\(40.33\)</span>. The coefficient is rather
high and positive. This indicates that a student with a previous grade value
that is <span class="math inline">\(1\)</span> above the mean, is estimated to receive a new grade that is <span class="math inline">\(0.9\)</span>
points above the intercept. This means, that the previous grade is a very strong
predictor for the new grade.</p>
<p>While plotting in more than two dimensions gets really hard, we can still
calculate <span class="math inline">\(\hat{y}\)</span> for certain values of both independent variables.
We already know the predicted grade for a student with mean values on both
independent variables, as this is the intercept. To make sure that we correct,
we can calculate it again.</p>
<p><span class="math display">\[b_0 + b_{hours\_centered}*0 + b_{previous\_grades\_centered}*0 = 2.9675\]</span></p>
<p>For this case we can see that the previous grade actually is a strong
predictor, as the previous and new grades are substantially the same.</p>
<p>What if a student whose previous grades were <span class="math inline">\(1\)</span> above the mean, so just below
<span class="math inline">\(4.0\)</span>, but who decides to invest <span class="math inline">\(10\)</span> hours more than the mean in writing the new paper?</p>
<p><span class="math display">\[2.9675 - 0.056543 * 10 + 0.904079 * 1 = 3.306149\]</span></p>
<p>So the good message is, while previous grades are a strong predictor, putting in
more hours still leads to better grades.</p>
<p>What if a really good student decides to rely on their skill and to work less
this time?</p>
<p><span class="math display">\[2.9675 - 0.056543 * -10 + 0.904079 * -2 = 1.724772\]</span></p>
<p>While <span class="math inline">\(1.7\)</span> is still a very good grade, working 10 less hours than the mean of
students leads to a substantially worse estimate compared to the about <span class="math inline">\(1.0\)</span>
received in previous grades.</p>
</div>
<div id="adding-dummy-variables" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Adding dummy variables<a href="lin-t-2.html#adding-dummy-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another variable that could be of interest in explaining the received grade,
is if a student attended most of the seminar sessions.
<code>attendance</code> holds this information in the form of a dummy variable. Dummies can
only have two states. “Yes” or “No”, “1” or “0” or in this case “<code>TRUE</code>” or
“<code>FALSE</code>”.</p>
<p>Let us add the variable to our model.</p>
<pre><code>## 
## Call:
## lm(formula = grade ~ hours_centered + previous_grades_centered + 
##     attendance, data = grades)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.41059 -0.30910  0.01667  0.35607  1.29849 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               3.157411   0.078658  40.141  &lt; 2e-16 ***
## hours_centered           -0.053942   0.006088  -8.860 4.85e-16 ***
## previous_grades_centered  0.911802   0.039282  23.212  &lt; 2e-16 ***
## attendanceTRUE           -0.248250   0.090246  -2.751   0.0065 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5331 on 196 degrees of freedom
## Multiple R-squared:  0.7586, Adjusted R-squared:  0.7549 
## F-statistic: 205.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This gives us a new line in the R Output holding an estimate for
<code>attendanceTRUE</code>. What is meant by this? In contrast to the metric variables we
have uses in our model up to this point, a dummy variable - or binary variable -
can only have two states. As we are using a logical variable here, it can only
have the value <code>TRUE</code> - here indicating regular attendance - or <code>FALSE</code>. So what
the output shows us, is the effect of attendance being <code>TRUE</code> compared to being
<code>FALSE</code>. If a student did regularly attend the seminar, the estimated grade is
<span class="math inline">\(-0.248250\)</span> lower compared to when they did not.</p>
<p>We can observe what happens in the formula:</p>
<p><span class="math display">\[\hat{y} = b_0 + b_{hours\_centered}*x_{hours\_centered} + \\
b_{previous\_grades\_centered} * x_{previous\_grades\_centered} +\\
b_{attendance} * x_{attendance}\]</span></p>
<p>If you calculate with <code>TRUE</code> and <code>FALSE</code> in R, the values <span class="math inline">\(1\)</span> and <span class="math inline">\(0\)</span> are used
respectively. So <span class="math inline">\(x_{attendance}\)</span> can either have the value <span class="math inline">\(1\)</span> for regular
attendance or <span class="math inline">\(0\)</span> for not so regular attendance.</p>
<p>If a student did regularly attend, the coefficient $b_{attendance} becomes a
part of the estimate <span class="math inline">\(\hat{y}\)</span>:</p>
<p><span class="math display">\[\hat{y} = b_0 + b_{hours\_centered}*x_{hours\_centered} +\\
b_{previous\_grades\_centered}*x_{previous\_grades\_centered} +\\
b_{attendance} * 1\]</span></p>
<p>If student did not regularly attended, this happens:</p>
<p><span class="math display">\[\hat{y} = b_0 + b_{hours\_centered}*x_{hours\_centered} \\
+ b_{previous\_grades\_centered}*x_{previous\_grades\_centered} +\\
b_{attendance} * 0\]</span></p>
<p>Which shortens to:</p>
<p><span class="math display">\[\hat{y} = b_0 + b_{hours\_centered}*x_{hours\_centered} +\\
b_{previous\_grades\_centered}*x_{previous\_grades\_centered}\]</span></p>
<p>The coefficient is no longer a part of the estimate. One can basically say, the
coefficient gets switched on or off by the value of the dummy variable.</p>
<p>So while the estimate for a student with mean values for invested hours and
previous grades who did not attend is equal to the intercept of <span class="math inline">\(3.157411\)</span>,
for a similar student who attended we can calculate the estimate as:</p>
<p><span class="math display">\[3.157411 - 0.053942*0 + 0.911802*0 - 0.248250 * 1 = 3.157411 - 0.248250 \\
= 2.909161\]</span></p>
<p>It seems attending class is an easy way to raise one’s grades.</p>
</div>
<div id="adding-categorical-variables" class="section level3 hasAnchor" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Adding categorical variables<a href="lin-t-2.html#adding-categorical-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have one further variable in our simulated data set that could be of interest
in explaining, what makes a good grade in a seminar paper. <code>contact</code> is a
categorical variable, or a factor variable in R terms.
It can take three different categories. <code>No contact</code> indicates that
the student did not contact the lecturer to discuss a research question or the
laid out plan for the paper. <code>E-Mail</code> means that there was some written contact
and at least the basics for the paper were discussed before writing. Lastly,
<code>In Person</code> stands for an in depth discussion with the lecturer, clearing up
problems beforehand and thus potentially having a more stringent vision for the
paper before writing the first word.</p>
<p>Let us add the variable to our model.</p>
<pre><code>## 
## Call:
## lm(formula = grade ~ hours_centered + previous_grades_centered + 
##     attendance + contact, data = grades)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.3835 -0.2525  0.0167  0.2678  0.9347 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               3.617949   0.068077  53.145  &lt; 2e-16 ***
## hours_centered           -0.050830   0.004433 -11.466  &lt; 2e-16 ***
## previous_grades_centered  0.874123   0.028657  30.503  &lt; 2e-16 ***
## attendanceTRUE           -0.324653   0.065781  -4.935 1.72e-06 ***
## contactE-Mail            -0.413808   0.069817  -5.927 1.39e-08 ***
## contactIn Person         -0.853252   0.063964 -13.340  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3869 on 194 degrees of freedom
## Multiple R-squared:  0.8741, Adjusted R-squared:  0.8709 
## F-statistic: 269.4 on 5 and 194 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Wait, we entered three categories into the model and got estimates for two of
them. What happened? What R does is to create two dummy variables on the fly.
The first discerns between having E-Mail contact and no contact at all. The
second one between having contact in person and no contact at all. So for
categorical variables in regression models we always compare being in one of the
categories to being in the <em>base category</em>. In this case the base category is
<code>No contact</code>, but we could also change the base category. It depends on what we
are interested in comparing to. For our example comparing the effects of having
more in depth contact to having none makes sense.</p>
<p>Let us look at our formula again:</p>
<p><span class="math display">\[\hat{y} = b_0 + b_{hours\_centered}*x_{hours\_centered} +\\
b_{previous\_grades\_centered} * x_{previous\_grades\_centeerd} +\\
b_{attendance} * x_{attendance} +\\
b_{E-Mail} * x_{E-Mail} + b_{In Person} * x_{In Person}\]</span></p>
<p>Now there are three possibilities. A student can have no contact at all. In this
case both dummy variables are equal to <span class="math inline">\(0\)</span>. To make our formula easier to read, we have
abbreviated the middle part for now:</p>
<p><span class="math display">\[\hat{y} = b_0 + ... + b_{E-Mail} * 0 + b_{In Person} * 0\]</span></p>
<p>So in this case controlling all other independent variables at their default
values, the mean for the metric variables and <code>FALSE</code> for <code>attendance</code>, the
intercept gives us the estimate for the grade when the student had no contact to
the lecturer, as both dummy variables that were created for <code>contact</code> are “switched off”.</p>
<p>The two other possibilities are that a student either had E-Mail contact or an
in person discussion:</p>
<p><span class="math display">\[\hat{y} = b_0 + ... + b_{E-Mail} * 1 + b_{In Person} * 0\]</span></p>
<p><span class="math display">\[\hat{y} = b_0 + ... + b_{E-Mail} * 0 + b_{In Person} * 1\]</span></p>
<p>In both cases the relevant dummy variable is “switched on” while the other does
not factor into the equation.</p>
<p>Looking at the estimates we can see that having contact to the lecturer before
writing has strong negative effects, resulting in better grades. Having E-Mail
contact reduces the value of <code>grade</code> by <span class="math inline">\(-0.413808\)</span> points, having an in person
discussion by <span class="math inline">\(-0.853252\)</span>.</p>
<p>So what grade can a student whose previous grades were at the mean of <span class="math inline">\(2.935\)</span>,
but who decided to put in 20 hours more compared to their peers, regularly
attend the seminar and have an in-depth personal discussion before writing their
paper expect on average as their new grade?</p>
<p><span class="math display">\[3.617949 - 0.050830 * 20 + 0.874123 * 0 - 0.324653 * 1 - 0.413808 * 0 - 0.853252 * 1
\\ = 1.423444\]</span></p>
<p>Putting in the hours, attending and working with your lecturer seems to pay off,
at least in our simulated data set.</p>
</div>
</div>
<div id="returning-to-our-research-question" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Returning to our research question<a href="lin-t-2.html#returning-to-our-research-question" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Our exemplary research question concerned itself with what makes a good grade in
a seminar paper. In particular we were interested in the effect of the invested
hours, as our main hypothesis was that more hours lead to better grades. What do
we know now?</p>
<p>Our analysis points towards a clear effect from <code>hours</code> on <code>grade</code>. This effect
was consistently visible in all of our models. But did we correctly identify
and estimate the effect of interest? Maybe. The problem is, we actually did not
approach the analysis correctly. In a real analysis we should <strong>absolutely</strong>
refrain from adding variables to our model that <em>could be</em> relevant until we are
satisfied or even until all available variables are bunched into one huge model.
It was fine to do this in this introduction to linear regression to learn how
different types of variables can be used in a regression model. But in a real
project, we have to invest time to think about which variables to add because we
assume that they have a relevant effect based on theoretical assumptions about
the processes we are interested in.</p>
<p>So let us do this now and vow do make this our first step in all future
endeavors. While we do not have a clear theoretical basis, we can make clear
assumptions on the data generating process and draw these in a DAG.</p>
<p><img src="_main_files/figure-html/dag-1.png" width="672" /></p>
<p>Our central assumption, and the effect we want to identify and estimate, is the
direct effect from <code>hours</code> on <code>grade</code> in the bottom line. The more hours a
student invests, the better the grade should be.</p>
<p>The assumed effect of <code>contact</code> is more complex. For one we assume that a more
in-depth contact with the lecturer will increase the grade directly. The
research question will be more focused, the student will know what is important
to a certain lecturer, common mistakes can be avoided if they are cleared up
beforehand and so on. But we will also assume that <code>contact</code> will have an effect
on <code>hours</code> in the sense that the hours invested can be used more efficiently if
an in-depth discussion has taken place. Instead of wasting time running into
problems that could have been avoided most of the invested time can actually go
into constructive work. This makes <code>contact</code> a confounder for <code>grade</code> and
<code>hours</code>.</p>
<p>A student’s skill level will also have a direct effect on <code>grade</code>. As we do not
have a direct measure of skill in our data, we use <code>previous_grades</code> as a proxy
for skill level. <code>attendance</code> is also assumed to have a direct effect on <code>grade</code>
as students who were present in the seminar will not only have learned the seminar’s
contents, but will also have a better understanding of what is expected in their
seminar papers.</p>
<p>Tapping into the knowledge from session 4, we can now make implications for our
model from the DAG. Let us list all paths from <code>hours</code> to <code>grade</code>:</p>
<p><span class="math display">\[A: Hours \rightarrow Grade\]</span></p>
<p><span class="math display">\[B: Hours \leftarrow Contact \rightarrow Grade\]</span></p>
<p>Path A represents our effect of interest. On path B, <code>contact</code> is a confounder
for <code>hours</code> and <code>grade</code>. To close this path, we have to control for <code>contact</code>.
As neither skill level - or <code>previous_grades</code> - nor <code>attendance</code> lie on a path
from our independent variable of interest to our dependent variable, we should
not control for them in our model.
That leaves us with <code>hours</code> and <code>contact</code> to be included in our linear
regression, if our goal is to get an unbiased estimate for the effect of
invested time on the final grade. So let us do this:</p>
<pre><code>## 
## Call:
## lm(formula = grade ~ hours_centered + contact, data = grades)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.85595 -0.74624 -0.02106  0.66648  2.50161 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       3.44352    0.10404  33.098  &lt; 2e-16 ***
## hours_centered   -0.04967    0.01052  -4.723 4.43e-06 ***
## contactE-Mail    -0.46482    0.16785  -2.769  0.00616 ** 
## contactIn Person -1.02804    0.15240  -6.746 1.67e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9305 on 196 degrees of freedom
## Multiple R-squared:  0.2643, Adjusted R-squared:  0.253 
## F-statistic: 23.47 on 3 and 196 DF,  p-value: 5.072e-13</code></pre>
<p>This is our estimate. Each hour invested beyond the mean of <span class="math inline">\(40.33\)</span> hours
changes the grade by about <span class="math inline">\(-0.05\)</span> points. This supports our hypotheses and we
can conclude, that investing more hours into writing a seminar paper actually
is a worthwhile investment.</p>
<p>But remember: This is correct as long as our DAG is drawn correctly, which is
always debatable. Maybe we should assume an effect from skill level on <code>hours</code>.
The higher the skill level the more efficiently the available time can be used.
For this example we know the DAG is correct, because we have simulated the data
exactly in this way. For real world applications we never know if our DAG is
correct. All we can and <em>have to</em> do is base it on thorough thinking,
theoretical work, exploratory data analysis and sound arguments.</p>
<p>This all is true <em>if</em> our goal is to estimate an effect of interest as precisely
as possible. But as we have alluded to in the introduction to this session we
could also use modelling with a different goal, i.e. predicting a grade as
accurately as possible. For this task, the model which only includes <code>hours</code> and
<code>contact</code> will not do the best job. From our DAG we know that <code>attendance</code> and
<code>previous_grade</code> should have an effect on <code>grade</code>, as we have also seen in our
models. For this task the full model including all these variables will produce
better estimates. We will return to this in a later session, but for now we
should remember that we have to know our task because the task dictates which is
the best model to use.</p>
</div>
<div id="adressing-the-uncertainty" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Adressing the uncertainty<a href="lin-t-2.html#adressing-the-uncertainty" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Looking at the coefficient block from the output, we see more
than just our estimates. The <code>Std. Error</code> - <em>standard error</em> - is a measure for the
uncertainty of our estimates. It basically tells us, how far away the actual
values of the observations used to compute the model are from our estimate
<em>on average</em>. The smaller the <em>standard error</em>, the more accurate our
estimate. The standard error is presented in the units of the estimate and we
can thus compare them. A large standard error for a large estimate is far less
problematic compared to a large standard error for a small estimate.</p>
<p>The estimate and it’s standard error are the basis for <em>hypothesis testing</em>.
What we are testing is the <em>alternative hypotheses</em> <span class="math inline">\(H_a\)</span> that there actually
is an effect of our independent variable on the dependent variable against the
<em>null hypothesis</em> <span class="math inline">\(H_0\)</span> that there is no effect. To reject the null hypothesis
and be confident that we are observing an actual effect, versus an effect that
is just based on random variation in our sample, the estimate has to be far
away enough from <span class="math inline">\(0\)</span> and be accurate enough, i.e. have a small standard error.
This relationship is computed in the <em>t-statistic</em>, <code>t value</code> in
our output. From this the <em>p-value</em> can be computed, <code>Pr(&gt;|t|)</code> in the output.
The <em>p-value</em> tells us the probability to observe an association
between the independent and the dependent variable as large or larger than our
estimate suggests, if the true association would actually be <span class="math inline">\(0\)</span>. If the p-value
is small enough, we can reject <span class="math inline">\(H_0\)</span> and conclude that we observed an actual
effect. There are certain agreed upon cutoffs in statistics, while values that
meet this cutoffs are considered <em>statistically significant</em>. The most common
cutoff in social sciences is <span class="math inline">\(0.05\)</span> indicated by one <code>*</code> in the output.
Other common cutoffs are indicated by more asterisks. It is important to note,
that we can not say that more <code>*</code> behind an effect mean that this effect has a
higher statistical significance. We have to decide on a level of statistical
significance that we want to test for before we see the results. If we decide on
testing for a significance level of <span class="math inline">\(5\%\)</span>, seeing more than one star then only
means that the effect is also statistically significant at the <span class="math inline">\(5\%\)</span> level.</p>
<p>Interpreting p-values correctly and not falling into the common pitfalls like the
one mentioned above is a
topic on its own. We do not have the time to dive into this here, so for now we
can agree that p-values below <span class="math inline">\(0.05\)</span> indicate that we can reject <span class="math inline">\(H_0\)</span> and thus
conclude that we have actually observed an effect. Still, our interpretation of
regression results should not focus solely on p-values or lead us to disregard
any effects that did not meet the cutoff. For example, we can have very small
p-values for effects that are so small that they are substantially irrelevant.
One way to address this is to inspect the actual magnitudes of the effects.
On the other hand, we
can have p-values larger than <span class="math inline">\(0.05\)</span> for effects that are still relevant. Maybe
the problem is not that there is no effect but that we were not able to measure
the variable in question precisely enough or that we just did not have enough
observations. We can not go any deeper than this here, but we should remember
that the practice of declaring every effect with stars a win, or even with more
stars a bigger win, and disregarding
everything without them may still be common but is not the way to go forward.</p>
<p>In our model, we can see that the effect of interest is statistically
significant. We can thus conclude, that we have observed an actual effect
from <code>hours</code> on <code>grade</code>. Our estimate is large enough and our standard error
small enough to reach this conclusion.</p>
</div>
<div id="moving-on-2" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Moving on<a href="lin-t-2.html#moving-on-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have attained an estimate for our effect of interest which supports our
hypotheses that investing more hours into writing a paper leads to better grades.
So can we wrap a bow on the question and move on to finally figuring out what
is going on in our NBA data? Almost, but not yet. We still do not know, if our
model actually works as intended. Linear regression, as well as every other modelling
technique, has some underlying statistical assumptions that we have to meet for the model
to accurately estimate an effect. In the <a href="lin-t-3.html#lin-t-3">next session</a> we will get to know these
assumptions and how we can test for them.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lin-t-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lin-t-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/06-linear-regression-t-2.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
