<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 11 Prediction - Theory | Data Analysis with R for Social Scientists</title>
  <meta name="description" content="In this course, you will learn how to analyse data using regression in R." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content=" 11 Prediction - Theory | Data Analysis with R for Social Scientists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="In this course, you will learn how to analyse data using regression in R." />
  <meta name="github-repo" content="jaspertjaden/DataAnalysisR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 11 Prediction - Theory | Data Analysis with R for Social Scientists" />
  
  <meta name="twitter:description" content="In this course, you will learn how to analyse data using regression in R." />
  

<meta name="author" content="Jakob Tures &amp; Jasper Tjaden" />


<meta name="date" content="2023-10-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="med.html"/>
<link rel="next" href="pm-a.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#about-the-authors"><i class="fa fa-check"></i><b>0.1</b> About the Authors</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro-sem.html"><a href="intro-sem.html"><i class="fa fa-check"></i><b>1</b> Introduction to Seminar</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro-sem.html"><a href="intro-sem.html#prerequisites"><i class="fa fa-check"></i><b>1.1</b> Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="eda-1.html"><a href="eda-1.html"><i class="fa fa-check"></i><b>2</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="eda-1.html"><a href="eda-1.html#objectives"><i class="fa fa-check"></i><b>2.1</b> Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="eda-1.html"><a href="eda-1.html#r-functions-covered-this-week"><i class="fa fa-check"></i><b>2.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="2.3" data-path="eda-1.html"><a href="eda-1.html#what-is-eda-and-why-is-it-so-important"><i class="fa fa-check"></i><b>2.3</b> What is <em>EDA</em> and why is it so important?</a></li>
<li class="chapter" data-level="2.4" data-path="eda-1.html"><a href="eda-1.html#importing-data-into-r"><i class="fa fa-check"></i><b>2.4</b> Importing data into R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="eda-1.html"><a href="eda-1.html#merge-datasets"><i class="fa fa-check"></i><b>2.4.1</b> Merge datasets</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="eda-1.html"><a href="eda-1.html#clean-dataset"><i class="fa fa-check"></i><b>2.5</b> Clean dataset</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="eda-1.html"><a href="eda-1.html#mutating-variables"><i class="fa fa-check"></i><b>2.5.1</b> Mutating variables</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="eda-1.html"><a href="eda-1.html#explore-the-complete-dataset"><i class="fa fa-check"></i><b>2.6</b> Explore the complete dataset</a></li>
<li class="chapter" data-level="2.7" data-path="eda-1.html"><a href="eda-1.html#explore-individual-variables"><i class="fa fa-check"></i><b>2.7</b> Explore individual variables</a></li>
<li class="chapter" data-level="2.8" data-path="eda-1.html"><a href="eda-1.html#moving-on"><i class="fa fa-check"></i><b>2.8</b> Moving on</a></li>
<li class="chapter" data-level="2.9" data-path="eda-1.html"><a href="eda-1.html#further-resources"><i class="fa fa-check"></i><b>2.9</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda-2.html"><a href="eda-2.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis - Exercise</a>
<ul>
<li class="chapter" data-level="3.1" data-path="eda-2.html"><a href="eda-2.html#what-is-r-markdown"><i class="fa fa-check"></i><b>3.1</b> What is R Markdown?</a></li>
<li class="chapter" data-level="3.2" data-path="eda-2.html"><a href="eda-2.html#creating-a-r-markdown-file"><i class="fa fa-check"></i><b>3.2</b> Creating a R Markdown file</a></li>
<li class="chapter" data-level="3.3" data-path="eda-2.html"><a href="eda-2.html#writing-in-r-markdown"><i class="fa fa-check"></i><b>3.3</b> Writing in R Markdown</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="eda-2.html"><a href="eda-2.html#document-components"><i class="fa fa-check"></i><b>3.3.1</b> Document components</a></li>
<li class="chapter" data-level="3.3.2" data-path="eda-2.html"><a href="eda-2.html#formatting"><i class="fa fa-check"></i><b>3.3.2</b> Formatting</a></li>
<li class="chapter" data-level="3.3.3" data-path="eda-2.html"><a href="eda-2.html#code-chunks"><i class="fa fa-check"></i><b>3.3.3</b> Code chunks</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="eda-2.html"><a href="eda-2.html#further-resources-1"><i class="fa fa-check"></i><b>3.4</b> Further resources</a></li>
<li class="chapter" data-level="3.5" data-path="eda-2.html"><a href="eda-2.html#eda---exercise"><i class="fa fa-check"></i><b>3.5</b> EDA - Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dags-1.html"><a href="dags-1.html"><i class="fa fa-check"></i><b>4</b> DAGs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dags-1.html"><a href="dags-1.html#objectives-1"><i class="fa fa-check"></i><b>4.1</b> Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="dags-1.html"><a href="dags-1.html#functions-covered"><i class="fa fa-check"></i><b>4.2</b> Functions Covered</a></li>
<li class="chapter" data-level="4.3" data-path="dags-1.html"><a href="dags-1.html#modelling"><i class="fa fa-check"></i><b>4.3</b> Modelling</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dags-1.html"><a href="dags-1.html#what-is-modelling"><i class="fa fa-check"></i><b>4.3.1</b> What is modelling?</a></li>
<li class="chapter" data-level="4.3.2" data-path="dags-1.html"><a href="dags-1.html#estimating-effects-vs.-prediction"><i class="fa fa-check"></i><b>4.3.2</b> Estimating effects vs. prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dags-1.html"><a href="dags-1.html#dags"><i class="fa fa-check"></i><b>4.4</b> DAGs</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dags-1.html"><a href="dags-1.html#directed-acyclical-graphs"><i class="fa fa-check"></i><b>4.4.1</b> Directed acyclical graphs</a></li>
<li class="chapter" data-level="4.4.2" data-path="dags-1.html"><a href="dags-1.html#patterns-of-relationships"><i class="fa fa-check"></i><b>4.4.2</b> Patterns of relationships</a></li>
<li class="chapter" data-level="4.4.3" data-path="dags-1.html"><a href="dags-1.html#adjustment-set"><i class="fa fa-check"></i><b>4.4.3</b> Adjustment set</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dags-1.html"><a href="dags-1.html#nba-dag"><i class="fa fa-check"></i><b>4.5</b> NBA DAG</a></li>
<li class="chapter" data-level="4.6" data-path="dags-1.html"><a href="dags-1.html#resources"><i class="fa fa-check"></i><b>4.6</b> Resources</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="dags-1.html"><a href="dags-1.html#dagitty.net"><i class="fa fa-check"></i><b>4.6.1</b> dagitty.net</a></li>
<li class="chapter" data-level="4.6.2" data-path="dags-1.html"><a href="dags-1.html#how-to-use-dagitty"><i class="fa fa-check"></i><b>4.6.2</b> How to use dagitty()</a></li>
<li class="chapter" data-level="4.6.3" data-path="dags-1.html"><a href="dags-1.html#more-on-dags"><i class="fa fa-check"></i><b>4.6.3</b> More on DAGs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lin-t-1.html"><a href="lin-t-1.html"><i class="fa fa-check"></i><b>5</b> Linear Regression Theory I: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lin-t-1.html"><a href="lin-t-1.html#objectives-2"><i class="fa fa-check"></i><b>5.1</b> Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="lin-t-1.html"><a href="lin-t-1.html#what-is-linear-regression"><i class="fa fa-check"></i><b>5.2</b> What is Linear Regression</a></li>
<li class="chapter" data-level="5.3" data-path="lin-t-1.html"><a href="lin-t-1.html#examplary-research-question-data"><i class="fa fa-check"></i><b>5.3</b> Examplary research question &amp; data</a></li>
<li class="chapter" data-level="5.4" data-path="lin-t-1.html"><a href="lin-t-1.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.4</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="lin-t-1.html"><a href="lin-t-1.html#regression-formula"><i class="fa fa-check"></i><b>5.4.1</b> Regression Formula</a></li>
<li class="chapter" data-level="5.4.2" data-path="lin-t-1.html"><a href="lin-t-1.html#regressing-grade-on-hours"><i class="fa fa-check"></i><b>5.4.2</b> Regressing <code>grade</code> on <code>hours</code></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="lin-t-1.html"><a href="lin-t-1.html#moving-on-1"><i class="fa fa-check"></i><b>5.5</b> Moving on</a></li>
<li class="chapter" data-level="5.6" data-path="lin-t-1.html"><a href="lin-t-1.html#further-resources-2"><i class="fa fa-check"></i><b>5.6</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lin-t-2.html"><a href="lin-t-2.html"><i class="fa fa-check"></i><b>6</b> Linear Regression Theory II: Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lin-t-2.html"><a href="lin-t-2.html#objectives-3"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="lin-t-2.html"><a href="lin-t-2.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-additional-metric-variables"><i class="fa fa-check"></i><b>6.2.1</b> Adding additional metric variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-dummy-variables"><i class="fa fa-check"></i><b>6.2.2</b> Adding dummy variables</a></li>
<li class="chapter" data-level="6.2.3" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-categorical-variables"><i class="fa fa-check"></i><b>6.2.3</b> Adding categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="lin-t-2.html"><a href="lin-t-2.html#returning-to-our-research-question"><i class="fa fa-check"></i><b>6.3</b> Returning to our research question</a></li>
<li class="chapter" data-level="6.4" data-path="lin-t-2.html"><a href="lin-t-2.html#adressing-the-uncertainty"><i class="fa fa-check"></i><b>6.4</b> Adressing the uncertainty</a></li>
<li class="chapter" data-level="6.5" data-path="lin-t-2.html"><a href="lin-t-2.html#moving-on-2"><i class="fa fa-check"></i><b>6.5</b> Moving on</a></li>
<li class="chapter" data-level="6.6" data-path="lin-t-2.html"><a href="lin-t-2.html#further-resources-3"><i class="fa fa-check"></i><b>6.6</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lin-t-3.html"><a href="lin-t-3.html"><i class="fa fa-check"></i><b>7</b> Linear Regression Theory III: Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lin-t-3.html"><a href="lin-t-3.html#objectives-4"><i class="fa fa-check"></i><b>7.1</b> Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="lin-t-3.html"><a href="lin-t-3.html#model-fit"><i class="fa fa-check"></i><b>7.2</b> Model fit</a></li>
<li class="chapter" data-level="7.3" data-path="lin-t-3.html"><a href="lin-t-3.html#regression-diagnostics"><i class="fa fa-check"></i><b>7.3</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="lin-t-3.html"><a href="lin-t-3.html#linearity"><i class="fa fa-check"></i><b>7.3.1</b> Linearity</a></li>
<li class="chapter" data-level="7.3.2" data-path="lin-t-3.html"><a href="lin-t-3.html#normally-distributed-residuals"><i class="fa fa-check"></i><b>7.3.2</b> Normally distributed residuals</a></li>
<li class="chapter" data-level="7.3.3" data-path="lin-t-3.html"><a href="lin-t-3.html#homoscedasticity"><i class="fa fa-check"></i><b>7.3.3</b> Homoscedasticity</a></li>
<li class="chapter" data-level="7.3.4" data-path="lin-t-3.html"><a href="lin-t-3.html#no-overly-influential-data-points"><i class="fa fa-check"></i><b>7.3.4</b> No overly influential data points</a></li>
<li class="chapter" data-level="7.3.5" data-path="lin-t-3.html"><a href="lin-t-3.html#no-multicollinearity"><i class="fa fa-check"></i><b>7.3.5</b> No (multi)collinearity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="lin-t-3.html"><a href="lin-t-3.html#returning-to-our-research-question-1"><i class="fa fa-check"></i><b>7.4</b> Returning to our research question</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="lin-t-3.html"><a href="lin-t-3.html#interactions"><i class="fa fa-check"></i><b>7.4.1</b> Interactions</a></li>
<li class="chapter" data-level="7.4.2" data-path="lin-t-3.html"><a href="lin-t-3.html#regression-diagnostics-revisited"><i class="fa fa-check"></i><b>7.4.2</b> Regression diagnostics (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="lin-t-3.html"><a href="lin-t-3.html#conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
<li class="chapter" data-level="7.6" data-path="lin-t-3.html"><a href="lin-t-3.html#further-resources-4"><i class="fa fa-check"></i><b>7.6</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lin-a.html"><a href="lin-a.html"><i class="fa fa-check"></i><b>8</b> Linear Regression - Application</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lin-a.html"><a href="lin-a.html#objectives-5"><i class="fa fa-check"></i><b>8.1</b> Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="lin-a.html"><a href="lin-a.html#r-functions-covered-this-week-1"><i class="fa fa-check"></i><b>8.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="8.3" data-path="lin-a.html"><a href="lin-a.html#research-question"><i class="fa fa-check"></i><b>8.3</b> Research question</a></li>
<li class="chapter" data-level="8.4" data-path="lin-a.html"><a href="lin-a.html#simple-linear-regression-in-r"><i class="fa fa-check"></i><b>8.4</b> Simple linear regression in R</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="lin-a.html"><a href="lin-a.html#interpretation"><i class="fa fa-check"></i><b>8.4.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lin-a.html"><a href="lin-a.html#multiple-linear-regression-in-r"><i class="fa fa-check"></i><b>8.5</b> Multiple linear regression in R</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="lin-a.html"><a href="lin-a.html#interpretation-1"><i class="fa fa-check"></i><b>8.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="8.5.2" data-path="lin-a.html"><a href="lin-a.html#sidenote-adding-interactions"><i class="fa fa-check"></i><b>8.5.2</b> Sidenote: Adding interactions</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lin-a.html"><a href="lin-a.html#regression-diagnostics-1"><i class="fa fa-check"></i><b>8.6</b> Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="lin-a.html"><a href="lin-a.html#skewed-outcome-variable"><i class="fa fa-check"></i><b>8.6.1</b> Skewed outcome variable</a></li>
<li class="chapter" data-level="8.6.2" data-path="lin-a.html"><a href="lin-a.html#non-linearity"><i class="fa fa-check"></i><b>8.6.2</b> Non-linearity</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="lin-a.html"><a href="lin-a.html#returning-to-our-research-question-2"><i class="fa fa-check"></i><b>8.7</b> Returning to our research question</a></li>
<li class="chapter" data-level="8.8" data-path="lin-a.html"><a href="lin-a.html#moving-on-3"><i class="fa fa-check"></i><b>8.8</b> Moving on</a></li>
<li class="chapter" data-level="8.9" data-path="lin-a.html"><a href="lin-a.html#further-resources-5"><i class="fa fa-check"></i><b>8.9</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lin-e.html"><a href="lin-e.html"><i class="fa fa-check"></i><b>9</b> Linear Regression - Exercise</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lin-e.html"><a href="lin-e.html#exercises"><i class="fa fa-check"></i><b>9.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="med.html"><a href="med.html"><i class="fa fa-check"></i><b>10</b> Mediation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="med.html"><a href="med.html#objectives-6"><i class="fa fa-check"></i><b>10.1</b> Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="med.html"><a href="med.html#r-functions-covered-this-week-2"><i class="fa fa-check"></i><b>10.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="10.3" data-path="med.html"><a href="med.html#further-resources-6"><i class="fa fa-check"></i><b>10.3</b> Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pm-t.html"><a href="pm-t.html"><i class="fa fa-check"></i><b>11</b> Prediction - Theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pm-t.html"><a href="pm-t.html#objectives-7"><i class="fa fa-check"></i><b>11.1</b> Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="pm-t.html"><a href="pm-t.html#r-functions-covered-this-week-3"><i class="fa fa-check"></i><b>11.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="11.3" data-path="pm-t.html"><a href="pm-t.html#how-prediction-works"><i class="fa fa-check"></i><b>11.3</b> How prediction works</a></li>
<li class="chapter" data-level="11.4" data-path="pm-t.html"><a href="pm-t.html#intro-to-machine-learning"><i class="fa fa-check"></i><b>11.4</b> Intro to Machine learning</a></li>
<li class="chapter" data-level="11.5" data-path="pm-t.html"><a href="pm-t.html#further-resources-7"><i class="fa fa-check"></i><b>11.5</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pm-a.html"><a href="pm-a.html"><i class="fa fa-check"></i><b>12</b> Prediction - Exercise</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pm-a.html"><a href="pm-a.html#exercises-1"><i class="fa fa-check"></i><b>12.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="log-est.html"><a href="log-est.html"><i class="fa fa-check"></i><b>13</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="13.1" data-path="log-est.html"><a href="log-est.html#objectives-8"><i class="fa fa-check"></i><b>13.1</b> Objectives</a></li>
<li class="chapter" data-level="13.2" data-path="log-est.html"><a href="log-est.html#functions-covered-in-this-week"><i class="fa fa-check"></i><b>13.2</b> Functions covered in this week</a></li>
<li class="chapter" data-level="13.3" data-path="log-est.html"><a href="log-est.html#basic-concepts"><i class="fa fa-check"></i><b>13.3</b> Basic concepts</a></li>
<li class="chapter" data-level="13.4" data-path="log-est.html"><a href="log-est.html#application"><i class="fa fa-check"></i><b>13.4</b> Application</a></li>
<li class="chapter" data-level="13.5" data-path="log-est.html"><a href="log-est.html#interpretation-2"><i class="fa fa-check"></i><b>13.5</b> Interpretation</a></li>
<li class="chapter" data-level="13.6" data-path="log-est.html"><a href="log-est.html#model-fit-1"><i class="fa fa-check"></i><b>13.6</b> model fit</a></li>
<li class="chapter" data-level="13.7" data-path="log-est.html"><a href="log-est.html#diagnostics"><i class="fa fa-check"></i><b>13.7</b> diagnostics</a></li>
<li class="chapter" data-level="13.8" data-path="log-est.html"><a href="log-est.html#prediction"><i class="fa fa-check"></i><b>13.8</b> prediction</a></li>
<li class="chapter" data-level="13.9" data-path="log-est.html"><a href="log-est.html#mediation-1"><i class="fa fa-check"></i><b>13.9</b> Mediation</a></li>
<li class="chapter" data-level="13.10" data-path="log-est.html"><a href="log-est.html#comparing-linear-and-logistic-regression"><i class="fa fa-check"></i><b>13.10</b> comparing linear and logistic regression</a></li>
<li class="chapter" data-level="13.11" data-path="log-est.html"><a href="log-est.html#logistic-regression-in-machine-learning-context"><i class="fa fa-check"></i><b>13.11</b> logistic regression in Machine Learning context</a></li>
<li class="chapter" data-level="13.12" data-path="log-est.html"><a href="log-est.html#further-resources-8"><i class="fa fa-check"></i><b>13.12</b> Further resources</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="out-look.html"><a href="out-look.html"><i class="fa fa-check"></i><b>14</b> Outlook</a>
<ul>
<li class="chapter" data-level="14.1" data-path="out-look.html"><a href="out-look.html#summary-of-what-was-covered-in-course"><i class="fa fa-check"></i><b>14.1</b> Summary of what was covered in course</a></li>
<li class="chapter" data-level="14.2" data-path="out-look.html"><a href="out-look.html#other-outcome-variables"><i class="fa fa-check"></i><b>14.2</b> Other outcome variables</a></li>
<li class="chapter" data-level="14.3" data-path="out-look.html"><a href="out-look.html#data-structures"><i class="fa fa-check"></i><b>14.3</b> Data structures</a></li>
<li class="chapter" data-level="14.4" data-path="out-look.html"><a href="out-look.html#where-to-go-next"><i class="fa fa-check"></i><b>14.4</b> Where to go next</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis with R for Social Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pm-t" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number"> 11</span> Prediction - Theory<a href="pm-t.html#pm-t" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In prior weeks, you learned how to build a linear regression model. The main interest
we pursued so far was to arrive at a good estimate of one independent variable (points scored in NBA basketball league) on an outcome (salary of NBA players).</p>
<div id="objectives-7" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Objectives<a href="pm-t.html#objectives-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="objectives">
<ul>
<li>here to be filled</li>
</ul>
</div>
</div>
<div id="r-functions-covered-this-week-3" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> R functions covered this week<a href="pm-t.html#r-functions-covered-this-week-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="functions">
<ul>
<li><code>lm()</code> : This function is used to fit a linear model to the data. It takes a formula that specifies the dependent and independent variables, and a data frame that contains the variables. It returns a model object that can be used for further analysis.</li>
<li><code>predict()</code> : This function is used to make predictions from a fitted model object. It takes a model object and a new data frame that contains the values of the independent variables for which predictions are desired. It returns a vector of predicted values for the dependent variable.</li>
<li><code>sqrt()</code> : This function is used to compute the square root of a numeric vector. It can be used to calculate the root mean squared error (RMSE) as a measure of prediction accuracy.</li>
<li><code>mean()</code> : This function is used to compute the arithmetic mean of a numeric vector. It can be used to calculate the mean squared error (MSE) as a measure of prediction error.</li>
<li><code>createDataPartition()</code> : This function is from the <strong>caret</strong> package. It is used to create a random split of the data into training and testing sets. It takes a vector of outcomes, a proportion of data to be assigned to the training set, and an option to return a list or not. It returns a vector or list of indices for the training set.</li>
<li><code>train()</code> : This function is from the <strong>caret</strong> package. It is used to train a predictive model using different methods and tuning parameters. It takes a formula that specifies the dependent and independent variables, a data frame that contains the training data, a method that specifies the type of model, and a train control object that specifies how to train the model. It returns a model object that can be used for prediction and evaluation.</li>
<li><code>trainControl()</code> : This function is from the <strong>caret</strong> package. It is used to create a train control object that controls how the model is trained. It takes various arguments that specify the resampling method, the number of resamples, the selection metric, etc. It returns a train control object that can be passed to <code>train()</code>.</li>
<li><code>glance()</code> : This function is from the <strong>broom</strong> package. It is used to get a summary of a model object, such as the R-squared, adjusted R-squared, RMSE, p-value, etc. It takes a model object and returns a tibble with one row per model and one column per statistic.</li>
<li><code>augment()</code> : This function is from the <strong>broom</strong> package. It is used to add columns with predictions, residuals, and other information to the original data frame. It takes a model object and an optional new data frame for prediction. It returns a tibble with one row per observation and one column per variable or statistic.</li>
<li><code>ggplot()</code> : This function is from the <strong>ggplot2</strong> package. It is used to create a wide variety of static, dynamic, and interactive graphics in R. The function allows you to specify a mapping from data to aesthetics (color, shape, size) and geometric objects (points, lines, bars). It also allows you to add statistical transformations, coordinate systems, faceting, and themes.</li>
<li><code>geom_point()</code> : This function is from the <strong>ggplot2</strong> package. It is used to create scatter plots in R. It takes a mapping from data to aesthetics and other arguments that control the appearance of the points, such as shape, size, color, alpha, etc. It returns a layer that can be added to a ggplot object.</li>
<li><code>geom_smooth()</code> : This function is from the <strong>ggplot2</strong> package. It is used to add a smoothed conditional mean or regression line to a plot. It takes a mapping from data to aesthetics and other arguments that control the appearance of the line or curve, such as method, formula, color, linetype, etc. It returns a layer that can be added to a ggplot object.</li>
<li><code>geom_line()</code> : This function is from the <strong>ggplot2</strong> package. It is used to create line charts in R. It takes a mapping from data to aesthetics and other arguments that control the appearance of the lines, such as color, line-type, size, alpha, etc. It returns a layer that can be added to a ggplot object.</li>
<li><code>geom_ribbon()</code> : This function is from the <strong>ggplot2</strong> package. It is used to create shaded regions between two y-values in R. It takes a mapping from data to aesthetics and other arguments that control the appearance of the ribbon, such as fill color, alpha value, line-type etc. It returns a layer that can be added to a ggplot object.</li>
<li><code>library()</code> : This function is used to load an installed package into R session so that its functions can be used. It takes one or more package names as arguments and loads them into memory.</li>
</ul>
</div>
<p>With the help of DAGs, we identified relevant “confounders” we should adjust for to “isolate’ the effect of points as much as possible and reduce bias. COnfounders enter as covariates in in the model.</p>
<p>With the help of mediation analysis, we were then interested what “explains” or “mediates” the effect of x on y. We use additional variables which we assume operate as mechanisms of the causal effect of x on y and we test how much of the effect of x and y can be attributed to this mediator. In our example, we found that points scored do not really explain why guards earn less money in the NBA compared to centers.</p>
<p>All what we have done so far can be considered part of causal inference, i.e.
understanding why an outcome varies. A different perspective is the perspective of PREDICTION.Prediction is at the heart of approaches in “data science” and “machine learning”.</p>
<p>In this scenario, we build regression models (or other models) simply to predict and outcome. The main interest is not to learn more about how the outcome can be explained but to predict something with it which we want to know. Machine learning then takes it a step further and simply iteratively select the best models among hundreds of options to arrive at the best possible prediction (more on that at the end of the class). First, we will learn how to predict values based on a linear regression model.</p>
</div>
<div id="how-prediction-works" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> How prediction works<a href="pm-t.html#how-prediction-works" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For a linear regression model, prediction is very straight forward. Linear regression is all about finding a straight line through a cloud of points that lie on as many dimensions as there are variables in model. The model provides you with an intercept (i.e. where the line touches the Y-Axis, and a slope; the increase in y given one unit increase in x. The unit is whatever the scale of the x variable is). The formula is <span class="math inline">\(y= b + ßx + €\)</span>. Any prediction is the on the line. You know the intercept, you plug in a value for x and you get your predicted y.</p>
<p>-&gt; visual here.</p>
<p>Let’s apply this logic to our NBA data. Remember in prior weeks, we built a linear model to estimate the effect of points scored on average per game and salaries of players. Let’s assume we now want to predict salaries of players and don’t care too much about the scores. We can consider a range of variables which we think explain variation in salaries. The better we can capture variation in salaries between players, the more precise our prediction will be.</p>
<p>Now, you may rightfully ask: “Why do we want to predict salaries if we already know the actual salaries!?” Fair point. Prediction is commonly used to predict values which we don’t have. Imagine there are some players that don’t report their salaries. We could predict their salaries based on what we know from players who are similar to them in many other observable characteristics. Or imagine we want to predict the salary of a hypothetical player that does not exist. Imagine an average players would like to know how much he could earn more if player more like other players. We can predict that. Last example, imagine we want to forecast how much a player makes next year, depending on his past performance.</p>
<p>Machine learning is basically predicting outcomes that are no known based on very large datasets. You provide R with a million photos of animals, you build a model to explain which animal is a cat. The you apply the model to new data and the model predicts whether there is a cat in the photo. Of course, machine learning gets much more complicated quickly, however, the basic logic is the logic of prediction.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="pm-t.html#cb135-1" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span></span>
<span id="cb135-2"><a href="pm-t.html#cb135-2" tabindex="-1"></a>             age, <span class="at">data =</span> data_nba)</span>
<span id="cb135-3"><a href="pm-t.html#cb135-3" tabindex="-1"></a></span>
<span id="cb135-4"><a href="pm-t.html#cb135-4" tabindex="-1"></a><span class="co"># base R way to get predicted values</span></span>
<span id="cb135-5"><a href="pm-t.html#cb135-5" tabindex="-1"></a>data_nba<span class="sc">$</span>predicted_values <span class="ot">&lt;-</span> model1<span class="sc">$</span>fitted.values</span>
<span id="cb135-6"><a href="pm-t.html#cb135-6" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="st">&#39;id&#39;</span>, name, salary, predicted_values, <span class="fu">everything</span>())</span>
<span id="cb135-7"><a href="pm-t.html#cb135-7" tabindex="-1"></a></span>
<span id="cb135-8"><a href="pm-t.html#cb135-8" tabindex="-1"></a>data_nba <span class="sc">%&gt;%</span></span>
<span id="cb135-9"><a href="pm-t.html#cb135-9" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>salary, <span class="at">y=</span>predicted_values)) <span class="sc">+</span></span>
<span id="cb135-10"><a href="pm-t.html#cb135-10" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb135-11"><a href="pm-t.html#cb135-11" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_0-1.png" width="672" /></p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="pm-t.html#cb136-1" tabindex="-1"></a><span class="co"># new tidyverse way to get predicted values</span></span>
<span id="cb136-2"><a href="pm-t.html#cb136-2" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb136-3"><a href="pm-t.html#cb136-3" tabindex="-1"></a></span>
<span id="cb136-4"><a href="pm-t.html#cb136-4" tabindex="-1"></a><span class="co"># broom package has nice features to work with models</span></span>
<span id="cb136-5"><a href="pm-t.html#cb136-5" tabindex="-1"></a></span>
<span id="cb136-6"><a href="pm-t.html#cb136-6" tabindex="-1"></a><span class="co"># tidy() converts the model output into a dataframe, makes it easy to process further, e.g. make graphs etc.</span></span>
<span id="cb136-7"><a href="pm-t.html#cb136-7" tabindex="-1"></a><span class="fu">tidy</span>(model1)</span></code></pre></div>
<pre><code>## # A tibble: 25 × 5
##    term                estimate std.error statistic  p.value
##    &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)         -568370.    29308.    -19.4  3.15e-82
##  2 career_PTS            53791.      731.     73.6  0       
##  3 position_recForward -140645.    12779.    -11.0  5.24e-28
##  4 position_recGuard   -208234.    12166.    -17.1  9.89e-65
##  5 position_recMixed   -103661.    12104.     -8.56 1.26e-17
##  6 season_start1999      29357.    22884.      1.28 2.00e- 1
##  7 season_start2000      77209.    23559.      3.28 1.05e- 3
##  8 season_start2001     106436.    23625.      4.51 6.71e- 6
##  9 season_start2002     130348.    23627.      5.52 3.54e- 8
## 10 season_start2003     135221.    23648.      5.72 1.11e- 8
## # ℹ 15 more rows</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="pm-t.html#cb138-1" tabindex="-1"></a><span class="co"># glance provides meta-level info like r-squared etc.</span></span>
<span id="cb138-2"><a href="pm-t.html#cb138-2" tabindex="-1"></a><span class="fu">glance</span>(model1)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared   sigma statistic p.value    df   logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.432         0.431 352361.      308.       0    24 -138041. 2.76e5 2.76e5
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="pm-t.html#cb140-1" tabindex="-1"></a><span class="co"># augment creates a dataframe with the predicted values for everyobservation in the dataframe. </span></span>
<span id="cb140-2"><a href="pm-t.html#cb140-2" tabindex="-1"></a></span>
<span id="cb140-3"><a href="pm-t.html#cb140-3" tabindex="-1"></a>nba_salalary_predicted <span class="ot">&lt;-</span> <span class="fu">augment</span>(model1)</span></code></pre></div>
<p>The output above, get you the predicted values for the observations in the dataset. This is mostly used to evaluate the model itself. The bigger the difference between the predicted values and the actual values (so-called residuals), the worse the model.</p>
<p>Now, let’s predict the salary of hypothetical players:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="pm-t.html#cb141-1" tabindex="-1"></a><span class="fu">table</span>(data_nba<span class="sc">$</span>position_rec)</span></code></pre></div>
<pre><code>## 
##  center Forward   Guard   Mixed 
##    1204    2130    3051    3343</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="pm-t.html#cb143-1" tabindex="-1"></a><span class="co"># create all combination of the control variables which you want to predict</span></span>
<span id="cb143-2"><a href="pm-t.html#cb143-2" tabindex="-1"></a>prediction.data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb143-3"><a href="pm-t.html#cb143-3" tabindex="-1"></a>  <span class="at">position_rec =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;center&quot;</span>, <span class="st">&quot;Guard&quot;</span>, <span class="st">&quot;Guard&quot;</span>),</span>
<span id="cb143-4"><a href="pm-t.html#cb143-4" tabindex="-1"></a>  <span class="at">career_PTS =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">14</span>),</span>
<span id="cb143-5"><a href="pm-t.html#cb143-5" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">20</span>),</span>
<span id="cb143-6"><a href="pm-t.html#cb143-6" tabindex="-1"></a>  <span class="at">season_start =</span> <span class="fu">c</span>(<span class="st">&quot;2017&quot;</span>, <span class="st">&quot;2017&quot;</span>, <span class="st">&quot;2017&quot;</span>, <span class="st">&quot;2017&quot;</span>)</span>
<span id="cb143-7"><a href="pm-t.html#cb143-7" tabindex="-1"></a>)</span>
<span id="cb143-8"><a href="pm-t.html#cb143-8" tabindex="-1"></a></span>
<span id="cb143-9"><a href="pm-t.html#cb143-9" tabindex="-1"></a><span class="co"># apply the model to the &quot;new&quot; dataset</span></span>
<span id="cb143-10"><a href="pm-t.html#cb143-10" tabindex="-1"></a><span class="fu">predict</span>(model1, </span>
<span id="cb143-11"><a href="pm-t.html#cb143-11" tabindex="-1"></a>        prediction.data)</span></code></pre></div>
<pre><code>##        1        2        3        4 
## 675129.3 890294.2 466895.1 682059.9</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="pm-t.html#cb145-1" tabindex="-1"></a>prediction.data<span class="sc">$</span>predicted_values <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, </span>
<span id="cb145-2"><a href="pm-t.html#cb145-2" tabindex="-1"></a>        prediction.data)</span>
<span id="cb145-3"><a href="pm-t.html#cb145-3" tabindex="-1"></a></span>
<span id="cb145-4"><a href="pm-t.html#cb145-4" tabindex="-1"></a>prediction.data <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb145-5"><a href="pm-t.html#cb145-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(position_rec, predicted_values,</span>
<span id="cb145-6"><a href="pm-t.html#cb145-6" tabindex="-1"></a>                 <span class="at">color=</span>career_PTS,</span>
<span id="cb145-7"><a href="pm-t.html#cb145-7" tabindex="-1"></a>                 <span class="at">size=</span><span class="dv">12</span>)) <span class="sc">+</span></span>
<span id="cb145-8"><a href="pm-t.html#cb145-8" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb145-9"><a href="pm-t.html#cb145-9" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_1-1.png" width="672" /></p>
<p>We can see that there is a huge salary increase predicted for just making two more baskets (i.e. 4 points) on average each game, for both guards and centers. We also see that centers make more money generally.</p>
<p>There is another way to get predicted values using the <code>margins()</code> function.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="pm-t.html#cb146-1" tabindex="-1"></a><span class="fu">library</span>(margins)</span>
<span id="cb146-2"><a href="pm-t.html#cb146-2" tabindex="-1"></a><span class="co"># This gets you the average change in predicted value for a unit-increase in the all model variables.</span></span>
<span id="cb146-3"><a href="pm-t.html#cb146-3" tabindex="-1"></a><span class="fu">margins</span>(model1)</span></code></pre></div>
<pre><code>##  career_PTS   age position_recForward position_recGuard position_recMixed
##       53791 16809             -140645           -208234           -103661
##  season_start1999 season_start2000 season_start2001 season_start2002
##             29357            77209           106436           130348
##  season_start2003 season_start2004 season_start2005 season_start2006
##            135221           150576           174625           183653
##  season_start2007 season_start2008 season_start2009 season_start2010
##            206434           231505           204116           192220
##  season_start2011 season_start2012 season_start2013 season_start2014
##            183026           182509           199072           174359
##  season_start2015 season_start2016 season_start2017
##            206791           305228           369398</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="pm-t.html#cb148-1" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">margins</span>(model1, <span class="at">at=</span> <span class="fu">list</span>(<span class="at">position_rec=</span> <span class="fu">c</span>(<span class="st">&quot;Guard&quot;</span>, <span class="st">&quot;center&quot;</span>),</span>
<span id="cb148-2"><a href="pm-t.html#cb148-2" tabindex="-1"></a>                         <span class="at">career_PTS=</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">14</span>))))</span></code></pre></div>
<pre><code>##              factor position_rec career_PTS         AME         SE       z
##                 age       1.0000    10.0000  16809.4290   822.1461 20.4458
##                 age       1.0000    14.0000  16809.4290   821.2659 20.4677
##                 age       2.0000    10.0000  16809.4290   821.3697 20.4651
##                 age       2.0000    14.0000  16809.4290   810.1705 20.7480
##          career_PTS       1.0000    10.0000  53791.2088   673.5739 79.8594
##          career_PTS       1.0000    14.0000  53791.2088   777.6596 69.1706
##          career_PTS       2.0000    10.0000  53791.2088   672.1461 80.0290
##          career_PTS       2.0000    14.0000  53791.2088   869.2152 61.8848
##  position_reccenter       1.0000    10.0000 208234.2670 12165.6828 17.1165
##  position_reccenter       1.0000    14.0000 208234.2670 12165.6828 17.1165
##  position_reccenter       2.0000    10.0000 208234.2670 12165.6828 17.1165
##  position_reccenter       2.0000    14.0000 208234.2670 12165.6828 17.1165
##    season_start1999       1.0000    10.0000  29356.8409 22884.2755  1.2828
##    season_start1999       1.0000    14.0000  29356.8409 22884.2755  1.2828
##    season_start1999       2.0000    10.0000  29356.8409 22884.2755  1.2828
##    season_start1999       2.0000    14.0000  29356.8409 22884.3468  1.2828
##    season_start2000       1.0000    10.0000  77209.1717 23559.4567  3.2772
##    season_start2000       1.0000    14.0000  77209.1717 23559.4567  3.2772
##    season_start2000       2.0000    10.0000  77209.1717 23559.4567  3.2772
##    season_start2000       2.0000    14.0000  77209.1717 23559.4567  3.2772
##    season_start2001       1.0000    10.0000 106435.5787 23624.8634  4.5052
##    season_start2001       1.0000    14.0000 106435.5787 23624.8634  4.5052
##    season_start2001       2.0000    10.0000 106435.5787 23624.8634  4.5052
##    season_start2001       2.0000    14.0000 106435.5787 23624.8621  4.5052
##    season_start2002       1.0000    10.0000 130348.2150 23627.2203  5.5169
##    season_start2002       1.0000    14.0000 130348.2150 23627.2203  5.5169
##    season_start2002       2.0000    10.0000 130348.2150 23627.2203  5.5169
##    season_start2002       2.0000    14.0000 130348.2150 23627.2203  5.5169
##    season_start2003       1.0000    10.0000 135220.5712 23648.3086  5.7180
##    season_start2003       1.0000    14.0000 135220.5712 23648.3086  5.7180
##    season_start2003       2.0000    10.0000 135220.5712 23648.3086  5.7180
##    season_start2003       2.0000    14.0000 135220.5712 23648.3047  5.7180
##    season_start2004       1.0000    10.0000 150575.6148 23423.7814  6.4283
##    season_start2004       1.0000    14.0000 150575.6148 23423.7814  6.4283
##    season_start2004       2.0000    10.0000 150575.6148 23423.7814  6.4283
##    season_start2004       2.0000    14.0000 150575.6148 23416.9662  6.4302
##    season_start2005       1.0000    10.0000 174625.3789 23247.7154  7.5115
##    season_start2005       1.0000    14.0000 174625.3789 23247.7154  7.5115
##    season_start2005       2.0000    10.0000 174625.3789 23247.7154  7.5115
##    season_start2005       2.0000    14.0000 174625.3789 23240.9439  7.5137
##    season_start2006       1.0000    10.0000 183653.2187 23057.8278  7.9649
##    season_start2006       1.0000    14.0000 183653.2187 23071.2667  7.9603
##    season_start2006       2.0000    10.0000 183653.2187 23071.2569  7.9603
##    season_start2006       2.0000    14.0000 183653.2187 23071.2471  7.9603
##    season_start2007       1.0000    10.0000 206434.1344 23336.8298  8.8459
##    season_start2007       1.0000    14.0000 206434.1344 23336.8298  8.8459
##    season_start2007       2.0000    10.0000 206434.1344 23336.8298  8.8459
##    season_start2007       2.0000    14.0000 206434.1344 23330.0326  8.8484
##    season_start2008       1.0000    10.0000 231505.0635 23507.2919  9.8482
##    season_start2008       1.0000    14.0000 231505.0635 23507.2919  9.8482
##    season_start2008       2.0000    10.0000 231505.0635 23507.2919  9.8482
##    season_start2008       2.0000    14.0000 231505.0635 23500.4440  9.8511
##    season_start2009       1.0000    10.0000 204115.6638 23475.4934  8.6948
##    season_start2009       1.0000    14.0000 204115.6638 23489.1731  8.6898
##    season_start2009       2.0000    10.0000 204115.6638 23489.1731  8.6898
##    season_start2009       2.0000    14.0000 204115.6638 23489.1586  8.6898
##    season_start2010       1.0000    10.0000 192219.8545 23548.5054  8.1627
##    season_start2010       1.0000    14.0000 192219.8545 23548.5054  8.1627
##    season_start2010       2.0000    10.0000 192219.8545 23548.5054  8.1627
##    season_start2010       2.0000    14.0000 192219.8545 23555.3511  8.1603
##    season_start2011       1.0000    10.0000 183025.8381 23534.7356  7.7768
##    season_start2011       1.0000    14.0000 183025.8381 23534.7356  7.7768
##    season_start2011       2.0000    10.0000 183025.8381 23534.7356  7.7768
##    season_start2011       2.0000    14.0000 183025.8381 23534.7356  7.7768
##    season_start2012       1.0000    10.0000 182509.4584 23219.2518  7.8603
##    season_start2012       1.0000    14.0000 182509.4584 23219.2518  7.8603
##    season_start2012       2.0000    10.0000 182509.4584 23219.2518  7.8603
##    season_start2012       2.0000    14.0000 182509.4584 23212.4961  7.8626
##    season_start2013       1.0000    10.0000 199072.4713 24314.5882  8.1874
##    season_start2013       1.0000    14.0000 199072.4713 24314.5882  8.1874
##    season_start2013       2.0000    10.0000 199072.4713 24314.5882  8.1874
##    season_start2013       2.0000    14.0000 199072.4713 24321.6667  8.1850
##    season_start2014       1.0000    10.0000 174358.9208 22746.2703  7.6654
##    season_start2014       1.0000    14.0000 174358.9208 22733.0380  7.6698
##    season_start2014       2.0000    10.0000 174358.9208 22733.0380  7.6698
##    season_start2014       2.0000    14.0000 174358.9208 22733.0380  7.6698
##    season_start2015       1.0000    10.0000 206791.4964 22900.6232  9.0300
##    season_start2015       1.0000    14.0000 206791.4964 22887.2931  9.0352
##    season_start2015       2.0000    10.0000 206791.4964 22887.2931  9.0352
##    season_start2015       2.0000    14.0000 206791.4964 22887.3012  9.0352
##    season_start2016       1.0000    10.0000 305227.6577 22617.9191 13.4949
##    season_start2016       1.0000    14.0000 305227.6577 22617.9191 13.4949
##    season_start2016       2.0000    10.0000 305227.6577 22617.9191 13.4949
##    season_start2016       2.0000    14.0000 305227.6577 22617.9191 13.4949
##    season_start2017       1.0000    10.0000 369398.3511 22665.9479 16.2975
##    season_start2017       1.0000    14.0000 369398.3511 22665.9479 16.2975
##    season_start2017       2.0000    10.0000 369398.3511 22665.9479 16.2975
##    season_start2017       2.0000    14.0000 369398.3511 22655.0335 16.3054
##       p       lower       upper
##  0.0000  15198.0523  18420.8057
##  0.0000  15199.7774  18419.0806
##  0.0000  15199.5740  18419.2841
##  0.0000  15221.5240  18397.3341
##  0.0000  52471.0281  55111.3895
##  0.0000  52267.0240  55315.3936
##  0.0000  52473.8267  55108.5909
##  0.0000  52087.5784  55494.8392
##  0.0000 184389.9668 232078.5671
##  0.0000 184389.9668 232078.5671
##  0.0000 184389.9668 232078.5671
##  0.0000 184389.9668 232078.5671
##  0.1995 -15495.5149  74209.1967
##  0.1995 -15495.5149  74209.1967
##  0.1995 -15495.5149  74209.1967
##  0.1995 -15495.6546  74209.3364
##  0.0010  31033.4850 123384.8584
##  0.0010  31033.4850 123384.8584
##  0.0010  31033.4850 123384.8584
##  0.0010  31033.4850 123384.8584
##  0.0000  60131.6973 152739.4600
##  0.0000  60131.6973 152739.4600
##  0.0000  60131.6973 152739.4600
##  0.0000  60131.6998 152739.4575
##  0.0000  84039.7141 176656.7158
##  0.0000  84039.7141 176656.7158
##  0.0000  84039.7141 176656.7158
##  0.0000  84039.7141 176656.7158
##  0.0000  88870.7382 181570.4043
##  0.0000  88870.7382 181570.4043
##  0.0000  88870.7382 181570.4043
##  0.0000  88870.7457 181570.3968
##  0.0000 104665.8469 196485.3827
##  0.0000 104665.8469 196485.3827
##  0.0000 104665.8469 196485.3827
##  0.0000 104679.2044 196472.0252
##  0.0000 129060.6941 220190.0637
##  0.0000 129060.6941 220190.0637
##  0.0000 129060.6941 220190.0637
##  0.0000 129073.9659 220176.7919
##  0.0000 138460.7067 228845.7307
##  0.0000 138434.3670 228872.0704
##  0.0000 138434.3861 228872.0513
##  0.0000 138434.4052 228872.0322
##  0.0000 160694.7885 252173.4804
##  0.0000 160694.7885 252173.4804
##  0.0000 160694.7885 252173.4804
##  0.0000 160708.1107 252160.1581
##  0.0000 185431.6180 277578.5090
##  0.0000 185431.6180 277578.5090
##  0.0000 185431.6180 277578.5090
##  0.0000 185445.0396 277565.0874
##  0.0000 158104.5422 250126.7855
##  0.0000 158077.7306 250153.5971
##  0.0000 158077.7306 250153.5971
##  0.0000 158077.7590 250153.5687
##  0.0000 146065.6320 238374.0769
##  0.0000 146065.6320 238374.0769
##  0.0000 146065.6320 238374.0769
##  0.0000 146052.2146 238387.4943
##  0.0000 136898.6039 229153.0723
##  0.0000 136898.6039 229153.0723
##  0.0000 136898.6039 229153.0723
##  0.0000 136898.6039 229153.0723
##  0.0000 137000.5611 228018.3557
##  0.0000 137000.5611 228018.3557
##  0.0000 137000.5611 228018.3557
##  0.0000 137013.8020 228005.1148
##  0.0000 151416.7540 246728.1885
##  0.0000 151416.7540 246728.1885
##  0.0000 151416.7540 246728.1885
##  0.0000 151402.8805 246742.0621
##  0.0000 129777.0502 218940.7913
##  0.0000 129802.9850 218914.8566
##  0.0000 129802.9850 218914.8566
##  0.0000 129802.9850 218914.8566
##  0.0000 161907.0996 251675.8931
##  0.0000 161933.2262 251649.7666
##  0.0000 161933.2262 251649.7666
##  0.0000 161933.2103 251649.7824
##  0.0000 260897.3510 349557.9645
##  0.0000 260897.3510 349557.9645
##  0.0000 260897.3510 349557.9645
##  0.0000 260897.3510 349557.9645
##  0.0000 324973.9095 413822.7927
##  0.0000 324973.9095 413822.7927
##  0.0000 324973.9095 413822.7927
##  0.0000 324995.3013 413801.4009</code></pre>
<p>The margins function is handy to calculate predictions for different groups.
It automatically can hold other control variables at their mean or at their observed value.</p>
<p>Now, let’s also calculate confidence and prediction intervals. For background, watch these short videos to understand what they are [hyperlink] [hyperlink]. Confidence intervals basically tell how the following: “If we repeated our study on a different sample of people with the same sample size, then the estimate which we have (for example, a mean) would we within the confidence interval 95% of the time. This means in 5% of cases, our study would arrive at a lower or higher mean. The formula for confidence is not very intuitive:</p>
<p>-&gt; formulate here: Margin of error = z * (standard deviation/ square-root of sample size)</p>
<p>Let’s not worry about why this formula works, but let’s focus on its ingredients: Sample size (N) is the number of people in our data; Standard Deviation is a measure for how much individual people deviate from the mean on average, in other words, how much the data spreads around the mean. and z is 1.96 and is derived from probability theory (i.e. in a normal distribution, there is a certain known likelihood that means fall within a range when re-sampling populations). In other words, the confidence intervals tells us how “confident” we can be that our estimate is within the range 95% of times.</p>
<p>Prediction intervals are very similar but only apply to predictions for specfific values. It gives us a measure for “confident” we can be that our prediction would be within the prediction interval (95% of times).</p>
<p>The 95% is an arbitrarily set value which is a standard in research. However, we can also set it at 99% or 90%.</p>
<p>Let’s apply this to our data.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="pm-t.html#cb150-1" tabindex="-1"></a><span class="co"># Just for illustration, let&#39;s take a simple model</span></span>
<span id="cb150-2"><a href="pm-t.html#cb150-2" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS, <span class="at">data =</span> data_nba)</span>
<span id="cb150-3"><a href="pm-t.html#cb150-3" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(model2)</span>
<span id="cb150-4"><a href="pm-t.html#cb150-4" tabindex="-1"></a>preds[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<pre><code>##        1        2        3        4        5        6        7        8 
## 721959.3 346026.1 346026.1 346026.1 346026.1 346026.1 346026.1 346026.1 
##        9       10 
## 346026.1 346026.1</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="pm-t.html#cb152-1" tabindex="-1"></a><span class="co"># using geom_smooth, method=lm will automatically plot the confidence intervals</span></span>
<span id="cb152-2"><a href="pm-t.html#cb152-2" tabindex="-1"></a>data_nba <span class="sc">%&gt;%</span></span>
<span id="cb152-3"><a href="pm-t.html#cb152-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>salary, <span class="at">y=</span>career_PTS)) <span class="sc">+</span></span>
<span id="cb152-4"><a href="pm-t.html#cb152-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb152-5"><a href="pm-t.html#cb152-5" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_3-1.png" width="672" /></p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="pm-t.html#cb153-1" tabindex="-1"></a><span class="co"># let&#39;s get prediction intervals and add them to our dataset</span></span>
<span id="cb153-2"><a href="pm-t.html#cb153-2" tabindex="-1"></a>data_nba_predict <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data_nba, <span class="fu">predict</span>(model2, <span class="at">interval =</span> <span class="fu">c</span>(<span class="st">&quot;prediction&quot;</span>)))</span>
<span id="cb153-3"><a href="pm-t.html#cb153-3" tabindex="-1"></a></span>
<span id="cb153-4"><a href="pm-t.html#cb153-4" tabindex="-1"></a>data_nba_predict <span class="sc">%&gt;%</span></span>
<span id="cb153-5"><a href="pm-t.html#cb153-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span> career_PTS, <span class="at">y=</span>salary)) <span class="sc">+</span></span>
<span id="cb153-6"><a href="pm-t.html#cb153-6" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb153-7"><a href="pm-t.html#cb153-7" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS, <span class="at">y=</span>fit),</span>
<span id="cb153-8"><a href="pm-t.html#cb153-8" tabindex="-1"></a>            <span class="at">col=</span><span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb153-9"><a href="pm-t.html#cb153-9" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lwr),</span>
<span id="cb153-10"><a href="pm-t.html#cb153-10" tabindex="-1"></a>                <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb153-11"><a href="pm-t.html#cb153-11" tabindex="-1"></a>                <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb153-12"><a href="pm-t.html#cb153-12" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>upr),</span>
<span id="cb153-13"><a href="pm-t.html#cb153-13" tabindex="-1"></a>                <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb153-14"><a href="pm-t.html#cb153-14" tabindex="-1"></a>                <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_3-2.png" width="672" /></p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="pm-t.html#cb154-1" tabindex="-1"></a><span class="co"># same using geom_ribbon</span></span>
<span id="cb154-2"><a href="pm-t.html#cb154-2" tabindex="-1"></a>data_nba_predict <span class="sc">%&gt;%</span></span>
<span id="cb154-3"><a href="pm-t.html#cb154-3" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>salary))<span class="sc">+</span></span>
<span id="cb154-4"><a href="pm-t.html#cb154-4" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb154-5"><a href="pm-t.html#cb154-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>fit))<span class="sc">+</span></span>
<span id="cb154-6"><a href="pm-t.html#cb154-6" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>upr,<span class="at">ymin=</span>lwr),<span class="at">color=</span><span class="st">&quot;red&quot;</span>,<span class="at">alpha=</span><span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_3-3.png" width="672" /></p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="pm-t.html#cb155-1" tabindex="-1"></a><span class="do">## do this with tidy approach</span></span>
<span id="cb155-2"><a href="pm-t.html#cb155-2" tabindex="-1"></a></span>
<span id="cb155-3"><a href="pm-t.html#cb155-3" tabindex="-1"></a><span class="co"># get confidnce interval for estimate</span></span>
<span id="cb155-4"><a href="pm-t.html#cb155-4" tabindex="-1"></a><span class="fu">tidy</span>(model2, <span class="at">conf.int =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 7
##   term        estimate std.error statistic  p.value conf.low conf.high
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  -85191.     7642.     -11.1 1.09e-28 -100171.   -70212.
## 2 career_PTS    55284.      745.      74.2 0          53823.    56745.</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="pm-t.html#cb157-1" tabindex="-1"></a><span class="co"># get predictive intervals</span></span>
<span id="cb157-2"><a href="pm-t.html#cb157-2" tabindex="-1"></a><span class="fu">augment</span>(model2, <span class="at">interval=</span> <span class="st">&quot;prediction&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb157-3"><a href="pm-t.html#cb157-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>salary))<span class="sc">+</span></span>
<span id="cb157-4"><a href="pm-t.html#cb157-4" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb157-5"><a href="pm-t.html#cb157-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>.fitted))<span class="sc">+</span></span>
<span id="cb157-6"><a href="pm-t.html#cb157-6" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>.upper,<span class="at">ymin=</span>.lower),<span class="at">color=</span><span class="st">&quot;red&quot;</span>,<span class="at">alpha=</span><span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_3-4.png" width="672" /></p>
<p>Now, let’s compare the prediction interval for 2 different models.To compare the performance of models, you can use the r-squared (which measures how much of the variation in the outcome can be explained by your set of independent variables) and the mean squared error. For more background on both measures see <a href="https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/">here</a></p>
<p>The Mean squared error (MSE) represents the error of the estimator or predictive model created based on the given set of observations in the sample. It measures the average squared difference between the predicted values and the actual values, quantifying the discrepancy between the model’s predictions and the true observations. The lower the <code>MSE</code>, the better the model predictive accuracy, and, the better the regression model is.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="pm-t.html#cb158-1" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span></span>
<span id="cb158-2"><a href="pm-t.html#cb158-2" tabindex="-1"></a>             age, <span class="at">data =</span> data_nba)</span>
<span id="cb158-3"><a href="pm-t.html#cb158-3" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS, <span class="at">data =</span> data_nba)</span>
<span id="cb158-4"><a href="pm-t.html#cb158-4" tabindex="-1"></a></span>
<span id="cb158-5"><a href="pm-t.html#cb158-5" tabindex="-1"></a><span class="co"># compared R-squared/ adjusted R-squared</span></span>
<span id="cb158-6"><a href="pm-t.html#cb158-6" tabindex="-1"></a><span class="fu">glance</span>(model1)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared   sigma statistic p.value    df   logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.432         0.431 352361.      308.       0    24 -138041. 2.76e5 2.76e5
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="pm-t.html#cb160-1" tabindex="-1"></a><span class="fu">glance</span>(model2)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared   sigma statistic p.value    df   logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.361         0.361 373217.     5502.       0     1 -138612. 2.77e5 2.77e5
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="pm-t.html#cb162-1" tabindex="-1"></a><span class="co"># compare prediction intervals</span></span>
<span id="cb162-2"><a href="pm-t.html#cb162-2" tabindex="-1"></a>model1_predicted <span class="ot">&lt;-</span> <span class="fu">augment</span>(model1, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb162-3"><a href="pm-t.html#cb162-3" tabindex="-1"></a>model2_predicted <span class="ot">&lt;-</span> <span class="fu">augment</span>(model2, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb162-4"><a href="pm-t.html#cb162-4" tabindex="-1"></a></span>
<span id="cb162-5"><a href="pm-t.html#cb162-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>salary), <span class="at">data =</span> model1_predicted)<span class="sc">+</span></span>
<span id="cb162-6"><a href="pm-t.html#cb162-6" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb162-7"><a href="pm-t.html#cb162-7" tabindex="-1"></a>  <span class="co"># geom_line(aes(x=career_pts,y=.fitted),</span></span>
<span id="cb162-8"><a href="pm-t.html#cb162-8" tabindex="-1"></a>  <span class="co">#           color =&quot;red&quot;, data = model1_predicted) +</span></span>
<span id="cb162-9"><a href="pm-t.html#cb162-9" tabindex="-1"></a>  <span class="co"># geom_line(aes(x=career_pts,y=.fitted),</span></span>
<span id="cb162-10"><a href="pm-t.html#cb162-10" tabindex="-1"></a>  <span class="co">#          color =&quot;blue&quot;, data = model2_predicted) +</span></span>
<span id="cb162-11"><a href="pm-t.html#cb162-11" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>.upper,<span class="at">ymin=</span>.lower),</span>
<span id="cb162-12"><a href="pm-t.html#cb162-12" tabindex="-1"></a>              <span class="at">color=</span><span class="st">&quot;red&quot;</span>,</span>
<span id="cb162-13"><a href="pm-t.html#cb162-13" tabindex="-1"></a>              <span class="at">alpha=</span><span class="fl">0.7</span>,</span>
<span id="cb162-14"><a href="pm-t.html#cb162-14" tabindex="-1"></a>              <span class="at">data =</span> model1_predicted) <span class="sc">+</span></span>
<span id="cb162-15"><a href="pm-t.html#cb162-15" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>.upper,<span class="at">ymin=</span>.lower),</span>
<span id="cb162-16"><a href="pm-t.html#cb162-16" tabindex="-1"></a>              <span class="at">color=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb162-17"><a href="pm-t.html#cb162-17" tabindex="-1"></a>              <span class="at">alpha=</span><span class="fl">0.7</span>,</span>
<span id="cb162-18"><a href="pm-t.html#cb162-18" tabindex="-1"></a>              <span class="at">data =</span> model2_predicted)</span></code></pre></div>
<p><img src="_main_files/figure-html/pred_th_4-1.png" width="672" /></p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="pm-t.html#cb163-1" tabindex="-1"></a><span class="co"># see if there is a better way to do this</span></span>
<span id="cb163-2"><a href="pm-t.html#cb163-2" tabindex="-1"></a></span>
<span id="cb163-3"><a href="pm-t.html#cb163-3" tabindex="-1"></a><span class="fu">library</span>(Metrics) <span class="co"># using rmse from Metrics library</span></span>
<span id="cb163-4"><a href="pm-t.html#cb163-4" tabindex="-1"></a><span class="co"># compare mean squared error</span></span>
<span id="cb163-5"><a href="pm-t.html#cb163-5" tabindex="-1"></a>  <span class="fu">rmse</span>(model1_predicted<span class="sc">$</span>.fitted, data_nba<span class="sc">$</span>salary)</span></code></pre></div>
<pre><code>## [1] 351908.3</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="pm-t.html#cb165-1" tabindex="-1"></a>  <span class="fu">rmse</span>(model2_predicted<span class="sc">$</span>.fitted, data_nba<span class="sc">$</span>salary)</span></code></pre></div>
<pre><code>## [1] 373178.4</code></pre>
<p>Looking at <code>r2</code>, the <code>prediction intervals</code> and <code>rmse</code>, model 1 clearly performs better than model 2.</p>
</div>
<div id="intro-to-machine-learning" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Intro to Machine learning<a href="pm-t.html#intro-to-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have now arrived at the entry gates to machine learning. We will conduct a very basic and simple machine learning routine using linear regression. The main difference between simple prediction and Machine Learning is that the sample is first divided into a training and a test dataset at random. The model is than tuned based on, let’s say, 80% of the sample. When the model is ready, it is tested based on the 20% remaining sample. The prediction produced with the model are then compared with the actual values in the test dataset. There is of course more nuance to all this, but this is basically the idea.</p>
<p>Let’s use the <code>caret</code> package, a common package for machine learning.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="pm-t.html#cb167-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb167-2"><a href="pm-t.html#cb167-2" tabindex="-1"></a><span class="co">#data transformation</span></span>
<span id="cb167-3"><a href="pm-t.html#cb167-3" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span> </span>
<span id="cb167-4"><a href="pm-t.html#cb167-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">salary_log =</span> <span class="fu">log</span>(salary))</span>
<span id="cb167-5"><a href="pm-t.html#cb167-5" tabindex="-1"></a></span>
<span id="cb167-6"><a href="pm-t.html#cb167-6" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span> </span>
<span id="cb167-7"><a href="pm-t.html#cb167-7" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">PTS_centered =</span> career_PTS <span class="sc">-</span> <span class="fu">mean</span>(career_PTS))</span>
<span id="cb167-8"><a href="pm-t.html#cb167-8" tabindex="-1"></a></span>
<span id="cb167-9"><a href="pm-t.html#cb167-9" tabindex="-1"></a><span class="co"># Create a train and test split</span></span>
<span id="cb167-10"><a href="pm-t.html#cb167-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb167-11"><a href="pm-t.html#cb167-11" tabindex="-1"></a>train_indices <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(data_nba<span class="sc">$</span>salary, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb167-12"><a href="pm-t.html#cb167-12" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> data_nba[train_indices, ]</span>
<span id="cb167-13"><a href="pm-t.html#cb167-13" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> data_nba[<span class="sc">-</span>train_indices, ]</span>
<span id="cb167-14"><a href="pm-t.html#cb167-14" tabindex="-1"></a></span>
<span id="cb167-15"><a href="pm-t.html#cb167-15" tabindex="-1"></a><span class="co"># Create a train control object with &quot;cross-validation&quot; for comparing results</span></span>
<span id="cb167-16"><a href="pm-t.html#cb167-16" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>) </span>
<span id="cb167-17"><a href="pm-t.html#cb167-17" tabindex="-1"></a></span>
<span id="cb167-18"><a href="pm-t.html#cb167-18" tabindex="-1"></a><span class="co"># Train a linear regression model using caret</span></span>
<span id="cb167-19"><a href="pm-t.html#cb167-19" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb167-20"><a href="pm-t.html#cb167-20" tabindex="-1"></a>  salary <span class="sc">~</span> career_PTS <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span> age,</span>
<span id="cb167-21"><a href="pm-t.html#cb167-21" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb167-22"><a href="pm-t.html#cb167-22" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb167-23"><a href="pm-t.html#cb167-23" tabindex="-1"></a>  <span class="at">trControl =</span> ctrl</span>
<span id="cb167-24"><a href="pm-t.html#cb167-24" tabindex="-1"></a>)</span>
<span id="cb167-25"><a href="pm-t.html#cb167-25" tabindex="-1"></a></span>
<span id="cb167-26"><a href="pm-t.html#cb167-26" tabindex="-1"></a></span>
<span id="cb167-27"><a href="pm-t.html#cb167-27" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb167-28"><a href="pm-t.html#cb167-28" tabindex="-1"></a>  salary <span class="sc">~</span> career_PTS,</span>
<span id="cb167-29"><a href="pm-t.html#cb167-29" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb167-30"><a href="pm-t.html#cb167-30" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb167-31"><a href="pm-t.html#cb167-31" tabindex="-1"></a>  <span class="at">trControl =</span> ctrl</span>
<span id="cb167-32"><a href="pm-t.html#cb167-32" tabindex="-1"></a>)</span>
<span id="cb167-33"><a href="pm-t.html#cb167-33" tabindex="-1"></a></span>
<span id="cb167-34"><a href="pm-t.html#cb167-34" tabindex="-1"></a></span>
<span id="cb167-35"><a href="pm-t.html#cb167-35" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb167-36"><a href="pm-t.html#cb167-36" tabindex="-1"></a>predicted_salaries_m1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, <span class="at">newdata =</span> test_data)</span>
<span id="cb167-37"><a href="pm-t.html#cb167-37" tabindex="-1"></a>predicted_salaries_m2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model2, <span class="at">newdata =</span> test_data)</span>
<span id="cb167-38"><a href="pm-t.html#cb167-38" tabindex="-1"></a></span>
<span id="cb167-39"><a href="pm-t.html#cb167-39" tabindex="-1"></a></span>
<span id="cb167-40"><a href="pm-t.html#cb167-40" tabindex="-1"></a><span class="co"># Calculate prediction errors (e.g., root mean squared error)</span></span>
<span id="cb167-41"><a href="pm-t.html#cb167-41" tabindex="-1"></a>rmse1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((predicted_salaries_m1 <span class="sc">-</span> test_data<span class="sc">$</span>salary)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb167-42"><a href="pm-t.html#cb167-42" tabindex="-1"></a>rmse2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((predicted_salaries_m2 <span class="sc">-</span> test_data<span class="sc">$</span>salary)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb167-43"><a href="pm-t.html#cb167-43" tabindex="-1"></a></span>
<span id="cb167-44"><a href="pm-t.html#cb167-44" tabindex="-1"></a><span class="co"># Print the prediction errors</span></span>
<span id="cb167-45"><a href="pm-t.html#cb167-45" tabindex="-1"></a><span class="fu">print</span>(rmse1)</span></code></pre></div>
<pre><code>## [1] 341746.4</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="pm-t.html#cb169-1" tabindex="-1"></a><span class="fu">print</span>(rmse2)</span></code></pre></div>
<pre><code>## [1] 360297.3</code></pre>
<p>Let us create a similar model from week <a href="lin-a.html#lin-a">8</a> where we have applied <code>log</code> transformation on <code>salary</code>, centered and squared on <code>career_PTS</code> .</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="pm-t.html#cb171-1" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb171-2"><a href="pm-t.html#cb171-2" tabindex="-1"></a>  salary_log <span class="sc">~</span> PTS_centered <span class="sc">+</span> <span class="fu">I</span>(career_PTS<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span> age,</span>
<span id="cb171-3"><a href="pm-t.html#cb171-3" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb171-4"><a href="pm-t.html#cb171-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb171-5"><a href="pm-t.html#cb171-5" tabindex="-1"></a>  <span class="at">trControl =</span> ctrl</span>
<span id="cb171-6"><a href="pm-t.html#cb171-6" tabindex="-1"></a>)</span>
<span id="cb171-7"><a href="pm-t.html#cb171-7" tabindex="-1"></a></span>
<span id="cb171-8"><a href="pm-t.html#cb171-8" tabindex="-1"></a>predicted_salaries_m3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model3, <span class="at">newdata =</span> test_data)</span>
<span id="cb171-9"><a href="pm-t.html#cb171-9" tabindex="-1"></a>rmse3 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((predicted_salaries_m3 <span class="sc">-</span> test_data<span class="sc">$</span>salary)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb171-10"><a href="pm-t.html#cb171-10" tabindex="-1"></a><span class="fu">print</span>(rmse3)</span></code></pre></div>
<pre><code>## [1] 608450.3</code></pre>
<p>We can compare the <span class="math inline">\(R^2\)</span> for all these 3 models:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="pm-t.html#cb173-1" tabindex="-1"></a>model1<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##   intercept     RMSE  Rsquared      MAE   RMSESD RsquaredSD    MAESD
## 1      TRUE 357678.7 0.4269381 255031.8 13553.71 0.04805627 7978.429</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="pm-t.html#cb175-1" tabindex="-1"></a>model2<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##   intercept   RMSE  Rsquared      MAE   RMSESD RsquaredSD   MAESD
## 1      TRUE 378428 0.3573984 263345.1 14136.21 0.02909487 7617.53</code></pre>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="pm-t.html#cb177-1" tabindex="-1"></a>model3<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##   intercept     RMSE  Rsquared       MAE     RMSESD RsquaredSD      MAESD
## 1      TRUE 1.033246 0.4146554 0.7875945 0.03299419 0.02357306 0.01866733</code></pre>
<p><em><span class="math inline">\(R^2\)</span> is a measure of how well a model fits the data. It ranges from 0 to 1, with higher values indicating better fit.</em></p>
<ul>
<li><p><code>model1</code> is a linear regression model that uses <code>career_PTS</code>, <code>position_rec</code>, <code>season_start</code> and <code>age</code> as predictors of <code>salary</code>. It has an <span class="math inline">\(R^2\)</span> value of <em>0.432</em>, which means that it explains about <em>43%</em> of the variation in salary.</p></li>
<li><p><code>model2</code> is a linear regression model that uses only <code>career_PTS</code> as a predictor of <code>salary</code>. It has an <span class="math inline">\(R^2\)</span> value of <em>0.361</em>, which means that it explains about <em>36%</em> of the variation in salary.</p></li>
<li><p><code>model3</code> is a machine learning model that uses the caret package to train a predictive model using <code>log</code> transformation on <code>salary</code>, centered and squared on <code>career_PTS</code>. It has an <span class="math inline">\(R^2\)</span> value of <em>0.415</em>, which means that it explains about <em>41%</em> of the variation in salary.</p></li>
</ul>
<p>Based on these results, we can see that <code>model1</code> has the highest <span class="math inline">\(R^2\)</span> value among the three models, followed by <code>model3</code> and then <code>model2</code>. This suggests that <code>model1</code> is the best model for predicting salary based on the given data.</p>
<p>Now machine learning usually involves several more steps:</p>
<ul>
<li><p>we can optimize how the variables (in ML language called <em>features</em>) enter the model (Pre-processing; transformations; diagnostics, see week <a href="eda-1.html#eda-1">2</a>)</p></li>
<li><p>we can optimize which variables should even enter the model (<em>feature selection</em>, see e.g. <code>lasso regression</code>)</p></li>
<li><p>we can optimize how the predictions of the model get evaluated (<em>training</em>)</p></li>
<li><p>we can optimize which estimator or algorithm best predicts the outcome (<code>lm</code> model is just one option among many)</p></li>
<li><p>for other algorithms (e.g. <code>random forests</code>), we can also <em>tune</em> the model using <em>hyper-parameters</em>.</p></li>
</ul>
</div>
<div id="further-resources-7" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> Further resources<a href="pm-t.html#further-resources-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="resources">
<ul>
<li><a href="https://www.dataquest.io/blog/statistical-learning-for-predictive-modeling-r/">Linear Regression for Predictive Modeling in R - Dataquest</a>: This is a blog post that explains how to use linear regression for predictive modeling in R, using the trees data set as an example. It covers how to fit, visualize, and evaluate linear regression models, as well as how to calculate confidence and prediction intervals.</li>
<li><a href="https://www.tidyverse.org/">Tidyverse</a>: This is a collection of R packages designed for data science. It includes packages for data manipulation, visualization, modeling, and more. It also provides a consistent and coherent syntax and data structures for working with data in R.</li>
<li><a href="http://www.sthda.com/english/articles/40-regression-analysis/166-predict-in-r-model-predictions-and-confidence-intervals/">Predict in R: Model Predictions and Confidence Intervals - STHDA</a>: This is a web page that shows how to use the predict() function in R to make predictions from a fitted model object. It also explains the difference between confidence intervals and prediction intervals, and how to calculate them using base R or the broom package.</li>
<li><a href="https://lgatto.github.io/IntroMachineLearningWithR/">An Introduction to Machine Learning with R</a>: This is an online book that introduces the basic concepts and techniques of machine learning with R. It covers topics such as supervised and unsupervised learning, classification, regression, clustering, dimensionality reduction, and model evaluation. It also provides examples of applying machine learning methods to real-world data sets.</li>
</ul>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="med.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pm-a.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/11-prediction-theory.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
