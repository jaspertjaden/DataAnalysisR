<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 11 Prediction - Theory | Data Analysis with R for Social Scientists</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content=" 11 Prediction - Theory | Data Analysis with R for Social Scientists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="jaspertjaden/DataAnalysisR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 11 Prediction - Theory | Data Analysis with R for Social Scientists" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Jakob Tures &amp; Jasper Tjaden" />


<meta name="date" content="2023-08-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="med.html"/>
<link rel="next" href="pm-a.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="intro-sem.html"><a href="intro-sem.html"><i class="fa fa-check"></i><b>1</b> Introduction to Seminar</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro-sem.html"><a href="intro-sem.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="intro-sem.html"><a href="intro-sem.html#why-should-i-take-this-course"><i class="fa fa-check"></i><b>1.2</b> Why should I take this course?</a></li>
<li class="chapter" data-level="1.3" data-path="intro-sem.html"><a href="intro-sem.html#objectives"><i class="fa fa-check"></i><b>1.3</b> Objectives</a></li>
<li class="chapter" data-level="1.4" data-path="intro-sem.html"><a href="intro-sem.html#what-is-not-covered"><i class="fa fa-check"></i><b>1.4</b> What is not covered</a></li>
<li class="chapter" data-level="1.5" data-path="intro-sem.html"><a href="intro-sem.html#prerequisites"><i class="fa fa-check"></i><b>1.5</b> Prerequisites</a></li>
<li class="chapter" data-level="1.6" data-path="intro-sem.html"><a href="intro-sem.html#structure"><i class="fa fa-check"></i><b>1.6</b> Structure</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="eda-1.html"><a href="eda-1.html"><i class="fa fa-check"></i><b>2</b> Exloratory Data Analysis - I</a>
<ul>
<li class="chapter" data-level="2.1" data-path="eda-1.html"><a href="eda-1.html#objectives-1"><i class="fa fa-check"></i><b>2.1</b> Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="eda-1.html"><a href="eda-1.html#r-functions-covered-this-week"><i class="fa fa-check"></i><b>2.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="2.3" data-path="eda-1.html"><a href="eda-1.html#why-is-eda-so-important"><i class="fa fa-check"></i><b>2.3</b> Why is EDA so important?</a></li>
<li class="chapter" data-level="2.4" data-path="eda-1.html"><a href="eda-1.html#importing-data-into-r"><i class="fa fa-check"></i><b>2.4</b> Importing data into R</a></li>
<li class="chapter" data-level="2.5" data-path="eda-1.html"><a href="eda-1.html#import-data-into-r"><i class="fa fa-check"></i><b>2.5</b> Import data into R</a></li>
<li class="chapter" data-level="2.6" data-path="eda-1.html"><a href="eda-1.html#merge-datasets"><i class="fa fa-check"></i><b>2.6</b> Merge datasets</a></li>
<li class="chapter" data-level="2.7" data-path="eda-1.html"><a href="eda-1.html#clean-dataset"><i class="fa fa-check"></i><b>2.7</b> Clean dataset</a></li>
<li class="chapter" data-level="2.8" data-path="eda-1.html"><a href="eda-1.html#change-variables"><i class="fa fa-check"></i><b>2.8</b> change variables</a></li>
<li class="chapter" data-level="2.9" data-path="eda-1.html"><a href="eda-1.html#explore-the-whole-dataset"><i class="fa fa-check"></i><b>2.9</b> Explore the whole dataset</a></li>
<li class="chapter" data-level="2.10" data-path="eda-1.html"><a href="eda-1.html#explore-individual-variables"><i class="fa fa-check"></i><b>2.10</b> explore individual variables</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda-2.html"><a href="eda-2.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis - II</a>
<ul>
<li class="chapter" data-level="3.1" data-path="eda-2.html"><a href="eda-2.html#markdown-introduction"><i class="fa fa-check"></i><b>3.1</b> Markdown Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="eda-2.html"><a href="eda-2.html#applying-edawvsown-data"><i class="fa fa-check"></i><b>3.2</b> Applying EDA(WVS/own data)</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="eda-2.html"><a href="eda-2.html#exercise---1"><i class="fa fa-check"></i><b>3.2.1</b> Exercise - 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dags-1.html"><a href="dags-1.html"><i class="fa fa-check"></i><b>4</b> DAGs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dags-1.html"><a href="dags-1.html#objectives-2"><i class="fa fa-check"></i><b>4.1</b> Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="dags-1.html"><a href="dags-1.html#modelling"><i class="fa fa-check"></i><b>4.2</b> Modelling</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dags-1.html"><a href="dags-1.html#what-is-modelling"><i class="fa fa-check"></i><b>4.2.1</b> What is modelling?</a></li>
<li class="chapter" data-level="4.2.2" data-path="dags-1.html"><a href="dags-1.html#estimating-effects-vs.-prediction"><i class="fa fa-check"></i><b>4.2.2</b> Estimating effects vs. prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dags-1.html"><a href="dags-1.html#dags"><i class="fa fa-check"></i><b>4.3</b> DAGs</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dags-1.html"><a href="dags-1.html#directed-acyclical-graphs"><i class="fa fa-check"></i><b>4.3.1</b> Directed acyclical graphs</a></li>
<li class="chapter" data-level="4.3.2" data-path="dags-1.html"><a href="dags-1.html#patterns-of-relationships"><i class="fa fa-check"></i><b>4.3.2</b> Patterns of relationships</a></li>
<li class="chapter" data-level="4.3.3" data-path="dags-1.html"><a href="dags-1.html#adjustment-set"><i class="fa fa-check"></i><b>4.3.3</b> Adjustment set</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dags-1.html"><a href="dags-1.html#nba-dag"><i class="fa fa-check"></i><b>4.4</b> NBA DAG</a></li>
<li class="chapter" data-level="4.5" data-path="dags-1.html"><a href="dags-1.html#resources"><i class="fa fa-check"></i><b>4.5</b> Resources</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="dags-1.html"><a href="dags-1.html#dagitty.net"><i class="fa fa-check"></i><b>4.5.1</b> dagitty.net</a></li>
<li class="chapter" data-level="4.5.2" data-path="dags-1.html"><a href="dags-1.html#more-on-dags"><i class="fa fa-check"></i><b>4.5.2</b> More on DAGs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lin-t-1.html"><a href="lin-t-1.html"><i class="fa fa-check"></i><b>5</b> Linear Regression Theory I: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lin-t-1.html"><a href="lin-t-1.html#objectives-3"><i class="fa fa-check"></i><b>5.1</b> Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="lin-t-1.html"><a href="lin-t-1.html#what-is-linear-regression"><i class="fa fa-check"></i><b>5.2</b> What is Linear Regression</a></li>
<li class="chapter" data-level="5.3" data-path="lin-t-1.html"><a href="lin-t-1.html#examplary-research-question-data"><i class="fa fa-check"></i><b>5.3</b> Examplary research question &amp; data</a></li>
<li class="chapter" data-level="5.4" data-path="lin-t-1.html"><a href="lin-t-1.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.4</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="lin-t-1.html"><a href="lin-t-1.html#regression-formula"><i class="fa fa-check"></i><b>5.4.1</b> Regression Formula</a></li>
<li class="chapter" data-level="5.4.2" data-path="lin-t-1.html"><a href="lin-t-1.html#regressing-grade-on-hours"><i class="fa fa-check"></i><b>5.4.2</b> Regressing <code>grade</code> on <code>hours</code></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="lin-t-1.html"><a href="lin-t-1.html#moving-on"><i class="fa fa-check"></i><b>5.5</b> Moving on</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lin-t-2.html"><a href="lin-t-2.html"><i class="fa fa-check"></i><b>6</b> Linear Regression Theory II: Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lin-t-2.html"><a href="lin-t-2.html#objectives-4"><i class="fa fa-check"></i><b>6.1</b> Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="lin-t-2.html"><a href="lin-t-2.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-additional-metric-variables"><i class="fa fa-check"></i><b>6.2.1</b> Adding additional metric variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-dummy-variables"><i class="fa fa-check"></i><b>6.2.2</b> Adding dummy variables</a></li>
<li class="chapter" data-level="6.2.3" data-path="lin-t-2.html"><a href="lin-t-2.html#adding-categorical-variables"><i class="fa fa-check"></i><b>6.2.3</b> Adding categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="lin-t-2.html"><a href="lin-t-2.html#returning-to-our-research-question"><i class="fa fa-check"></i><b>6.3</b> Returning to our research question</a></li>
<li class="chapter" data-level="6.4" data-path="lin-t-2.html"><a href="lin-t-2.html#adressing-the-uncertainty"><i class="fa fa-check"></i><b>6.4</b> Adressing the uncertainty</a></li>
<li class="chapter" data-level="6.5" data-path="lin-t-2.html"><a href="lin-t-2.html#moving-on-1"><i class="fa fa-check"></i><b>6.5</b> Moving on</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="log-t-3.html"><a href="log-t-3.html"><i class="fa fa-check"></i><b>7</b> Linear Regression Theory III: Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="log-t-3.html"><a href="log-t-3.html#objectives-5"><i class="fa fa-check"></i><b>7.1</b> Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="log-t-3.html"><a href="log-t-3.html#model-fit"><i class="fa fa-check"></i><b>7.2</b> Model fit</a></li>
<li class="chapter" data-level="7.3" data-path="log-t-3.html"><a href="log-t-3.html#regression-diagnostics"><i class="fa fa-check"></i><b>7.3</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="log-t-3.html"><a href="log-t-3.html#linearity"><i class="fa fa-check"></i><b>7.3.1</b> Linearity</a></li>
<li class="chapter" data-level="7.3.2" data-path="log-t-3.html"><a href="log-t-3.html#normally-distributed-residuals"><i class="fa fa-check"></i><b>7.3.2</b> Normally distributed residuals</a></li>
<li class="chapter" data-level="7.3.3" data-path="log-t-3.html"><a href="log-t-3.html#homoscedasticity"><i class="fa fa-check"></i><b>7.3.3</b> Homoscedasticity</a></li>
<li class="chapter" data-level="7.3.4" data-path="log-t-3.html"><a href="log-t-3.html#no-overly-influential-data-points"><i class="fa fa-check"></i><b>7.3.4</b> No overly influential data points</a></li>
<li class="chapter" data-level="7.3.5" data-path="log-t-3.html"><a href="log-t-3.html#no-multicollinearity"><i class="fa fa-check"></i><b>7.3.5</b> No (multi)collinearity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="log-t-3.html"><a href="log-t-3.html#returning-to-our-research-question-1"><i class="fa fa-check"></i><b>7.4</b> Returning to our research question</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="log-t-3.html"><a href="log-t-3.html#interactions"><i class="fa fa-check"></i><b>7.4.1</b> Interactions</a></li>
<li class="chapter" data-level="7.4.2" data-path="log-t-3.html"><a href="log-t-3.html#regression-diagnostics-revisited"><i class="fa fa-check"></i><b>7.4.2</b> Regression diagnostics (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="log-t-3.html"><a href="log-t-3.html#conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lin-a.html"><a href="lin-a.html"><i class="fa fa-check"></i><b>8</b> Linear Regression - Application</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lin-a.html"><a href="lin-a.html#objectives-6"><i class="fa fa-check"></i><b>8.1</b> Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="lin-a.html"><a href="lin-a.html#r-functions-covered-this-week-1"><i class="fa fa-check"></i><b>8.2</b> R functions covered this week</a></li>
<li class="chapter" data-level="8.3" data-path="lin-a.html"><a href="lin-a.html#research-question"><i class="fa fa-check"></i><b>8.3</b> Research question</a></li>
<li class="chapter" data-level="8.4" data-path="lin-a.html"><a href="lin-a.html#simple-linear-regression-in-r"><i class="fa fa-check"></i><b>8.4</b> Simple linear regression in R</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="lin-a.html"><a href="lin-a.html#interpretation"><i class="fa fa-check"></i><b>8.4.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lin-a.html"><a href="lin-a.html#multiple-linear-regression-in-r"><i class="fa fa-check"></i><b>8.5</b> Multiple linear regression in R</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="lin-a.html"><a href="lin-a.html#interpretation-1"><i class="fa fa-check"></i><b>8.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="8.5.2" data-path="lin-a.html"><a href="lin-a.html#sidenote-adding-interactions"><i class="fa fa-check"></i><b>8.5.2</b> Sidenote: Adding interactions</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lin-a.html"><a href="lin-a.html#regression-diagnostics-1"><i class="fa fa-check"></i><b>8.6</b> Regression Diagnostics</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="lin-a.html"><a href="lin-a.html#skewed-outcome-variable"><i class="fa fa-check"></i><b>8.6.1</b> Skewed outcome variable</a></li>
<li class="chapter" data-level="8.6.2" data-path="lin-a.html"><a href="lin-a.html#non-linearity"><i class="fa fa-check"></i><b>8.6.2</b> Non-linearity</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="lin-a.html"><a href="lin-a.html#returning-to-our-research-question-2"><i class="fa fa-check"></i><b>8.7</b> Returning to our research question</a></li>
<li class="chapter" data-level="8.8" data-path="lin-a.html"><a href="lin-a.html#moving-on-2"><i class="fa fa-check"></i><b>8.8</b> Moving on</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lin-e.html"><a href="lin-e.html"><i class="fa fa-check"></i><b>9</b> Linear Regression - Exercises</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lin-e.html"><a href="lin-e.html#exercises-of-linear-regression"><i class="fa fa-check"></i><b>9.1</b> Exercises of Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="med.html"><a href="med.html"><i class="fa fa-check"></i><b>10</b> Mediation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="med.html"><a href="med.html#find-out-more"><i class="fa fa-check"></i><b>10.1</b> Find out more</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pm-t.html"><a href="pm-t.html"><i class="fa fa-check"></i><b>11</b> Prediction - Theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pm-t.html"><a href="pm-t.html#how-prediction-works"><i class="fa fa-check"></i><b>11.1</b> How prediction works</a></li>
<li class="chapter" data-level="11.2" data-path="pm-t.html"><a href="pm-t.html#intro-to-machine-learning"><i class="fa fa-check"></i><b>11.2</b> Intro to Machine learning</a></li>
<li class="chapter" data-level="11.3" data-path="pm-t.html"><a href="pm-t.html#more-resources"><i class="fa fa-check"></i><b>11.3</b> More resources:</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pm-a.html"><a href="pm-a.html"><i class="fa fa-check"></i><b>12</b> Prediction - Application</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pm-a.html"><a href="pm-a.html#exercises"><i class="fa fa-check"></i><b>12.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="out-look.html"><a href="out-look.html"><i class="fa fa-check"></i><b>13</b> Outlook</a>
<ul>
<li class="chapter" data-level="13.1" data-path="out-look.html"><a href="out-look.html#summary-of-what-was-covered-in-course"><i class="fa fa-check"></i><b>13.1</b> Summary of what was covered in course</a></li>
<li class="chapter" data-level="13.2" data-path="out-look.html"><a href="out-look.html#other-outcome-variables"><i class="fa fa-check"></i><b>13.2</b> Other outcome variables</a></li>
<li class="chapter" data-level="13.3" data-path="out-look.html"><a href="out-look.html#data-structures"><i class="fa fa-check"></i><b>13.3</b> Data structures</a></li>
<li class="chapter" data-level="13.4" data-path="out-look.html"><a href="out-look.html#where-to-go-next"><i class="fa fa-check"></i><b>13.4</b> Where to go next</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis with R for Social Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pm-t" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number"> 11</span> Prediction - Theory<a href="pm-t.html#pm-t" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In prior weeks, you learned how to build a linear regression model. The main interest
we pursued so far was to arrive at a good estimate of one independent variable (points scored in NBA basketball league) on an outcome (salary of NBA players).</p>
<p>With the help of DAGs, we identified relevant “counfounders” we should adjust for to “isolate’ the effect of points as much as possible and reduce bias. COnfounders enter as covariates in in the model.</p>
<p>With the help of mediation analysis, we were then interested what “explains” or “mediates” the effect of x on y. We use additional variables which we assume operate as mechanisms of the causal effect of x on y and we test how much of the effect of x and y can be attributed to this mediator. In our example, we found that points scored do not really explain why guards earn less money in the NBA compared to centers.</p>
<p>All what we have done so far can be considered part of causal inference, i.e.
understanding why an outcome varies. A different perspective is the perspective of PREDICTION.Prediction is at the heart of appraoches in “data science” and “machine learning”.</p>
<p>In this scenario, we build regression models (or other models) simply to predict and outcome. The main interest is not to learn more about how the outcome can be explained but to predict something with it which we want to know. Machine learning then takes it a step further and simply iteratively select the best models among hundrets of options to arrive at the best possible prediction (more on that at the end of the class). First, we will learn how to predict values based on a linear regression model.</p>
<div id="how-prediction-works" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> How prediction works<a href="pm-t.html#how-prediction-works" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For a linear regression model, prediction is very straight forward. Linear regression is all about finding a straight line through a cloud of points that lie on as many dimensions as there are variables in model. The model provides you with an intercept (i.e. where the line touches the Y-Axis, and a slope; the increase in y given one unit increase in x. The unit is whatever the scale of the x variable is). The formula is y= b + ßx + €. Any prediction is the on the line. You know the intercept, you plug in a value for x and you get your predicted y.</p>
<p>-&gt; visual here.</p>
<p>Let’s apply this logic to our NBA data. Remember in prior weeks, we built a linear model to estimate the effect of points scored on average per game and salaries of players. Let’s assume we now want to predict salaries of players and don’t care too much about the scores. We can consider a range of variables which we think explain variation in salaries. The better we can capture variation in salaries between players, the more precise our prediction will be.</p>
<p>Now, you may rightfully ask: “Why do we want to predict salaries if we already know the actual salaries!?” Fair point. Prediction is commonly used to predict values which we don’t have. Imagine there are some players that don’t report their salaries. We could predict their salaries based on what we know from players who are similar to them in many other observable characteristics. Or imagine we want to predict the salary of a hypothetical player that does not exist. Imagine an average players would like to know how much he could earn more if player more like other players. We can predict that. Last example, imagine we want to forecast how much a player makes next year, depending on his past performance.</p>
<p>Machine learning is basically predicting outcomes that are no known based on very large datasets. You provide R with a million photos of animals, you build a model to explain which animal is a cat. The you apply the model to new data and the model predicts whether there is a cat in the photo. Of course, machine learning gets much more complicated quickly, however, the basic logic is the logic of prediction.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="pm-t.html#cb165-1" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span></span>
<span id="cb165-2"><a href="pm-t.html#cb165-2" tabindex="-1"></a>             age, <span class="at">data =</span> data_nba)</span>
<span id="cb165-3"><a href="pm-t.html#cb165-3" tabindex="-1"></a></span>
<span id="cb165-4"><a href="pm-t.html#cb165-4" tabindex="-1"></a><span class="co"># base R way to get predicted values</span></span>
<span id="cb165-5"><a href="pm-t.html#cb165-5" tabindex="-1"></a>data_nba<span class="sc">$</span>predicted_values <span class="ot">&lt;-</span> model1<span class="sc">$</span>fitted.values</span>
<span id="cb165-6"><a href="pm-t.html#cb165-6" tabindex="-1"></a>data_nba <span class="ot">&lt;-</span> data_nba <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="st">&#39;_id&#39;</span>, name, salary, predicted_values, <span class="fu">everything</span>())</span>
<span id="cb165-7"><a href="pm-t.html#cb165-7" tabindex="-1"></a></span>
<span id="cb165-8"><a href="pm-t.html#cb165-8" tabindex="-1"></a>data_nba <span class="sc">%&gt;%</span></span>
<span id="cb165-9"><a href="pm-t.html#cb165-9" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>salary, <span class="at">y=</span>predicted_values)) <span class="sc">+</span></span>
<span id="cb165-10"><a href="pm-t.html#cb165-10" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb165-11"><a href="pm-t.html#cb165-11" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="pm-t.html#cb167-1" tabindex="-1"></a><span class="co"># new tidyverse way to get predicted values</span></span>
<span id="cb167-2"><a href="pm-t.html#cb167-2" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb167-3"><a href="pm-t.html#cb167-3" tabindex="-1"></a></span>
<span id="cb167-4"><a href="pm-t.html#cb167-4" tabindex="-1"></a><span class="co"># broom package has nice features to work with models</span></span>
<span id="cb167-5"><a href="pm-t.html#cb167-5" tabindex="-1"></a></span>
<span id="cb167-6"><a href="pm-t.html#cb167-6" tabindex="-1"></a><span class="co"># tidy() converts the model output into a dataframe, makes it easy to process further, e.g. make graphs etc.</span></span>
<span id="cb167-7"><a href="pm-t.html#cb167-7" tabindex="-1"></a><span class="fu">tidy</span>(model1)</span></code></pre></div>
<pre><code>## # A tibble: 25 × 5
##    term                estimate std.error statistic  p.value
##    &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)         -568370.    29308.    -19.4  3.15e-82
##  2 career_PTS            53791.      731.     73.6  0       
##  3 position_recForward -140645.    12779.    -11.0  5.24e-28
##  4 position_recGuard   -208234.    12166.    -17.1  9.89e-65
##  5 position_recMixed   -103661.    12104.     -8.56 1.26e-17
##  6 season_start1999      29357.    22884.      1.28 2.00e- 1
##  7 season_start2000      77209.    23559.      3.28 1.05e- 3
##  8 season_start2001     106436.    23625.      4.51 6.71e- 6
##  9 season_start2002     130348.    23627.      5.52 3.54e- 8
## 10 season_start2003     135221.    23648.      5.72 1.11e- 8
## # ℹ 15 more rows</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="pm-t.html#cb169-1" tabindex="-1"></a><span class="co"># glance provides meta-level info like r-squared etc.</span></span>
<span id="cb169-2"><a href="pm-t.html#cb169-2" tabindex="-1"></a><span class="fu">glance</span>(model1)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared   sigma statistic p.value    df   logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.432         0.431 352361.      308.       0    24 -138041. 2.76e5 2.76e5
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="pm-t.html#cb171-1" tabindex="-1"></a><span class="co"># augment creates a dataframe with the predicted values for everyobservation in the dataframe. </span></span>
<span id="cb171-2"><a href="pm-t.html#cb171-2" tabindex="-1"></a></span>
<span id="cb171-3"><a href="pm-t.html#cb171-3" tabindex="-1"></a>nba_salalary_predicted <span class="ot">&lt;-</span> <span class="fu">augment</span>(model1)</span></code></pre></div>
<p>The output above, get you the predicted values for the observations in the dataset. This is mostly used to evaluate the model itself. The bigger the difference between the predicted values and the actual values (so-called residuals), the worse the model.</p>
<p>Now, let’s predict the salary of hypothetical players:</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="pm-t.html#cb172-1" tabindex="-1"></a><span class="fu">table</span>(data_nba<span class="sc">$</span>position_rec)</span></code></pre></div>
<pre><code>## 
##  center Forward   Guard   Mixed 
##    1204    2130    3051    3343</code></pre>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="pm-t.html#cb174-1" tabindex="-1"></a><span class="co"># create all combination of the control variables which you want to predict</span></span>
<span id="cb174-2"><a href="pm-t.html#cb174-2" tabindex="-1"></a>prediction.data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb174-3"><a href="pm-t.html#cb174-3" tabindex="-1"></a>  <span class="at">position_rec =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;center&quot;</span>, <span class="st">&quot;Guard&quot;</span>, <span class="st">&quot;Guard&quot;</span>),</span>
<span id="cb174-4"><a href="pm-t.html#cb174-4" tabindex="-1"></a>  <span class="at">career_PTS =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">14</span>),</span>
<span id="cb174-5"><a href="pm-t.html#cb174-5" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">20</span>,<span class="dv">20</span>),</span>
<span id="cb174-6"><a href="pm-t.html#cb174-6" tabindex="-1"></a>  <span class="at">season_start =</span> <span class="fu">c</span>(<span class="st">&quot;2017&quot;</span>, <span class="st">&quot;2017&quot;</span>, <span class="st">&quot;2017&quot;</span>, <span class="st">&quot;2017&quot;</span>)</span>
<span id="cb174-7"><a href="pm-t.html#cb174-7" tabindex="-1"></a>)</span>
<span id="cb174-8"><a href="pm-t.html#cb174-8" tabindex="-1"></a></span>
<span id="cb174-9"><a href="pm-t.html#cb174-9" tabindex="-1"></a><span class="co"># apply the model to the &quot;new&quot; dataset</span></span>
<span id="cb174-10"><a href="pm-t.html#cb174-10" tabindex="-1"></a><span class="fu">predict</span>(model1, </span>
<span id="cb174-11"><a href="pm-t.html#cb174-11" tabindex="-1"></a>        prediction.data)</span></code></pre></div>
<pre><code>##        1        2        3        4 
## 675129.3 890294.2 466895.1 682059.9</code></pre>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="pm-t.html#cb176-1" tabindex="-1"></a>prediction.data<span class="sc">$</span>predicted_values <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, </span>
<span id="cb176-2"><a href="pm-t.html#cb176-2" tabindex="-1"></a>        prediction.data)</span>
<span id="cb176-3"><a href="pm-t.html#cb176-3" tabindex="-1"></a></span>
<span id="cb176-4"><a href="pm-t.html#cb176-4" tabindex="-1"></a>prediction.data <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb176-5"><a href="pm-t.html#cb176-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(position_rec, predicted_values,</span>
<span id="cb176-6"><a href="pm-t.html#cb176-6" tabindex="-1"></a>                 <span class="at">color=</span>career_PTS,</span>
<span id="cb176-7"><a href="pm-t.html#cb176-7" tabindex="-1"></a>                 <span class="at">size=</span><span class="dv">12</span>)) <span class="sc">+</span></span>
<span id="cb176-8"><a href="pm-t.html#cb176-8" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb176-9"><a href="pm-t.html#cb176-9" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>We can see that there is a huge salary increase predicted for just making two more baskets (i.e. 4 points) on average each game, for both guards and centers. We also see that centers make more money generally.</p>
<p>There is another way to get predicted values using the <code>margins()</code> function.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="pm-t.html#cb177-1" tabindex="-1"></a><span class="fu">library</span>(margins)</span>
<span id="cb177-2"><a href="pm-t.html#cb177-2" tabindex="-1"></a><span class="co"># This gets you the average change in predicted value for a unit-increase in the all model variables.</span></span>
<span id="cb177-3"><a href="pm-t.html#cb177-3" tabindex="-1"></a><span class="fu">margins</span>(model1)</span></code></pre></div>
<pre><code>##  career_PTS   age position_recForward position_recGuard position_recMixed
##       53791 16809             -140645           -208234           -103661
##  season_start1999 season_start2000 season_start2001 season_start2002
##             29357            77209           106436           130348
##  season_start2003 season_start2004 season_start2005 season_start2006
##            135221           150576           174625           183653
##  season_start2007 season_start2008 season_start2009 season_start2010
##            206434           231505           204116           192220
##  season_start2011 season_start2012 season_start2013 season_start2014
##            183026           182509           199072           174359
##  season_start2015 season_start2016 season_start2017
##            206791           305228           369398</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="pm-t.html#cb179-1" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">margins</span>(model1, <span class="at">at=</span> <span class="fu">list</span>(<span class="at">position_rec=</span> <span class="fu">c</span>(<span class="st">&quot;Guard&quot;</span>, <span class="st">&quot;center&quot;</span>),</span>
<span id="cb179-2"><a href="pm-t.html#cb179-2" tabindex="-1"></a>                         <span class="at">career_PTS=</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">14</span>))))</span></code></pre></div>
<pre><code>##              factor position_rec career_PTS         AME         SE       z
##                 age       1.0000    10.0000  16809.4290   822.1461 20.4458
##                 age       1.0000    14.0000  16809.4290   821.2659 20.4677
##                 age       2.0000    10.0000  16809.4290   821.3697 20.4651
##                 age       2.0000    14.0000  16809.4290   810.1705 20.7480
##          career_PTS       1.0000    10.0000  53791.2088   673.5739 79.8594
##          career_PTS       1.0000    14.0000  53791.2088   777.6596 69.1706
##          career_PTS       2.0000    10.0000  53791.2088   672.1461 80.0290
##          career_PTS       2.0000    14.0000  53791.2088   869.2152 61.8848
##  position_reccenter       1.0000    10.0000 208234.2670 12165.6828 17.1165
##  position_reccenter       1.0000    14.0000 208234.2670 12165.6828 17.1165
##  position_reccenter       2.0000    10.0000 208234.2670 12165.6828 17.1165
##  position_reccenter       2.0000    14.0000 208234.2670 12165.6828 17.1165
##    season_start1999       1.0000    10.0000  29356.8409 22884.2755  1.2828
##    season_start1999       1.0000    14.0000  29356.8409 22884.2755  1.2828
##    season_start1999       2.0000    10.0000  29356.8409 22884.2755  1.2828
##    season_start1999       2.0000    14.0000  29356.8409 22884.3468  1.2828
##    season_start2000       1.0000    10.0000  77209.1717 23559.4567  3.2772
##    season_start2000       1.0000    14.0000  77209.1717 23559.4567  3.2772
##    season_start2000       2.0000    10.0000  77209.1717 23559.4567  3.2772
##    season_start2000       2.0000    14.0000  77209.1717 23559.4567  3.2772
##    season_start2001       1.0000    10.0000 106435.5787 23624.8634  4.5052
##    season_start2001       1.0000    14.0000 106435.5787 23624.8634  4.5052
##    season_start2001       2.0000    10.0000 106435.5787 23624.8634  4.5052
##    season_start2001       2.0000    14.0000 106435.5787 23624.8621  4.5052
##    season_start2002       1.0000    10.0000 130348.2150 23627.2203  5.5169
##    season_start2002       1.0000    14.0000 130348.2150 23627.2203  5.5169
##    season_start2002       2.0000    10.0000 130348.2150 23627.2203  5.5169
##    season_start2002       2.0000    14.0000 130348.2150 23627.2203  5.5169
##    season_start2003       1.0000    10.0000 135220.5712 23648.3086  5.7180
##    season_start2003       1.0000    14.0000 135220.5712 23648.3086  5.7180
##    season_start2003       2.0000    10.0000 135220.5712 23648.3086  5.7180
##    season_start2003       2.0000    14.0000 135220.5712 23648.3047  5.7180
##    season_start2004       1.0000    10.0000 150575.6148 23423.7814  6.4283
##    season_start2004       1.0000    14.0000 150575.6148 23423.7814  6.4283
##    season_start2004       2.0000    10.0000 150575.6148 23423.7814  6.4283
##    season_start2004       2.0000    14.0000 150575.6148 23416.9662  6.4302
##    season_start2005       1.0000    10.0000 174625.3789 23247.7154  7.5115
##    season_start2005       1.0000    14.0000 174625.3789 23247.7154  7.5115
##    season_start2005       2.0000    10.0000 174625.3789 23247.7154  7.5115
##    season_start2005       2.0000    14.0000 174625.3789 23240.9439  7.5137
##    season_start2006       1.0000    10.0000 183653.2187 23057.8278  7.9649
##    season_start2006       1.0000    14.0000 183653.2187 23071.2667  7.9603
##    season_start2006       2.0000    10.0000 183653.2187 23071.2569  7.9603
##    season_start2006       2.0000    14.0000 183653.2187 23071.2471  7.9603
##    season_start2007       1.0000    10.0000 206434.1344 23336.8298  8.8459
##    season_start2007       1.0000    14.0000 206434.1344 23336.8298  8.8459
##    season_start2007       2.0000    10.0000 206434.1344 23336.8298  8.8459
##    season_start2007       2.0000    14.0000 206434.1344 23330.0326  8.8484
##    season_start2008       1.0000    10.0000 231505.0635 23507.2919  9.8482
##    season_start2008       1.0000    14.0000 231505.0635 23507.2919  9.8482
##    season_start2008       2.0000    10.0000 231505.0635 23507.2919  9.8482
##    season_start2008       2.0000    14.0000 231505.0635 23500.4440  9.8511
##    season_start2009       1.0000    10.0000 204115.6638 23475.4934  8.6948
##    season_start2009       1.0000    14.0000 204115.6638 23489.1731  8.6898
##    season_start2009       2.0000    10.0000 204115.6638 23489.1731  8.6898
##    season_start2009       2.0000    14.0000 204115.6638 23489.1586  8.6898
##    season_start2010       1.0000    10.0000 192219.8545 23548.5054  8.1627
##    season_start2010       1.0000    14.0000 192219.8545 23548.5054  8.1627
##    season_start2010       2.0000    10.0000 192219.8545 23548.5054  8.1627
##    season_start2010       2.0000    14.0000 192219.8545 23555.3511  8.1603
##    season_start2011       1.0000    10.0000 183025.8381 23534.7356  7.7768
##    season_start2011       1.0000    14.0000 183025.8381 23534.7356  7.7768
##    season_start2011       2.0000    10.0000 183025.8381 23534.7356  7.7768
##    season_start2011       2.0000    14.0000 183025.8381 23534.7356  7.7768
##    season_start2012       1.0000    10.0000 182509.4584 23219.2518  7.8603
##    season_start2012       1.0000    14.0000 182509.4584 23219.2518  7.8603
##    season_start2012       2.0000    10.0000 182509.4584 23219.2518  7.8603
##    season_start2012       2.0000    14.0000 182509.4584 23212.4961  7.8626
##    season_start2013       1.0000    10.0000 199072.4713 24314.5882  8.1874
##    season_start2013       1.0000    14.0000 199072.4713 24314.5882  8.1874
##    season_start2013       2.0000    10.0000 199072.4713 24314.5882  8.1874
##    season_start2013       2.0000    14.0000 199072.4713 24321.6667  8.1850
##    season_start2014       1.0000    10.0000 174358.9208 22746.2703  7.6654
##    season_start2014       1.0000    14.0000 174358.9208 22733.0380  7.6698
##    season_start2014       2.0000    10.0000 174358.9208 22733.0380  7.6698
##    season_start2014       2.0000    14.0000 174358.9208 22733.0380  7.6698
##    season_start2015       1.0000    10.0000 206791.4964 22900.6232  9.0300
##    season_start2015       1.0000    14.0000 206791.4964 22887.2931  9.0352
##    season_start2015       2.0000    10.0000 206791.4964 22887.2931  9.0352
##    season_start2015       2.0000    14.0000 206791.4964 22887.3012  9.0352
##    season_start2016       1.0000    10.0000 305227.6577 22617.9191 13.4949
##    season_start2016       1.0000    14.0000 305227.6577 22617.9191 13.4949
##    season_start2016       2.0000    10.0000 305227.6577 22617.9191 13.4949
##    season_start2016       2.0000    14.0000 305227.6577 22617.9191 13.4949
##    season_start2017       1.0000    10.0000 369398.3511 22665.9479 16.2975
##    season_start2017       1.0000    14.0000 369398.3511 22665.9479 16.2975
##    season_start2017       2.0000    10.0000 369398.3511 22665.9479 16.2975
##    season_start2017       2.0000    14.0000 369398.3511 22655.0335 16.3054
##       p       lower       upper
##  0.0000  15198.0523  18420.8057
##  0.0000  15199.7774  18419.0806
##  0.0000  15199.5740  18419.2841
##  0.0000  15221.5240  18397.3341
##  0.0000  52471.0281  55111.3895
##  0.0000  52267.0240  55315.3936
##  0.0000  52473.8267  55108.5909
##  0.0000  52087.5784  55494.8392
##  0.0000 184389.9668 232078.5671
##  0.0000 184389.9668 232078.5671
##  0.0000 184389.9668 232078.5671
##  0.0000 184389.9668 232078.5671
##  0.1995 -15495.5149  74209.1967
##  0.1995 -15495.5149  74209.1967
##  0.1995 -15495.5149  74209.1967
##  0.1995 -15495.6546  74209.3364
##  0.0010  31033.4850 123384.8584
##  0.0010  31033.4850 123384.8584
##  0.0010  31033.4850 123384.8584
##  0.0010  31033.4850 123384.8584
##  0.0000  60131.6973 152739.4600
##  0.0000  60131.6973 152739.4600
##  0.0000  60131.6973 152739.4600
##  0.0000  60131.6998 152739.4575
##  0.0000  84039.7141 176656.7158
##  0.0000  84039.7141 176656.7158
##  0.0000  84039.7141 176656.7158
##  0.0000  84039.7141 176656.7158
##  0.0000  88870.7382 181570.4043
##  0.0000  88870.7382 181570.4043
##  0.0000  88870.7382 181570.4043
##  0.0000  88870.7457 181570.3968
##  0.0000 104665.8469 196485.3827
##  0.0000 104665.8469 196485.3827
##  0.0000 104665.8469 196485.3827
##  0.0000 104679.2044 196472.0252
##  0.0000 129060.6941 220190.0637
##  0.0000 129060.6941 220190.0637
##  0.0000 129060.6941 220190.0637
##  0.0000 129073.9659 220176.7919
##  0.0000 138460.7067 228845.7307
##  0.0000 138434.3670 228872.0704
##  0.0000 138434.3861 228872.0513
##  0.0000 138434.4052 228872.0322
##  0.0000 160694.7885 252173.4804
##  0.0000 160694.7885 252173.4804
##  0.0000 160694.7885 252173.4804
##  0.0000 160708.1107 252160.1581
##  0.0000 185431.6180 277578.5090
##  0.0000 185431.6180 277578.5090
##  0.0000 185431.6180 277578.5090
##  0.0000 185445.0396 277565.0874
##  0.0000 158104.5422 250126.7855
##  0.0000 158077.7306 250153.5971
##  0.0000 158077.7306 250153.5971
##  0.0000 158077.7590 250153.5687
##  0.0000 146065.6320 238374.0769
##  0.0000 146065.6320 238374.0769
##  0.0000 146065.6320 238374.0769
##  0.0000 146052.2146 238387.4943
##  0.0000 136898.6039 229153.0723
##  0.0000 136898.6039 229153.0723
##  0.0000 136898.6039 229153.0723
##  0.0000 136898.6039 229153.0723
##  0.0000 137000.5611 228018.3557
##  0.0000 137000.5611 228018.3557
##  0.0000 137000.5611 228018.3557
##  0.0000 137013.8020 228005.1148
##  0.0000 151416.7540 246728.1885
##  0.0000 151416.7540 246728.1885
##  0.0000 151416.7540 246728.1885
##  0.0000 151402.8805 246742.0621
##  0.0000 129777.0502 218940.7913
##  0.0000 129802.9850 218914.8566
##  0.0000 129802.9850 218914.8566
##  0.0000 129802.9850 218914.8566
##  0.0000 161907.0996 251675.8931
##  0.0000 161933.2262 251649.7666
##  0.0000 161933.2262 251649.7666
##  0.0000 161933.2103 251649.7824
##  0.0000 260897.3510 349557.9645
##  0.0000 260897.3510 349557.9645
##  0.0000 260897.3510 349557.9645
##  0.0000 260897.3510 349557.9645
##  0.0000 324973.9095 413822.7927
##  0.0000 324973.9095 413822.7927
##  0.0000 324973.9095 413822.7927
##  0.0000 324995.3013 413801.4009</code></pre>
<p>The margins function is handy to calculate predictions for different groups.
It automatically can hold other control variables at their mean or at their observed value.</p>
<p>Now, let’s also calculate confidence and prediction intervals. For background, watch these short videos to understand what they are [hyperlink] [hyperlink]. Confidence intervals basically tell how the following: “If we repeated our study on a different sample of people with the same sample size, then the estimate which we have (for example, a mean) would we within the confidence interval 95% of the time. This means in 5% of cases, our study would arrive at a lower or higher mean. The formula for confidence is not very intuitive:</p>
<p>-&gt; formulate here: Margin of error = z * (standard deviation/ square-root of sample size)</p>
<p>Let’s not worry about why this formula works, but let’s focus on its ingredients: Sample size (N) is the number of people in our data; Standard Deviation is a measure for how much individual people deviate from the mean on average, in other words, how much the data spreads around the mean. and z is 1.96 and is derived from probability theory (i.e. in a normal distribution, there is a certain known likelihood that means fall within a range when re-sampling populations). In other words, the confidence intervals tells us how “confident” we can be that our estimate is within the range 95% of times.</p>
<p>Prediction intervals are very similar but only apply to predictions for specfific values. It gives us a measure for “confident” we can be that our prediction would be within the prediction interval (95% of times).</p>
<p>The 95% is an arbitrarily set value which is a standard in research. However, we can also set it at 99% or 90%.</p>
<p>Let’s apply this to our data.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="pm-t.html#cb181-1" tabindex="-1"></a><span class="co"># Just for illustration, let&#39;s take a simple model</span></span>
<span id="cb181-2"><a href="pm-t.html#cb181-2" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS, <span class="at">data =</span> data_nba)</span>
<span id="cb181-3"><a href="pm-t.html#cb181-3" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(model2)</span>
<span id="cb181-4"><a href="pm-t.html#cb181-4" tabindex="-1"></a>preds[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<pre><code>##        1        2        3        4        5        6        7        8 
## 721959.3 346026.1 346026.1 346026.1 346026.1 346026.1 346026.1 346026.1 
##        9       10 
## 346026.1 346026.1</code></pre>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="pm-t.html#cb183-1" tabindex="-1"></a><span class="co"># using geom_smooth, method=lm will automatically plot the confidence intervals</span></span>
<span id="cb183-2"><a href="pm-t.html#cb183-2" tabindex="-1"></a>data_nba <span class="sc">%&gt;%</span></span>
<span id="cb183-3"><a href="pm-t.html#cb183-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>salary, <span class="at">y=</span>career_PTS)) <span class="sc">+</span></span>
<span id="cb183-4"><a href="pm-t.html#cb183-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb183-5"><a href="pm-t.html#cb183-5" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="pm-t.html#cb184-1" tabindex="-1"></a><span class="co"># let&#39;s get prediction intervals and add them to our dataset</span></span>
<span id="cb184-2"><a href="pm-t.html#cb184-2" tabindex="-1"></a>data_nba_predict <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data_nba, <span class="fu">predict</span>(model2, <span class="at">interval =</span> <span class="fu">c</span>(<span class="st">&quot;prediction&quot;</span>)))</span>
<span id="cb184-3"><a href="pm-t.html#cb184-3" tabindex="-1"></a></span>
<span id="cb184-4"><a href="pm-t.html#cb184-4" tabindex="-1"></a>data_nba_predict <span class="sc">%&gt;%</span></span>
<span id="cb184-5"><a href="pm-t.html#cb184-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span> career_PTS, <span class="at">y=</span>salary)) <span class="sc">+</span></span>
<span id="cb184-6"><a href="pm-t.html#cb184-6" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb184-7"><a href="pm-t.html#cb184-7" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS, <span class="at">y=</span>fit),</span>
<span id="cb184-8"><a href="pm-t.html#cb184-8" tabindex="-1"></a>            <span class="at">col=</span><span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb184-9"><a href="pm-t.html#cb184-9" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lwr),</span>
<span id="cb184-10"><a href="pm-t.html#cb184-10" tabindex="-1"></a>                <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb184-11"><a href="pm-t.html#cb184-11" tabindex="-1"></a>                <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb184-12"><a href="pm-t.html#cb184-12" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>upr),</span>
<span id="cb184-13"><a href="pm-t.html#cb184-13" tabindex="-1"></a>                <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb184-14"><a href="pm-t.html#cb184-14" tabindex="-1"></a>                <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-2.png" width="672" /></p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="pm-t.html#cb185-1" tabindex="-1"></a><span class="co"># same using geom_ribbon</span></span>
<span id="cb185-2"><a href="pm-t.html#cb185-2" tabindex="-1"></a>data_nba_predict <span class="sc">%&gt;%</span></span>
<span id="cb185-3"><a href="pm-t.html#cb185-3" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>salary))<span class="sc">+</span></span>
<span id="cb185-4"><a href="pm-t.html#cb185-4" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb185-5"><a href="pm-t.html#cb185-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>fit))<span class="sc">+</span></span>
<span id="cb185-6"><a href="pm-t.html#cb185-6" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>upr,<span class="at">ymin=</span>lwr),<span class="at">color=</span><span class="st">&quot;red&quot;</span>,<span class="at">alpha=</span><span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-3.png" width="672" /></p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="pm-t.html#cb186-1" tabindex="-1"></a><span class="do">## do this with tidy approach</span></span>
<span id="cb186-2"><a href="pm-t.html#cb186-2" tabindex="-1"></a></span>
<span id="cb186-3"><a href="pm-t.html#cb186-3" tabindex="-1"></a><span class="co"># get confidnce interval for estimate</span></span>
<span id="cb186-4"><a href="pm-t.html#cb186-4" tabindex="-1"></a><span class="fu">tidy</span>(model2, <span class="at">conf.int =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 7
##   term        estimate std.error statistic  p.value conf.low conf.high
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  -85191.     7642.     -11.1 1.09e-28 -100171.   -70212.
## 2 career_PTS    55284.      745.      74.2 0          53823.    56745.</code></pre>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="pm-t.html#cb188-1" tabindex="-1"></a><span class="co"># get predictive intervals</span></span>
<span id="cb188-2"><a href="pm-t.html#cb188-2" tabindex="-1"></a><span class="fu">augment</span>(model2, <span class="at">interval=</span> <span class="st">&quot;prediction&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb188-3"><a href="pm-t.html#cb188-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>salary))<span class="sc">+</span></span>
<span id="cb188-4"><a href="pm-t.html#cb188-4" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb188-5"><a href="pm-t.html#cb188-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>.fitted))<span class="sc">+</span></span>
<span id="cb188-6"><a href="pm-t.html#cb188-6" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>.upper,<span class="at">ymin=</span>.lower),<span class="at">color=</span><span class="st">&quot;red&quot;</span>,<span class="at">alpha=</span><span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-4.png" width="672" /></p>
<p>Now, let’s compare the prediction interval for 2 differnt models.To compare the performance of models, you can use the r-squared (which measures how much of the variation in the outcome can be explained by your set of independent variables) and the mean squared error. For more background on both measures see here: <a href="https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/" class="uri">https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/</a></p>
<p>The Mean squared error (MSE) represents the error of the estimator or predictive model created based on the given set of observations in the sample. It measures the average squared difference between the predicted values and the actual values, quantifying the discrepancy between the model’s predictions and the true observations. The lower the MSE, the better the model predictive accuracy, and, the better the regression model is.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="pm-t.html#cb189-1" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span></span>
<span id="cb189-2"><a href="pm-t.html#cb189-2" tabindex="-1"></a>             age, <span class="at">data =</span> data_nba)</span>
<span id="cb189-3"><a href="pm-t.html#cb189-3" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> career_PTS, <span class="at">data =</span> data_nba)</span>
<span id="cb189-4"><a href="pm-t.html#cb189-4" tabindex="-1"></a></span>
<span id="cb189-5"><a href="pm-t.html#cb189-5" tabindex="-1"></a><span class="co"># compared R-squared/ adjusted R-squared</span></span>
<span id="cb189-6"><a href="pm-t.html#cb189-6" tabindex="-1"></a><span class="fu">glance</span>(model1)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared   sigma statistic p.value    df   logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.432         0.431 352361.      308.       0    24 -138041. 2.76e5 2.76e5
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="pm-t.html#cb191-1" tabindex="-1"></a><span class="fu">glance</span>(model2)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared   sigma statistic p.value    df   logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.361         0.361 373217.     5502.       0     1 -138612. 2.77e5 2.77e5
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="pm-t.html#cb193-1" tabindex="-1"></a><span class="co"># compare prediction intervals</span></span>
<span id="cb193-2"><a href="pm-t.html#cb193-2" tabindex="-1"></a>model1_predicted <span class="ot">&lt;-</span> <span class="fu">augment</span>(model1, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb193-3"><a href="pm-t.html#cb193-3" tabindex="-1"></a>model2_predicted <span class="ot">&lt;-</span> <span class="fu">augment</span>(model2, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb193-4"><a href="pm-t.html#cb193-4" tabindex="-1"></a></span>
<span id="cb193-5"><a href="pm-t.html#cb193-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>career_PTS,<span class="at">y=</span>salary), <span class="at">data =</span> model1_predicted)<span class="sc">+</span></span>
<span id="cb193-6"><a href="pm-t.html#cb193-6" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb193-7"><a href="pm-t.html#cb193-7" tabindex="-1"></a>  <span class="co"># geom_line(aes(x=career_pts,y=.fitted),</span></span>
<span id="cb193-8"><a href="pm-t.html#cb193-8" tabindex="-1"></a>  <span class="co">#           color =&quot;red&quot;, data = model1_predicted) +</span></span>
<span id="cb193-9"><a href="pm-t.html#cb193-9" tabindex="-1"></a>  <span class="co"># geom_line(aes(x=career_pts,y=.fitted),</span></span>
<span id="cb193-10"><a href="pm-t.html#cb193-10" tabindex="-1"></a>  <span class="co">#          color =&quot;blue&quot;, data = model2_predicted) +</span></span>
<span id="cb193-11"><a href="pm-t.html#cb193-11" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>.upper,<span class="at">ymin=</span>.lower),</span>
<span id="cb193-12"><a href="pm-t.html#cb193-12" tabindex="-1"></a>              <span class="at">color=</span><span class="st">&quot;red&quot;</span>,</span>
<span id="cb193-13"><a href="pm-t.html#cb193-13" tabindex="-1"></a>              <span class="at">alpha=</span><span class="fl">0.7</span>,</span>
<span id="cb193-14"><a href="pm-t.html#cb193-14" tabindex="-1"></a>              <span class="at">data =</span> model1_predicted) <span class="sc">+</span></span>
<span id="cb193-15"><a href="pm-t.html#cb193-15" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>.upper,<span class="at">ymin=</span>.lower),</span>
<span id="cb193-16"><a href="pm-t.html#cb193-16" tabindex="-1"></a>              <span class="at">color=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb193-17"><a href="pm-t.html#cb193-17" tabindex="-1"></a>              <span class="at">alpha=</span><span class="fl">0.7</span>,</span>
<span id="cb193-18"><a href="pm-t.html#cb193-18" tabindex="-1"></a>              <span class="at">data =</span> model2_predicted)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="pm-t.html#cb194-1" tabindex="-1"></a><span class="co"># see if there is a better way to do this</span></span>
<span id="cb194-2"><a href="pm-t.html#cb194-2" tabindex="-1"></a></span>
<span id="cb194-3"><a href="pm-t.html#cb194-3" tabindex="-1"></a><span class="fu">library</span>(Metrics) <span class="co"># using rmse from Metrics library</span></span>
<span id="cb194-4"><a href="pm-t.html#cb194-4" tabindex="-1"></a><span class="co"># compare mean squared error</span></span>
<span id="cb194-5"><a href="pm-t.html#cb194-5" tabindex="-1"></a>  <span class="fu">rmse</span>(model1_predicted<span class="sc">$</span>.fitted, data_nba<span class="sc">$</span>salary)</span></code></pre></div>
<pre><code>## [1] 351908.3</code></pre>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="pm-t.html#cb196-1" tabindex="-1"></a>  <span class="fu">rmse</span>(model2_predicted<span class="sc">$</span>.fitted, data_nba<span class="sc">$</span>salary)</span></code></pre></div>
<pre><code>## [1] 373178.4</code></pre>
<p>Looking at r2, the prediction intervals and rmse, model 1 clearly performs better than model 2.</p>
</div>
<div id="intro-to-machine-learning" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Intro to Machine learning<a href="pm-t.html#intro-to-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have now arrived at the entry gates to machine learning. We will conduct a very basic and simple machine learning routine using linear regression. The main difference between simple prediction and Machine Learning is that the sample is first divided into a training and a test dataset at random. The model is than tuned based on, let’s say, 80% of the sample. When the model is ready, it is tested based on the 20% remaining sample. The prediction produced with the model are then compared with the actual values in the test dataset. There is of course more nuance to all this, but this is basically the idea.</p>
<p>Let’s use the “caret” package, a common package for machine learning.</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="pm-t.html#cb198-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb198-2"><a href="pm-t.html#cb198-2" tabindex="-1"></a></span>
<span id="cb198-3"><a href="pm-t.html#cb198-3" tabindex="-1"></a><span class="co"># Create a train and test split</span></span>
<span id="cb198-4"><a href="pm-t.html#cb198-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb198-5"><a href="pm-t.html#cb198-5" tabindex="-1"></a>train_indices <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(data_nba<span class="sc">$</span>salary, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb198-6"><a href="pm-t.html#cb198-6" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> data_nba[train_indices, ]</span>
<span id="cb198-7"><a href="pm-t.html#cb198-7" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> data_nba[<span class="sc">-</span>train_indices, ]</span>
<span id="cb198-8"><a href="pm-t.html#cb198-8" tabindex="-1"></a></span>
<span id="cb198-9"><a href="pm-t.html#cb198-9" tabindex="-1"></a><span class="co"># Create a train control object</span></span>
<span id="cb198-10"><a href="pm-t.html#cb198-10" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb198-11"><a href="pm-t.html#cb198-11" tabindex="-1"></a></span>
<span id="cb198-12"><a href="pm-t.html#cb198-12" tabindex="-1"></a><span class="co"># Train a linear regression model using caret</span></span>
<span id="cb198-13"><a href="pm-t.html#cb198-13" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb198-14"><a href="pm-t.html#cb198-14" tabindex="-1"></a>  salary <span class="sc">~</span> career_PTS <span class="sc">+</span> position_rec <span class="sc">+</span> season_start <span class="sc">+</span> age,</span>
<span id="cb198-15"><a href="pm-t.html#cb198-15" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb198-16"><a href="pm-t.html#cb198-16" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb198-17"><a href="pm-t.html#cb198-17" tabindex="-1"></a>  <span class="at">trControl =</span> ctrl</span>
<span id="cb198-18"><a href="pm-t.html#cb198-18" tabindex="-1"></a>)</span>
<span id="cb198-19"><a href="pm-t.html#cb198-19" tabindex="-1"></a></span>
<span id="cb198-20"><a href="pm-t.html#cb198-20" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb198-21"><a href="pm-t.html#cb198-21" tabindex="-1"></a>  salary <span class="sc">~</span> career_PTS,</span>
<span id="cb198-22"><a href="pm-t.html#cb198-22" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb198-23"><a href="pm-t.html#cb198-23" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb198-24"><a href="pm-t.html#cb198-24" tabindex="-1"></a>  <span class="at">trControl =</span> ctrl</span>
<span id="cb198-25"><a href="pm-t.html#cb198-25" tabindex="-1"></a>)</span>
<span id="cb198-26"><a href="pm-t.html#cb198-26" tabindex="-1"></a></span>
<span id="cb198-27"><a href="pm-t.html#cb198-27" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb198-28"><a href="pm-t.html#cb198-28" tabindex="-1"></a>predicted_salaries_m1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, <span class="at">newdata =</span> test_data)</span>
<span id="cb198-29"><a href="pm-t.html#cb198-29" tabindex="-1"></a>predicted_salaries_m2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model2, <span class="at">newdata =</span> test_data)</span>
<span id="cb198-30"><a href="pm-t.html#cb198-30" tabindex="-1"></a></span>
<span id="cb198-31"><a href="pm-t.html#cb198-31" tabindex="-1"></a></span>
<span id="cb198-32"><a href="pm-t.html#cb198-32" tabindex="-1"></a><span class="co"># Calculate prediction errors (e.g., root mean squared error)</span></span>
<span id="cb198-33"><a href="pm-t.html#cb198-33" tabindex="-1"></a>rmse1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((predicted_salaries_m1 <span class="sc">-</span> test_data<span class="sc">$</span>salary)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb198-34"><a href="pm-t.html#cb198-34" tabindex="-1"></a>rmse2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((predicted_salaries_m2 <span class="sc">-</span> test_data<span class="sc">$</span>salary)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb198-35"><a href="pm-t.html#cb198-35" tabindex="-1"></a></span>
<span id="cb198-36"><a href="pm-t.html#cb198-36" tabindex="-1"></a><span class="co"># Print the prediction errors</span></span>
<span id="cb198-37"><a href="pm-t.html#cb198-37" tabindex="-1"></a><span class="fu">print</span>(rmse1)</span></code></pre></div>
<pre><code>## [1] 341746.4</code></pre>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="pm-t.html#cb200-1" tabindex="-1"></a><span class="fu">print</span>(rmse2)</span></code></pre></div>
<pre><code>## [1] 360297.3</code></pre>
<p>Now machine learning usually involves several more steps:
+ we can optimize how the variables (in ML language called features) enter the model (Pre-processing; transformations; diagnostics, see week X)
+ we can optimize which variables should even enter the model (“feature selection”, see e.g. lasso regression)
+ we can optimize how the predictions of the model get evaluated (“training”)
+ we can optimize which estimator or algorithm best predicts the outcome (lm model is just one option among many)
+ for other algorithms (e.g. random forests), we can also “tune” the model using hyper-parameters</p>
</div>
<div id="more-resources" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> More resources:<a href="pm-t.html#more-resources" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Provide list of online resources to dig deeper</li>
<li>see <code>tidymodels()</code> for another package for Machine Learning</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="med.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pm-a.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/11-prediction-theory.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
